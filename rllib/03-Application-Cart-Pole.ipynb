{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JD0Eu7JWdVqY"
   },
   "source": [
    "# RLlib Sample Application: CartPole-v0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were briefly introduced to the _CartPole_ example and the OpenAI gym `CartPole-v0` environment ([gym.openai.com/envs/CartPole-v0/](https://gym.openai.com/envs/CartPole-v0/)) in the [introduction](01-Introduction-to-Reinforcement-Learning.ipynb). This lesson uses [RLlib](https://ray.readthedocs.io/en/latest/rllib.html) to train a policy for _CartPole_.\n",
    "\n",
    "Even though this is a relatively simple and quick example to run, its results can be understood quite visually.\n",
    "\n",
    "For more background about this problem, see:\n",
    "\n",
    "* [\"Neuronlike Adaptive Elements That Can Solve Difficult Learning Control Problem\"](https://ieeexplore.ieee.org/document/6313077), AG Barto, RS Sutton, and CW Anderson, *IEEE Transactions on Systems, Man, and Cybernetics* (1983)\n",
    "* [\"Cartpole - Introduction to Reinforcement Learning (DQN - Deep Q-Learning)\"](https://towardsdatascience.com/cartpole-introduction-to-reinforcement-learning-ed0eb5b58288), [Greg Surma](https://twitter.com/GSurma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import Ray and the PPO module in RLlib, then start Ray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import ray.rllib.agents.ppo as ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-01 11:54:47,624\tINFO resource_spec.py:212 -- Starting Ray with 4.79 GiB memory available for workers and up to 2.42 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-05-01 11:54:47,952\tINFO services.py:1148 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.149',\n",
       " 'redis_address': '192.168.1.149:19062',\n",
       " 'object_store_address': '/tmp/ray/session_2020-05-01_11-54-47_613558_27290/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-05-01_11-54-47_613558_27290/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-05-01_11-54-47_613558_27290'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ray Dashboard is useful for monitoring Ray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard URL: http://localhost:8265\n"
     ]
    }
   ],
   "source": [
    "print(f'Dashboard URL: http://{ray.get_webui_url()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll train an RLlib policy with the [`CartPole-v0` environment](https://gym.openai.com/envs/CartPole-v0/).\n",
    "\n",
    "By default, training runs for `10` iterations. Increase the `N_ITER` setting if you want to train longer and see the resulting rewards improve.\n",
    "Also note that *checkpoints* get saved after each iteration into the `/tmp/ppo/cart` directory.\n",
    "\n",
    "> **Note:** If you prefer to use a different directory root than `/tmp`, change it in the next cell **and** in the `rllib rollout` command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-01 12:01:15,835\tINFO trainer.py:428 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2020-05-01 12:01:15,858\tINFO trainer.py:585 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2020-05-01 12:01:17,762\tINFO trainable.py:217 -- Getting current IP.\n",
      "2020-05-01 12:01:17,762\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'episode_reward_max': 79.0, 'episode_reward_min': 8.0, 'episode_reward_mean': 21.690217391304348, 'episode_len_mean': 21.690217391304348, 'episodes_this_iter': 184, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [11.0, 15.0, 32.0, 17.0, 36.0, 75.0, 34.0, 22.0, 47.0, 27.0, 21.0, 21.0, 14.0, 23.0, 21.0, 18.0, 20.0, 18.0, 23.0, 14.0, 15.0, 19.0, 20.0, 19.0, 10.0, 28.0, 25.0, 19.0, 25.0, 36.0, 17.0, 12.0, 18.0, 21.0, 10.0, 24.0, 27.0, 19.0, 31.0, 22.0, 10.0, 11.0, 19.0, 35.0, 26.0, 13.0, 24.0, 33.0, 13.0, 10.0, 16.0, 11.0, 31.0, 31.0, 21.0, 14.0, 24.0, 14.0, 47.0, 18.0, 14.0, 39.0, 41.0, 11.0, 25.0, 23.0, 39.0, 30.0, 19.0, 14.0, 16.0, 11.0, 25.0, 12.0, 11.0, 30.0, 14.0, 25.0, 9.0, 62.0, 26.0, 28.0, 23.0, 19.0, 11.0, 14.0, 14.0, 12.0, 14.0, 18.0, 19.0, 16.0, 25.0, 50.0, 28.0, 19.0, 13.0, 15.0, 33.0, 29.0, 15.0, 20.0, 23.0, 16.0, 49.0, 17.0, 28.0, 18.0, 43.0, 20.0, 26.0, 9.0, 38.0, 23.0, 24.0, 15.0, 11.0, 17.0, 22.0, 8.0, 39.0, 16.0, 19.0, 13.0, 21.0, 11.0, 12.0, 23.0, 30.0, 13.0, 27.0, 10.0, 13.0, 26.0, 15.0, 11.0, 26.0, 25.0, 34.0, 14.0, 17.0, 23.0, 30.0, 29.0, 16.0, 22.0, 17.0, 14.0, 23.0, 79.0, 17.0, 19.0, 22.0, 19.0, 17.0, 20.0, 11.0, 12.0, 14.0, 31.0, 9.0, 19.0, 13.0, 13.0, 24.0, 23.0, 11.0, 46.0, 21.0, 27.0, 16.0, 14.0, 32.0, 14.0, 17.0, 16.0, 14.0, 17.0, 18.0, 13.0, 37.0, 11.0, 20.0, 11.0], 'episode_lengths': [11, 15, 32, 17, 36, 75, 34, 22, 47, 27, 21, 21, 14, 23, 21, 18, 20, 18, 23, 14, 15, 19, 20, 19, 10, 28, 25, 19, 25, 36, 17, 12, 18, 21, 10, 24, 27, 19, 31, 22, 10, 11, 19, 35, 26, 13, 24, 33, 13, 10, 16, 11, 31, 31, 21, 14, 24, 14, 47, 18, 14, 39, 41, 11, 25, 23, 39, 30, 19, 14, 16, 11, 25, 12, 11, 30, 14, 25, 9, 62, 26, 28, 23, 19, 11, 14, 14, 12, 14, 18, 19, 16, 25, 50, 28, 19, 13, 15, 33, 29, 15, 20, 23, 16, 49, 17, 28, 18, 43, 20, 26, 9, 38, 23, 24, 15, 11, 17, 22, 8, 39, 16, 19, 13, 21, 11, 12, 23, 30, 13, 27, 10, 13, 26, 15, 11, 26, 25, 34, 14, 17, 23, 30, 29, 16, 22, 17, 14, 23, 79, 17, 19, 22, 19, 17, 20, 11, 12, 14, 31, 9, 19, 13, 13, 24, 23, 11, 46, 21, 27, 16, 14, 32, 14, 17, 16, 14, 17, 18, 13, 37, 11, 20, 11]}, 'sampler_perf': {'mean_env_wait_ms': 0.043487064717653776, 'mean_processing_ms': 0.12681575812279752, 'mean_inference_ms': 0.5654149184680691}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 3968, 'num_steps_sampled': 4000, 'sample_time_ms': 3380.793, 'load_time_ms': 52.145, 'grad_time_ms': 1943.254, 'update_time_ms': 506.733, 'learner': {'default_policy': {'cur_kl_coeff': 0.20000000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 86.56224, 'policy_loss': -0.045091983, 'vf_loss': 86.600815, 'vf_explained_var': 0.07337995, 'kl': 0.03260612, 'entropy': 0.6611264, 'entropy_coeff': 0.0, 'model': {}}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 4000, 'episodes_total': 184, 'training_iteration': 1, 'experiment_id': 'ef6533da38f340edadc19202698a4949', 'date': '2020-05-01_12-01-23', 'timestamp': 1588359683, 'time_this_iter_s': 5.924252986907959, 'time_total_s': 5.924252986907959, 'pid': 27290, 'hostname': 'DWAnyscaleMBP.local', 'node_ip': '192.168.1.149', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'use_exec_api': False, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 5.924252986907959, 'timesteps_since_restore': 4000, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 38.411111111111104, 'ram_util_percent': 67.47777777777777}, 'num_healthy_workers': 2}\n",
      "\n",
      "tmp/ppo/cart/checkpoint_1/checkpoint-1\n",
      "{'episode_reward_max': 96.0, 'episode_reward_min': 9.0, 'episode_reward_mean': 39.78, 'episode_len_mean': 39.78, 'episodes_this_iter': 97, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [73.0, 59.0, 9.0, 96.0, 34.0, 54.0, 19.0, 14.0, 10.0, 51.0, 14.0, 56.0, 90.0, 52.0, 52.0, 36.0, 41.0, 56.0, 33.0, 24.0, 90.0, 73.0, 13.0, 12.0, 26.0, 44.0, 37.0, 36.0, 19.0, 14.0, 17.0, 81.0, 21.0, 90.0, 57.0, 35.0, 44.0, 80.0, 24.0, 94.0, 48.0, 44.0, 44.0, 34.0, 33.0, 38.0, 40.0, 32.0, 22.0, 70.0, 12.0, 70.0, 15.0, 16.0, 34.0, 39.0, 79.0, 67.0, 26.0, 50.0, 23.0, 53.0, 28.0, 37.0, 23.0, 41.0, 67.0, 17.0, 96.0, 48.0, 21.0, 54.0, 28.0, 39.0, 13.0, 57.0, 20.0, 43.0, 26.0, 29.0, 21.0, 68.0, 35.0, 28.0, 75.0, 29.0, 11.0, 28.0, 23.0, 42.0, 51.0, 9.0, 28.0, 33.0, 52.0, 23.0, 24.0, 11.0, 20.0, 11.0], 'episode_lengths': [73, 59, 9, 96, 34, 54, 19, 14, 10, 51, 14, 56, 90, 52, 52, 36, 41, 56, 33, 24, 90, 73, 13, 12, 26, 44, 37, 36, 19, 14, 17, 81, 21, 90, 57, 35, 44, 80, 24, 94, 48, 44, 44, 34, 33, 38, 40, 32, 22, 70, 12, 70, 15, 16, 34, 39, 79, 67, 26, 50, 23, 53, 28, 37, 23, 41, 67, 17, 96, 48, 21, 54, 28, 39, 13, 57, 20, 43, 26, 29, 21, 68, 35, 28, 75, 29, 11, 28, 23, 42, 51, 9, 28, 33, 52, 23, 24, 11, 20, 11]}, 'sampler_perf': {'mean_env_wait_ms': 0.04423686027577957, 'mean_processing_ms': 0.12291264415076172, 'mean_inference_ms': 0.5585989586268894}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 7936, 'num_steps_sampled': 8000, 'sample_time_ms': 2416.752, 'load_time_ms': 26.828, 'grad_time_ms': 1984.498, 'update_time_ms': 254.756, 'learner': {'default_policy': {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 176.84914, 'policy_loss': -0.035111774, 'vf_loss': 176.8784, 'vf_explained_var': 0.16017696, 'kl': 0.01948518, 'entropy': 0.6006518, 'entropy_coeff': 0.0, 'model': {}}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 8000, 'episodes_total': 281, 'training_iteration': 2, 'experiment_id': 'ef6533da38f340edadc19202698a4949', 'date': '2020-05-01_12-01-27', 'timestamp': 1588359687, 'time_this_iter_s': 3.4871859550476074, 'time_total_s': 9.411438941955566, 'pid': 27290, 'hostname': 'DWAnyscaleMBP.local', 'node_ip': '192.168.1.149', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'use_exec_api': False, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 9.411438941955566, 'timesteps_since_restore': 8000, 'iterations_since_restore': 2, 'perf': {'cpu_util_percent': 53.959999999999994, 'ram_util_percent': 67.88}, 'num_healthy_workers': 2}\n",
      "\n",
      "tmp/ppo/cart/checkpoint_2/checkpoint-2\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 9.0, 'episode_reward_mean': 61.62, 'episode_len_mean': 61.62, 'episodes_this_iter': 43, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [174.0, 77.0, 138.0, 60.0, 200.0, 112.0, 200.0, 104.0, 31.0, 58.0, 18.0, 157.0, 106.0, 101.0, 181.0, 71.0, 39.0, 152.0, 110.0, 14.0, 10.0, 88.0, 141.0, 130.0, 20.0, 200.0, 41.0, 83.0, 51.0, 19.0, 47.0, 31.0, 104.0, 80.0, 189.0, 153.0, 200.0, 45.0, 99.0, 16.0, 85.0, 34.0, 37.0, 48.0, 44.0, 44.0, 34.0, 33.0, 38.0, 40.0, 32.0, 22.0, 70.0, 12.0, 70.0, 15.0, 16.0, 34.0, 39.0, 79.0, 67.0, 26.0, 50.0, 23.0, 53.0, 28.0, 37.0, 23.0, 41.0, 67.0, 17.0, 96.0, 48.0, 21.0, 54.0, 28.0, 39.0, 13.0, 57.0, 20.0, 43.0, 26.0, 29.0, 21.0, 68.0, 35.0, 28.0, 75.0, 29.0, 11.0, 28.0, 23.0, 42.0, 51.0, 9.0, 28.0, 33.0, 52.0, 23.0, 24.0], 'episode_lengths': [174, 77, 138, 60, 200, 112, 200, 104, 31, 58, 18, 157, 106, 101, 181, 71, 39, 152, 110, 14, 10, 88, 141, 130, 20, 200, 41, 83, 51, 19, 47, 31, 104, 80, 189, 153, 200, 45, 99, 16, 85, 34, 37, 48, 44, 44, 34, 33, 38, 40, 32, 22, 70, 12, 70, 15, 16, 34, 39, 79, 67, 26, 50, 23, 53, 28, 37, 23, 41, 67, 17, 96, 48, 21, 54, 28, 39, 13, 57, 20, 43, 26, 29, 21, 68, 35, 28, 75, 29, 11, 28, 23, 42, 51, 9, 28, 33, 52, 23, 24]}, 'sampler_perf': {'mean_env_wait_ms': 0.04627891958382608, 'mean_processing_ms': 0.12583237752553728, 'mean_inference_ms': 0.5841607820983937}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 11904, 'num_steps_sampled': 12000, 'sample_time_ms': 2247.35, 'load_time_ms': 18.303, 'grad_time_ms': 1963.02, 'update_time_ms': 171.038, 'learner': {'default_policy': {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 470.96582, 'policy_loss': -0.01628473, 'vf_loss': 470.9785, 'vf_explained_var': 0.1407725, 'kl': 0.012293886, 'entropy': 0.56601626, 'entropy_coeff': 0.0, 'model': {}}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 12000, 'episodes_total': 324, 'training_iteration': 3, 'experiment_id': 'ef6533da38f340edadc19202698a4949', 'date': '2020-05-01_12-01-31', 'timestamp': 1588359691, 'time_this_iter_s': 3.8387410640716553, 'time_total_s': 13.250180006027222, 'pid': 27290, 'hostname': 'DWAnyscaleMBP.local', 'node_ip': '192.168.1.149', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'use_exec_api': False, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 13.250180006027222, 'timesteps_since_restore': 12000, 'iterations_since_restore': 3, 'perf': {'cpu_util_percent': 64.6, 'ram_util_percent': 65.43333333333334}, 'num_healthy_workers': 2}\n",
      "\n",
      "tmp/ppo/cart/checkpoint_3/checkpoint-3\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 9.0, 'episode_reward_mean': 91.64, 'episode_len_mean': 91.64, 'episodes_this_iter': 26, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [50.0, 179.0, 74.0, 200.0, 145.0, 195.0, 163.0, 155.0, 142.0, 160.0, 34.0, 124.0, 191.0, 200.0, 200.0, 145.0, 184.0, 138.0, 145.0, 196.0, 200.0, 176.0, 154.0, 200.0, 108.0, 162.0, 67.0, 17.0, 96.0, 48.0, 21.0, 54.0, 28.0, 39.0, 13.0, 57.0, 20.0, 43.0, 26.0, 29.0, 21.0, 68.0, 35.0, 28.0, 75.0, 29.0, 11.0, 28.0, 23.0, 42.0, 51.0, 9.0, 28.0, 33.0, 52.0, 23.0, 24.0, 174.0, 77.0, 138.0, 60.0, 200.0, 112.0, 200.0, 104.0, 31.0, 58.0, 18.0, 157.0, 106.0, 101.0, 181.0, 71.0, 39.0, 152.0, 110.0, 14.0, 10.0, 88.0, 141.0, 130.0, 20.0, 200.0, 41.0, 83.0, 51.0, 19.0, 47.0, 31.0, 104.0, 80.0, 189.0, 153.0, 200.0, 45.0, 99.0, 16.0, 85.0, 34.0, 37.0], 'episode_lengths': [50, 179, 74, 200, 145, 195, 163, 155, 142, 160, 34, 124, 191, 200, 200, 145, 184, 138, 145, 196, 200, 176, 154, 200, 108, 162, 67, 17, 96, 48, 21, 54, 28, 39, 13, 57, 20, 43, 26, 29, 21, 68, 35, 28, 75, 29, 11, 28, 23, 42, 51, 9, 28, 33, 52, 23, 24, 174, 77, 138, 60, 200, 112, 200, 104, 31, 58, 18, 157, 106, 101, 181, 71, 39, 152, 110, 14, 10, 88, 141, 130, 20, 200, 41, 83, 51, 19, 47, 31, 104, 80, 189, 153, 200, 45, 99, 16, 85, 34, 37]}, 'sampler_perf': {'mean_env_wait_ms': 0.047500096586069684, 'mean_processing_ms': 0.12712949886069377, 'mean_inference_ms': 0.6008041659298952}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 15872, 'num_steps_sampled': 16000, 'sample_time_ms': 2096.157, 'load_time_ms': 14.022, 'grad_time_ms': 1962.448, 'update_time_ms': 129.302, 'learner': {'default_policy': {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 483.9784, 'policy_loss': -0.010556337, 'vf_loss': 483.98578, 'vf_explained_var': 0.35133046, 'kl': 0.0103806555, 'entropy': 0.5358525, 'entropy_coeff': 0.0, 'model': {}}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 16000, 'episodes_total': 350, 'training_iteration': 4, 'experiment_id': 'ef6533da38f340edadc19202698a4949', 'date': '2020-05-01_12-01-34', 'timestamp': 1588359694, 'time_this_iter_s': 3.6119649410247803, 'time_total_s': 16.862144947052002, 'pid': 27290, 'hostname': 'DWAnyscaleMBP.local', 'node_ip': '192.168.1.149', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'use_exec_api': False, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 16.862144947052002, 'timesteps_since_restore': 16000, 'iterations_since_restore': 4, 'perf': {'cpu_util_percent': 56.4, 'ram_util_percent': 65.47999999999999}, 'num_healthy_workers': 2}\n",
      "\n",
      "tmp/ppo/cart/checkpoint_4/checkpoint-4\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 9.0, 'episode_reward_mean': 121.25, 'episode_len_mean': 121.25, 'episodes_this_iter': 22, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 132.0, 60.0, 200.0, 200.0, 130.0, 200.0, 137.0, 200.0, 200.0, 123.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 171.0, 122.0, 200.0, 178.0, 182.0, 23.0, 42.0, 51.0, 9.0, 28.0, 33.0, 52.0, 23.0, 24.0, 174.0, 77.0, 138.0, 60.0, 200.0, 112.0, 200.0, 104.0, 31.0, 58.0, 18.0, 157.0, 106.0, 101.0, 181.0, 71.0, 39.0, 152.0, 110.0, 14.0, 10.0, 88.0, 141.0, 130.0, 20.0, 200.0, 41.0, 83.0, 51.0, 19.0, 47.0, 31.0, 104.0, 80.0, 189.0, 153.0, 200.0, 45.0, 99.0, 16.0, 85.0, 34.0, 37.0, 50.0, 179.0, 74.0, 200.0, 145.0, 195.0, 163.0, 155.0, 142.0, 160.0, 34.0, 124.0, 191.0, 200.0, 200.0, 145.0, 184.0, 138.0, 145.0, 196.0, 200.0, 176.0, 154.0, 200.0, 108.0, 162.0], 'episode_lengths': [200, 132, 60, 200, 200, 130, 200, 137, 200, 200, 123, 200, 200, 179, 200, 200, 200, 171, 122, 200, 178, 182, 23, 42, 51, 9, 28, 33, 52, 23, 24, 174, 77, 138, 60, 200, 112, 200, 104, 31, 58, 18, 157, 106, 101, 181, 71, 39, 152, 110, 14, 10, 88, 141, 130, 20, 200, 41, 83, 51, 19, 47, 31, 104, 80, 189, 153, 200, 45, 99, 16, 85, 34, 37, 50, 179, 74, 200, 145, 195, 163, 155, 142, 160, 34, 124, 191, 200, 200, 145, 184, 138, 145, 196, 200, 176, 154, 200, 108, 162]}, 'sampler_perf': {'mean_env_wait_ms': 0.048499008052270316, 'mean_processing_ms': 0.12779552946659867, 'mean_inference_ms': 0.6135610813705331}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 19840, 'num_steps_sampled': 20000, 'sample_time_ms': 1985.643, 'load_time_ms': 11.462, 'grad_time_ms': 1898.271, 'update_time_ms': 104.195, 'learner': {'default_policy': {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 324.25662, 'policy_loss': -0.005759865, 'vf_loss': 324.26065, 'vf_explained_var': 0.41557226, 'kl': 0.005687899, 'entropy': 0.5284314, 'entropy_coeff': 0.0, 'model': {}}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 20000, 'episodes_total': 372, 'training_iteration': 5, 'experiment_id': 'ef6533da38f340edadc19202698a4949', 'date': '2020-05-01_12-01-37', 'timestamp': 1588359697, 'time_this_iter_s': 3.1928188800811768, 'time_total_s': 20.05496382713318, 'pid': 27290, 'hostname': 'DWAnyscaleMBP.local', 'node_ip': '192.168.1.149', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'use_exec_api': False, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 20.05496382713318, 'timesteps_since_restore': 20000, 'iterations_since_restore': 5, 'perf': {'cpu_util_percent': 53.125, 'ram_util_percent': 65.42500000000001}, 'num_healthy_workers': 2}\n",
      "\n",
      "tmp/ppo/cart/checkpoint_5/checkpoint-5\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 10.0, 'episode_reward_mean': 146.55, 'episode_len_mean': 146.55, 'episodes_this_iter': 21, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 166.0, 200.0, 200.0, 200.0, 106.0, 101.0, 181.0, 71.0, 39.0, 152.0, 110.0, 14.0, 10.0, 88.0, 141.0, 130.0, 20.0, 200.0, 41.0, 83.0, 51.0, 19.0, 47.0, 31.0, 104.0, 80.0, 189.0, 153.0, 200.0, 45.0, 99.0, 16.0, 85.0, 34.0, 37.0, 50.0, 179.0, 74.0, 200.0, 145.0, 195.0, 163.0, 155.0, 142.0, 160.0, 34.0, 124.0, 191.0, 200.0, 200.0, 145.0, 184.0, 138.0, 145.0, 196.0, 200.0, 176.0, 154.0, 200.0, 108.0, 162.0, 200.0, 132.0, 60.0, 200.0, 200.0, 130.0, 200.0, 137.0, 200.0, 200.0, 123.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 171.0, 122.0, 200.0, 178.0, 182.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 178, 200, 200, 200, 200, 200, 200, 200, 166, 200, 200, 200, 106, 101, 181, 71, 39, 152, 110, 14, 10, 88, 141, 130, 20, 200, 41, 83, 51, 19, 47, 31, 104, 80, 189, 153, 200, 45, 99, 16, 85, 34, 37, 50, 179, 74, 200, 145, 195, 163, 155, 142, 160, 34, 124, 191, 200, 200, 145, 184, 138, 145, 196, 200, 176, 154, 200, 108, 162, 200, 132, 60, 200, 200, 130, 200, 137, 200, 200, 123, 200, 200, 179, 200, 200, 200, 171, 122, 200, 178, 182]}, 'sampler_perf': {'mean_env_wait_ms': 0.0488583015891128, 'mean_processing_ms': 0.12719043848584757, 'mean_inference_ms': 0.6155084568842301}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 23808, 'num_steps_sampled': 24000, 'sample_time_ms': 1886.507, 'load_time_ms': 9.739, 'grad_time_ms': 1832.224, 'update_time_ms': 87.217, 'learner': {'default_policy': {'cur_kl_coeff': 0.30000001192092896, 'cur_lr': 4.999999873689376e-05, 'total_loss': 342.5065, 'policy_loss': -0.00248389, 'vf_loss': 342.50803, 'vf_explained_var': 0.3700403, 'kl': 0.0030817636, 'entropy': 0.5369367, 'entropy_coeff': 0.0, 'model': {}}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 24000, 'episodes_total': 393, 'training_iteration': 6, 'experiment_id': 'ef6533da38f340edadc19202698a4949', 'date': '2020-05-01_12-01-40', 'timestamp': 1588359700, 'time_this_iter_s': 2.8991003036499023, 'time_total_s': 22.95406413078308, 'pid': 27290, 'hostname': 'DWAnyscaleMBP.local', 'node_ip': '192.168.1.149', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'use_exec_api': False, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 22.95406413078308, 'timesteps_since_restore': 24000, 'iterations_since_restore': 6, 'perf': {'cpu_util_percent': 48.675, 'ram_util_percent': 65.55}, 'num_healthy_workers': 2}\n",
      "\n",
      "tmp/ppo/cart/checkpoint_6/checkpoint-6\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 16.0, 'episode_reward_mean': 170.2, 'episode_len_mean': 170.2, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 104.0, 80.0, 189.0, 153.0, 200.0, 45.0, 99.0, 16.0, 85.0, 34.0, 37.0, 50.0, 179.0, 74.0, 200.0, 145.0, 195.0, 163.0, 155.0, 142.0, 160.0, 34.0, 124.0, 191.0, 200.0, 200.0, 145.0, 184.0, 138.0, 145.0, 196.0, 200.0, 176.0, 154.0, 200.0, 108.0, 162.0, 200.0, 132.0, 60.0, 200.0, 200.0, 130.0, 200.0, 137.0, 200.0, 200.0, 123.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 171.0, 122.0, 200.0, 178.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 166.0, 200.0, 200.0, 200.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 104, 80, 189, 153, 200, 45, 99, 16, 85, 34, 37, 50, 179, 74, 200, 145, 195, 163, 155, 142, 160, 34, 124, 191, 200, 200, 145, 184, 138, 145, 196, 200, 176, 154, 200, 108, 162, 200, 132, 60, 200, 200, 130, 200, 137, 200, 200, 123, 200, 200, 179, 200, 200, 200, 171, 122, 200, 178, 182, 200, 200, 200, 200, 200, 200, 200, 200, 200, 178, 200, 200, 200, 200, 200, 200, 200, 166, 200, 200, 200]}, 'sampler_perf': {'mean_env_wait_ms': 0.048612345098100855, 'mean_processing_ms': 0.125470891129422, 'mean_inference_ms': 0.6101233420242141}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 27776, 'num_steps_sampled': 28000, 'sample_time_ms': 1814.303, 'load_time_ms': 8.501, 'grad_time_ms': 1801.81, 'update_time_ms': 75.112, 'learner': {'default_policy': {'cur_kl_coeff': 0.15000000596046448, 'cur_lr': 4.999999873689376e-05, 'total_loss': 311.08255, 'policy_loss': -0.0015405463, 'vf_loss': 311.0833, 'vf_explained_var': 0.34770983, 'kl': 0.004711054, 'entropy': 0.5144471, 'entropy_coeff': 0.0, 'model': {}}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 28000, 'episodes_total': 413, 'training_iteration': 7, 'experiment_id': 'ef6533da38f340edadc19202698a4949', 'date': '2020-05-01_12-01-43', 'timestamp': 1588359703, 'time_this_iter_s': 3.0068418979644775, 'time_total_s': 25.96090602874756, 'pid': 27290, 'hostname': 'DWAnyscaleMBP.local', 'node_ip': '192.168.1.149', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'use_exec_api': False, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 25.96090602874756, 'timesteps_since_restore': 28000, 'iterations_since_restore': 7, 'perf': {'cpu_util_percent': 48.8, 'ram_util_percent': 65.61999999999999}, 'num_healthy_workers': 2}\n",
      "\n",
      "tmp/ppo/cart/checkpoint_7/checkpoint-7\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 34.0, 'episode_reward_mean': 186.75, 'episode_len_mean': 186.75, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 160.0, 34.0, 124.0, 191.0, 200.0, 200.0, 145.0, 184.0, 138.0, 145.0, 196.0, 200.0, 176.0, 154.0, 200.0, 108.0, 162.0, 200.0, 132.0, 60.0, 200.0, 200.0, 130.0, 200.0, 137.0, 200.0, 200.0, 123.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 171.0, 122.0, 200.0, 178.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 166.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 160, 34, 124, 191, 200, 200, 145, 184, 138, 145, 196, 200, 176, 154, 200, 108, 162, 200, 132, 60, 200, 200, 130, 200, 137, 200, 200, 123, 200, 200, 179, 200, 200, 200, 171, 122, 200, 178, 182, 200, 200, 200, 200, 200, 200, 200, 200, 200, 178, 200, 200, 200, 200, 200, 200, 200, 166, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_env_wait_ms': 0.04822206730396681, 'mean_processing_ms': 0.12358250719048547, 'mean_inference_ms': 0.6029476516133502}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 31744, 'num_steps_sampled': 32000, 'sample_time_ms': 1762.502, 'load_time_ms': 7.565, 'grad_time_ms': 1774.575, 'update_time_ms': 66.081, 'learner': {'default_policy': {'cur_kl_coeff': 0.07500000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 328.64536, 'policy_loss': -0.0058892225, 'vf_loss': 328.65067, 'vf_explained_var': 0.31739068, 'kl': 0.0074051344, 'entropy': 0.5386504, 'entropy_coeff': 0.0, 'model': {}}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 32000, 'episodes_total': 433, 'training_iteration': 8, 'experiment_id': 'ef6533da38f340edadc19202698a4949', 'date': '2020-05-01_12-01-46', 'timestamp': 1588359706, 'time_this_iter_s': 2.990546941757202, 'time_total_s': 28.95145297050476, 'pid': 27290, 'hostname': 'DWAnyscaleMBP.local', 'node_ip': '192.168.1.149', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'use_exec_api': False, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 28.95145297050476, 'timesteps_since_restore': 32000, 'iterations_since_restore': 8, 'perf': {'cpu_util_percent': 48.050000000000004, 'ram_util_percent': 65.72500000000001}, 'num_healthy_workers': 2}\n",
      "\n",
      "tmp/ppo/cart/checkpoint_8/checkpoint-8\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 122.0, 'episode_reward_mean': 195.66, 'episode_len_mean': 195.66, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 130.0, 200.0, 137.0, 200.0, 200.0, 123.0, 200.0, 200.0, 179.0, 200.0, 200.0, 200.0, 171.0, 122.0, 200.0, 178.0, 182.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 166.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 130, 200, 137, 200, 200, 123, 200, 200, 179, 200, 200, 200, 171, 122, 200, 178, 182, 200, 200, 200, 200, 200, 200, 200, 200, 200, 178, 200, 200, 200, 200, 200, 200, 200, 166, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_env_wait_ms': 0.04769168124533255, 'mean_processing_ms': 0.12166046811846241, 'mean_inference_ms': 0.5945926701690134}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 35712, 'num_steps_sampled': 36000, 'sample_time_ms': 1723.327, 'load_time_ms': 6.845, 'grad_time_ms': 1757.789, 'update_time_ms': 59.01, 'learner': {'default_policy': {'cur_kl_coeff': 0.07500000298023224, 'cur_lr': 4.999999873689376e-05, 'total_loss': 344.33188, 'policy_loss': -0.0021770506, 'vf_loss': 344.3338, 'vf_explained_var': 0.26294574, 'kl': 0.0034189841, 'entropy': 0.5022357, 'entropy_coeff': 0.0, 'model': {}}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 36000, 'episodes_total': 453, 'training_iteration': 9, 'experiment_id': 'ef6533da38f340edadc19202698a4949', 'date': '2020-05-01_12-01-49', 'timestamp': 1588359709, 'time_this_iter_s': 3.0396840572357178, 'time_total_s': 31.99113702774048, 'pid': 27290, 'hostname': 'DWAnyscaleMBP.local', 'node_ip': '192.168.1.149', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'use_exec_api': False, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 31.99113702774048, 'timesteps_since_restore': 36000, 'iterations_since_restore': 9, 'perf': {'cpu_util_percent': 37.900000000000006, 'ram_util_percent': 65.67499999999998}, 'num_healthy_workers': 2}\n",
      "\n",
      "tmp/ppo/cart/checkpoint_9/checkpoint-9\n",
      "{'episode_reward_max': 200.0, 'episode_reward_min': 166.0, 'episode_reward_mean': 199.16, 'episode_len_mean': 199.16, 'episodes_this_iter': 20, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 172.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 178.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 166.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0], 'episode_lengths': [200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 172, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 178, 200, 200, 200, 200, 200, 200, 200, 166, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200]}, 'sampler_perf': {'mean_env_wait_ms': 0.04717476206578082, 'mean_processing_ms': 0.12002083821809618, 'mean_inference_ms': 0.5871343885292986}, 'off_policy_estimator': {}, 'info': {'num_steps_trained': 39680, 'num_steps_sampled': 40000, 'sample_time_ms': 1699.044, 'load_time_ms': 6.279, 'grad_time_ms': 1745.511, 'update_time_ms': 53.383, 'learner': {'default_policy': {'cur_kl_coeff': 0.03750000149011612, 'cur_lr': 4.999999873689376e-05, 'total_loss': 256.88522, 'policy_loss': -0.0058996123, 'vf_loss': 256.8909, 'vf_explained_var': 0.42711163, 'kl': 0.0065117613, 'entropy': 0.49951756, 'entropy_coeff': 0.0, 'model': {}}}}, 'timesteps_this_iter': 4000, 'done': False, 'timesteps_total': 40000, 'episodes_total': 473, 'training_iteration': 10, 'experiment_id': 'ef6533da38f340edadc19202698a4949', 'date': '2020-05-01_12-01-53', 'timestamp': 1588359713, 'time_this_iter_s': 3.1224682331085205, 'time_total_s': 35.113605260849, 'pid': 27290, 'hostname': 'DWAnyscaleMBP.local', 'node_ip': '192.168.1.149', 'config': {'num_workers': 2, 'num_envs_per_worker': 1, 'rollout_fragment_length': 200, 'sample_batch_size': -1, 'batch_mode': 'truncate_episodes', 'num_gpus': 0, 'train_batch_size': 4000, 'model': {'conv_filters': None, 'conv_activation': 'relu', 'fcnet_activation': 'tanh', 'fcnet_hiddens': [256, 256], 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action_reward': False, 'state_shape': None, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_action_dist': None, 'custom_options': {}, 'custom_preprocessor': None}, 'optimizer': {}, 'gamma': 0.99, 'horizon': None, 'soft_horizon': False, 'no_done_at_end': False, 'env_config': {}, 'env': 'CartPole-v0', 'normalize_actions': False, 'clip_rewards': None, 'clip_actions': True, 'preprocessor_pref': 'deepmind', 'lr': 5e-05, 'monitor': False, 'log_level': 'WARN', 'callbacks': {'on_episode_start': None, 'on_episode_step': None, 'on_episode_end': None, 'on_sample_end': None, 'on_train_result': None, 'on_postprocess_traj': None}, 'ignore_worker_failures': False, 'log_sys_usage': True, 'use_pytorch': False, 'eager': False, 'eager_tracing': False, 'no_eager_on_workers': False, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'evaluation_interval': None, 'evaluation_num_episodes': 10, 'in_evaluation': False, 'evaluation_config': {}, 'evaluation_num_workers': 0, 'custom_eval_function': None, 'use_exec_api': False, 'sample_async': False, 'observation_filter': 'NoFilter', 'synchronize_filters': True, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'compress_observations': False, 'collect_metrics_timeout': 180, 'metrics_smoothing_episodes': 100, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'min_iter_time_s': 0, 'timesteps_per_iteration': 0, 'seed': None, 'num_cpus_per_worker': 1, 'num_gpus_per_worker': 0, 'custom_resources_per_worker': {}, 'num_cpus_for_driver': 1, 'memory': 0, 'object_store_memory': 0, 'memory_per_worker': 0, 'object_store_memory_per_worker': 0, 'input': 'sampler', 'input_evaluation': ['is', 'wis'], 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'multiagent': {'policies': {}, 'policy_mapping_fn': None, 'policies_to_train': None}, 'use_critic': True, 'use_gae': True, 'lambda': 1.0, 'kl_coeff': 0.2, 'sgd_minibatch_size': 128, 'shuffle_sequences': True, 'num_sgd_iter': 30, 'lr_schedule': None, 'vf_share_layers': False, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'grad_clip': None, 'kl_target': 0.01, 'simple_optimizer': False}, 'time_since_restore': 35.113605260849, 'timesteps_since_restore': 40000, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': 50.760000000000005, 'ram_util_percent': 65.7}, 'num_healthy_workers': 2}\n",
      "\n",
      "tmp/ppo/cart/checkpoint_10/checkpoint-10\n"
     ]
    }
   ],
   "source": [
    "SELECT_ENV = \"CartPole-v0\"\n",
    "N_ITER = 10\n",
    "\n",
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "config[\"log_level\"] = \"WARN\"\n",
    "\n",
    "reward_history = []\n",
    "\n",
    "agent = ppo.PPOTrainer(config, env=select_env)\n",
    "\n",
    "for _ in range(N_ITER):\n",
    "    result = agent.train()\n",
    "    print(result)\n",
    "\n",
    "    max_reward = result[\"episode_reward_max\"]\n",
    "    reward_history.append(max_reward)\n",
    "\n",
    "    file_name = agent.save('/tmp/ppo/cart')\n",
    "    print(f'\\ncheckpoint saved to {file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.0, 96.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0, 200.0]\n"
     ]
    }
   ],
   "source": [
    "print(reward_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gp1LgeCJjGLk"
   },
   "source": [
    "Do the episode rewards increase after multiple iterations?\n",
    "That shows how the policy is improving.\n",
    "\n",
    "Also, print out the policy and model to see the results of training in detail…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'default_policy/fc_1/kernel:0' shape=(4, 256) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_1/bias:0' shape=(256,) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_value_1/kernel:0' shape=(4, 256) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_value_1/bias:0' shape=(256,) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_2/kernel:0' shape=(256, 256) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_2/bias:0' shape=(256,) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_value_2/kernel:0' shape=(256, 256) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_value_2/bias:0' shape=(256,) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_out/kernel:0' shape=(256, 2) dtype=float32>,\n",
      " <tf.Variable 'default_policy/fc_out/bias:0' shape=(2,) dtype=float32>,\n",
      " <tf.Variable 'default_policy/value_out/kernel:0' shape=(256, 1) dtype=float32>,\n",
      " <tf.Variable 'default_policy/value_out/bias:0' shape=(1,) dtype=float32>]\n",
      "<tf.Tensor 'Reshape:0' shape=(?,) dtype=float32>\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "observations (InputLayer)       [(None, 4)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "fc_1 (Dense)                    (None, 256)          1280        observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc_value_1 (Dense)              (None, 256)          1280        observations[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "fc_2 (Dense)                    (None, 256)          65792       fc_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "fc_value_2 (Dense)              (None, 256)          65792       fc_value_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "fc_out (Dense)                  (None, 2)            514         fc_2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "value_out (Dense)               (None, 1)            257         fc_value_2[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 134,915\n",
      "Trainable params: 134,915\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "policy = agent.get_policy()\n",
    "model = policy.model\n",
    "\n",
    "pprint.pprint(model.variables())\n",
    "pprint.pprint(model.value_function())\n",
    "\n",
    "print(model.base_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use the [`rollout` script](https://ray.readthedocs.io/en/latest/rllib-training.html#evaluating-trained-policies), using the `rllib rollout` command line, to evaluate the trained policy.\n",
    "\n",
    "This visualizes the \"cartpole\" agent operating within the simulation: moving the cart left or right to avoid having the pole fall over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-01 12:08:49,808\tINFO resource_spec.py:212 -- Starting Ray with 4.3 GiB memory available for workers and up to 2.16 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-05-01 12:08:50,119\tINFO services.py:1148 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8266\u001b[39m\u001b[22m\n",
      "2020-05-01 12:08:50,771\tINFO trainer.py:428 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "2020-05-01 12:08:50,799\tINFO trainer.py:585 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2020-05-01 12:08:53,763\tINFO trainable.py:217 -- Getting current IP.\n",
      "2020-05-01 12:08:53,763\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "2020-05-01 12:08:53,828\tINFO trainable.py:217 -- Getting current IP.\n",
      "2020-05-01 12:08:53,829\tINFO trainable.py:423 -- Restored on 192.168.1.149 from checkpoint: /tmp/ppo/cart/checkpoint_2/checkpoint-2\n",
      "2020-05-01 12:08:53,829\tINFO trainable.py:430 -- Current state after restoring: {'_iteration': 2, '_timesteps_total': 8000, '_time_total': 9.411438941955566, '_episodes_total': 281}\n",
      "Episode #0: reward: 41.0\n",
      "Episode #1: reward: 78.0\n",
      "Episode #2: reward: 42.0\n",
      "Episode #3: reward: 135.0\n",
      "Episode #4: reward: 32.0\n",
      "Episode #5: reward: 62.0\n",
      "Episode #6: reward: 20.0\n",
      "Episode #7: reward: 26.0\n",
      "Episode #8: reward: 200.0\n",
      "Episode #9: reward: 117.0\n",
      "Episode #10: reward: 161.0\n",
      "Episode #11: reward: 160.0\n",
      "Episode #12: reward: 146.0\n",
      "Episode #13: reward: 110.0\n",
      "Episode #14: reward: 60.0\n",
      "Episode #15: reward: 81.0\n",
      "Episode #16: reward: 146.0\n",
      "Episode #17: reward: 124.0\n",
      "Episode #18: reward: 128.0\n",
      "Episode #19: reward: 131.0\n"
     ]
    }
   ],
   "source": [
    "! rllib rollout \\\n",
    "    /tmp/ppo/cart/checkpoint_2/checkpoint-2 \\\n",
    "    --config \"{\\\"env\\\": \\\"CartPole-v0\\\"}\" --run PPO \\\n",
    "    --steps 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tI9vJ1vU6Mj1"
   },
   "source": [
    "The rollout uses the second saved checkpoint, evaluated through `2000` steps.\n",
    "Modify the path to view other checkpoints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tI9vJ1vU6Mj1"
   },
   "source": [
    "Finally, launch [TensorBoard](https://ray.readthedocs.io/en/latest/rllib-training.html#getting-started) then follow the instructions (for example, click the URL link or copy and paste it into a browser) to visualize key metrics from training with RLlib…\n",
    "\n",
    "TODO: explain what to do with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.1.1 at http://localhost:6007/ (Press CTRL+C to quit)\n",
      "W0501 12:15:52.709307 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-11-39yyf7qw4j: No event timestamp could be found\n",
      "W0501 12:15:52.711589 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-21-05wb9qng9p: No event timestamp could be found\n",
      "W0501 12:15:52.713537 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-43-39ai8xvs0i: No event timestamp could be found\n",
      "W0501 12:15:52.724436 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_10-29-417oh9pqog: No event timestamp could be found\n",
      "W0501 12:15:52.741851 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_11-06-505qt757lc: No event timestamp could be found\n",
      "W0501 12:15:52.747407 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-05-437fff6xkf: No event timestamp could be found\n",
      "W0501 12:15:52.749470 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-06-412sevc6zc: No event timestamp could be found\n",
      "W0501 12:15:52.751634 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-08-50sz27wf08: No event timestamp could be found\n",
      "W0501 12:16:23.530768 123145380827136 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-11-39yyf7qw4j: No event timestamp could be found\n",
      "W0501 12:16:23.536365 123145380827136 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-21-05wb9qng9p: No event timestamp could be found\n",
      "W0501 12:16:23.537801 123145380827136 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-43-39ai8xvs0i: No event timestamp could be found\n",
      "W0501 12:16:23.539200 123145380827136 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_10-29-417oh9pqog: No event timestamp could be found\n",
      "W0501 12:16:23.540142 123145380827136 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_11-06-505qt757lc: No event timestamp could be found\n",
      "W0501 12:16:23.540992 123145380827136 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-05-437fff6xkf: No event timestamp could be found\n",
      "W0501 12:16:23.542043 123145380827136 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-06-412sevc6zc: No event timestamp could be found\n",
      "W0501 12:16:23.542970 123145380827136 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-08-50sz27wf08: No event timestamp could be found\n",
      "W0501 12:16:54.056978 123145375571968 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-11-39yyf7qw4j: No event timestamp could be found\n",
      "W0501 12:16:54.060474 123145375571968 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-21-05wb9qng9p: No event timestamp could be found\n",
      "W0501 12:16:54.061834 123145375571968 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-43-39ai8xvs0i: No event timestamp could be found\n",
      "W0501 12:16:54.063001 123145375571968 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_10-29-417oh9pqog: No event timestamp could be found\n",
      "W0501 12:16:54.063804 123145375571968 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_11-06-505qt757lc: No event timestamp could be found\n",
      "W0501 12:16:54.064845 123145375571968 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-05-437fff6xkf: No event timestamp could be found\n",
      "W0501 12:16:54.065619 123145375571968 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-06-412sevc6zc: No event timestamp could be found\n",
      "W0501 12:16:54.066574 123145375571968 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-08-50sz27wf08: No event timestamp could be found\n",
      "W0501 12:17:25.332604 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-11-39yyf7qw4j: No event timestamp could be found\n",
      "W0501 12:17:25.333920 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-21-05wb9qng9p: No event timestamp could be found\n",
      "W0501 12:17:25.334986 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-03-26_15-43-39ai8xvs0i: No event timestamp could be found\n",
      "W0501 12:17:25.335863 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_10-29-417oh9pqog: No event timestamp could be found\n",
      "W0501 12:17:25.336776 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_11-06-505qt757lc: No event timestamp could be found\n",
      "W0501 12:17:25.337690 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-05-437fff6xkf: No event timestamp could be found\n",
      "W0501 12:17:25.338494 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-06-412sevc6zc: No event timestamp could be found\n",
      "W0501 12:17:25.339294 123145370316800 core_plugin.py:200] Unable to get first event timestamp for run PPO_CartPole-v0_2020-05-01_12-08-50sz27wf08: No event timestamp could be found\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=~/ray_results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, go through any of the following lessons:\n",
    "\n",
    "* [04a: Application: Mountain Car](04a-Application-Mountain-Car.ipynb) -- Based on the `MountainCar-v0` environment from OpenAI Gym.\n",
    "* [04b: Application: Taxi](04b-Application-Taxi.ipynb) -- Based on the `Taxi-v3` environment from OpenAI Gym.\n",
    "* [04c: Application: Frozen Lake](04c-Application-Frozen-Lake.ipynb) -- Based on the `FrozenLake-v0` environment from OpenAI Gym."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of rllib_ppo_dqn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
