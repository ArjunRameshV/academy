{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Ray API Calls\n",
    "\n",
    "To finish our tutorial on the core features of Ray, this lesson explores a few of the other API calls you might find useful, as well as options that can be used with the API calls we've already learned.\n",
    "\n",
    "> **Tip:** The [Ray Package Reference](https://ray.readthedocs.io/en/latest/package-ref.html) in the [Ray Docs](https://ray.readthedocs.io/en/latest/) is useful for exploring the API features we'll learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray, time, sys\n",
    "sys.path.append('..')  \n",
    "from util.printing import pnd, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-10 12:23:48,634\tINFO resource_spec.py:204 -- Starting Ray with 4.25 GiB memory available for workers and up to 2.13 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-04-10 12:23:48,984\tINFO services.py:1146 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.149',\n",
       " 'redis_address': '192.168.1.149:49277',\n",
       " 'object_store_address': '/tmp/ray/session_2020-04-10_12-23-48_623844_55305/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-04-10_12-23-48_623844_55305/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-04-10_12-23-48_623844_55305'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ray.init()\n",
    "\n",
    "[`ray.init()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.init) has a lot of keyword arguments you can pass. Here are some of them.\n",
    "\n",
    "| Name | Type | Example | Description |\n",
    "| :--- | :--- | :------ | :---------- |\n",
    "| `address` | `str` | `address='auto'` | The address of the Ray cluster to connect to. If this address is not provided, then this command will start Redis, a raylet, a plasma store, a plasma manager, and some workers. It will also kill these processes when Python exits. Using `auto` on a node in a Ray cluster connects to the cluster. |\n",
    "| `num_cpus` | `int` | `num_cpus=4` | Each _raylet_ should be configured with this number of CPU cores. |\n",
    "| `num_gpus` | `int` | `num_gpus=1` | Each _raylet_ should be configured with this number of GPU cores. |\n",
    "| `memory` | `int` | `memory=1000000000` | The amount of memory (in bytes) that is available for use by workers requesting memory resources. By default, this is automatically set based on the available system memory. |\n",
    "| `object_store_memory` | `int` | `object_store_memory=1000000000` | The amount of memory (in bytes) for the object store. By default, this is automatically set based on available system memory, subject to a 20GB cap. |\n",
    "| `log_to_driver` | `bool` | `log_to_driver=True` | If true, then output from all of the worker processes on all nodes will be directed to the driver program. |\n",
    "| `local_mode` | `bool` | `local_mode=True` | Use `True` if the code should be executed serially. This is useful for debugging. |\n",
    "| `ignore_reinit_error` | `bool` | `ignore_reinit_error=True` | `True` if we should suppress errors from calling `ray.init()` a second time, as we've done in these notebooks. |\n",
    "| `include_webui` | `bool` | `include_webui=False` | Boolean flag indicating whether to start the web UI, which displays the status of the Ray cluster. Bt default, or if this argument is `None`, then the UI will be started if the relevant dependencies are present. |\n",
    "| `configure_logging` | `bool` | `configure_logging=True` | True if allow the logging cofiguration here. Otherwise, the users may want to configure it by their own. |\n",
    "| `logging_level` | _Flag_ | `logging_level=logging.INFO` | Logging level, defaults to `logging.INFO`. |\n",
    "| `logging_format` | `str` | `logging_format='...'` | The logging format to use, defaults to a string containing a timestamp, filename, line number, and message. See in the Ray source code `ray_constants.py` for details. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ray.is_initialized()\n",
    "\n",
    "Is Ray [initialized](https://ray.readthedocs.io/en/latest/package-ref.html#ray.is_initialized)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.is_initialized()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @ray.remote()\n",
    "\n",
    "We've used [@ray.remote](https://ray.readthedocs.io/en/latest/package-ref.html#ray.remote) a lot. You can pass arguments when using it. Here are some of them.\n",
    "\n",
    "| Name | Type | Example | Description |\n",
    "| :--- | :--- | :------ | :---------- |\n",
    "| `num_cpus` | `int` | `num_cpus=4` | The number of CPU cores to reserve for this task or for the lifetime of the actor. |\n",
    "| `num_gpus` | `int` | `num_gpus=1` | The number of GPU cores to reserve for this task or for the lifetime of the actor. |\n",
    "| `num_return_vals` | `int` | `num_return_vals=2` | (only for remote functions/tasks, not actors) The number of object IDs returned by the remote function invocation. |\n",
    "| `max_calls` | `int` | `max_calls=5` | (only for remote functions) The maximum number of times that a given worker can execute the given remote function before it must exit (this can be used to address memory leaks in third-party libraries or to reclaim resources that cannot easily be released, e.g., GPU memory that was acquired by TensorFlow). By default this is infinite. |\n",
    "| `max_reconstructions` | `int` | `max_reconstructions=4` | (only for actors) The maximum number of times that the actor should be reconstructed when it dies unexpectedly. The minimum valid value is 0 (default), which indicates that the actor doesnâ€™t need to be reconstructed. And the maximum valid value is `ray.ray_constants.INFINITE_RECONSTRUCTION`. |\n",
    "| `max_retries` | `int` | `max_retries=5` | (only for remote functions) The maximum number of times that the remote function should be rerun when the worker process executing it crashes unexpectedly. The minimum valid value is 0, the default is 4 (default), and the maximum valid value is `ray.ray_constants.INFINITE_RECONSTRUCTION`. |\n",
    "\n",
    "What is `ray.ray_constants.INFINITE_RECONSTRUCTION`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073741824"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.ray_constants.INFINITE_RECONSTRUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## @ray.method()\n",
    "\n",
    "here is a similar [`ray.method()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.method) used to annotate methods in actors. Its only purpose is to provide the same optional arguments available for `ray.remote()`, when needed. Otherwise, methods in an actor are called just as we described in lesson 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ray.get()\n",
    "\n",
    "We used [`ray.get`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.gett) a lot to retrieve objects and we used actor methods to retrieve state from an actor. You can actually put objects into the object store explicitly with [`ray.put`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.put), as shown in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object returned: Hello World!\n"
     ]
    }
   ],
   "source": [
    "id = ray.put(\"Hello World!\")\n",
    "print(f'Object returned: {ray.get(id)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an optional flag you can pass `weakref=True` (defaults to `False`). If set, Ray is allowed to evict the object while a reference to the returned ID still exists. This is useful if you are putting a lot of objects into the object store and many of them might not be needed in the future. It allows Ray to more aggressively reclaim memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ray.kill(actor)\n",
    "\n",
    "Sometimes it might be necessary to terminate an actor. Use [`ray.kill(actor)`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.kill) for this purpose.\n",
    "It will interrupt any running tasks on the actor, causing them to fail immediately. Any [`atexit`](https://docs.python.org/3/library/atexit.html) handlers installed in the actor process will still be run.\n",
    "\n",
    "If you want to kill the actor but let pending tasks finish, you can call `actor.__ray_terminate__.remote()` instead to queue a termination task.\n",
    "\n",
    "If this actor is reconstructable, reconstruction will be attempted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Information\n",
    "\n",
    "Many methods return information:\n",
    "\n",
    "| Method | Brief Description |\n",
    "| :----- | :---------------- |\n",
    "| [`ray.get_gpu_ids()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.get_gpu_ids) | GPUs |\n",
    "| [`ray.get_resource_ids()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.get_resource_ids) | Resources available to the _worker_ |\n",
    "| [`ray.get_webui_url()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.get_webui_url) | Ray Dashboard URL |\n",
    "| [`ray.nodes()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.nodes) | Cluster nodes |\n",
    "| [`ray.objects()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.objects) | Objects currently in the Object Store |\n",
    "| [`ray.cluster_resources()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.cluster_resources) | All the available resources, used or not |\n",
    "| [`ray.available_resources()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.available_resources) | Resources not in use |\n",
    "| [`ray.errors()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.errors) | What errrors have occurred for this job (use `all_jobs=True` for all) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ray.get_gpu_ids():          []\n",
      "ray.get_resource_ids():     {}\n",
      "ray.get_webui_url():        localhost:8265\n",
      "ray.nodes():                [{'NodeID': 'eaff91c6b430b8ae6d1c92703c4b0095f0523b78', 'Alive': True, 'NodeManagerAddress': '192.168.1.149', 'NodeManagerHostname': 'DWAnyscaleMBP.local', 'NodeManagerPort': 53569, 'ObjectManagerPort': 53600, 'ObjectStoreSocketName': '/tmp/ray/session_2020-04-10_12-23-48_623844_55305/sockets/plasma_store', 'RayletSocketName': '/tmp/ray/session_2020-04-10_12-23-48_623844_55305/sockets/raylet', 'Resources': {'object_store_memory': 30.0, 'CPU': 8.0, 'node:192.168.1.149': 1.0, 'memory': 87.0}, 'alive': True}]\n",
      "ray.objects():              {ObjectID(ffffffffffffffffffffffff0100008801000000): {'DataSize': 0, 'Manager': b'\\xea\\xff\\x91\\xc6\\xb40\\xb8\\xaem\\x1c\\x92p<K\\x00\\x95\\xf0R;x'}}\n",
      "ray.cluster_resources():    {'object_store_memory': 30.0, 'CPU': 8.0, 'node:192.168.1.149': 1.0, 'memory': 87.0}\n",
      "ray.available_resources():  {'memory': 87.0, 'node:192.168.1.149': 1.0, 'object_store_memory': 30.0, 'CPU': 8.0}\n",
      "ray.errors():               {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "ray.get_gpu_ids():          {ray.get_gpu_ids()}\n",
    "ray.get_resource_ids():     {ray.get_resource_ids()}\n",
    "ray.get_webui_url():        {ray.get_webui_url()}\n",
    "ray.nodes():                {ray.nodes()}\n",
    "ray.objects():              {ray.objects()}\n",
    "ray.cluster_resources():    {ray.cluster_resources()}\n",
    "ray.available_resources():  {ray.available_resources()}\n",
    "ray.errors():               {ray.errors(all_jobs=True)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we used `ray.nodes()[0]['Resources']['CPU']` in the second lesson to determine the number of CPU cores on our machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "ray.nodes()[0]['Resources']['CPU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ray.shutdown()\n",
    "\n",
    "You don't always need to call it explicitly, but [`ray.shutdown()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.shutdown) will disconnect the worker, and terminate processes started by `ray.init()`.\n",
    "\n",
    "It is automatically run at the end when a Python process that uses Ray exits. It is okay to run this twice in a row. The primary use case for this function is to cleanup state between tests.\n",
    "\n",
    "Note that this will clear any remote function definitions, actor definitions, and existing actors, so if you wish to use any previously defined remote functions or actors after calling `ray.shutdown()`, then you need to redefine them. If they were defined in an imported module, then you will need to reload the module.\n",
    "\n",
    "There is one optional parameter, `exiting_interpreter=True|False`. `True` is passed when `ray.shutdown()` is called by the `atexit` hook and `False` otherwise. If Ray is exiting the interpreter, it waits a little while to print any extra error messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ray.timeline()\n",
    "\n",
    "Sometimes you need to find where the bottlenecks are. [`ray.timeline()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.timeline) helps. It returns a list of profiling events that can viewed as a timeline. To use the results, the easiest method is to dump the data to a JSON file by passing in `filename=...` argument. Or, you can call `json.dump(filename)` on the returned object. In either case, then open chrome://tracing in a Chrome browser window (only Chrome works) and load the dumped file. Try examing the following file (but the output will be boring at the moment):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.timeline(filename = '../tmp/timeline-example.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ray.object_transfer_timeline()\n",
    "\n",
    "The related [`ray.object_transfer_timeline()`](https://ray.readthedocs.io/en/latest/package-ref.html#ray.object_transfer_timeline) returns events for objects moved between nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
