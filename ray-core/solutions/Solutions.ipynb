{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions to exercises in the `ray-core` Lessons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import everything we'll need and start Ray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray, time, sys\n",
    "import numpy as np\n",
    "sys.path.append('../..')\n",
    "from util.printing import pnd, pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-07 08:02:48,921\tINFO resource_spec.py:204 -- Starting Ray with 4.44 GiB memory available for workers and up to 2.23 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-04-07 08:02:49,274\tINFO services.py:1146 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8266\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.149',\n",
       " 'redis_address': '192.168.1.149:26771',\n",
       " 'object_store_address': '/tmp/ray/session_2020-04-07_08-02-48_912726_63557/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-04-07_08-02-48_912726_63557/sockets/raylet',\n",
       " 'webui_url': 'localhost:8266',\n",
       " 'session_dir': '/tmp/ray/session_2020-04-07_08-02-48_912726_63557'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 in 02-TaskParallelism-Part1\n",
    "\n",
    "You were asked to convert the regular Python code to Ray code. Here are the three cells appropriately modified.\n",
    "\n",
    "First, we need the appropriate imports and `ray.init()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def slow_square(n):\n",
    "    time.sleep(n)\n",
    "    return n*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "ids = [slow_square.remote(n) for n in range(4)]\n",
    "squares = ray.get(ids)\n",
    "duration = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert squares == [0, 1, 4, 9]\n",
    "# should fail until the code modifications are made:\n",
    "assert duration < 4.1, f'duration = {duration}' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 in 03-TaskParallelism-Part2\n",
    "\n",
    "You were asked to use `ray.wait()` with a shorter timeout, `2.5` seconds. First we need to redefine in this notebook the remote functions we used in that lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def make_array(n):\n",
    "    time.sleep(n/10.0)\n",
    "    return np.random.standard_normal(n)\n",
    "\n",
    "@ray.remote\n",
    "def add_arrays(a1, a2):\n",
    "    time.sleep(a1.size/10.0)\n",
    "    return np.add(a1, a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned   2 completed tasks. (elapsed time:  2.021)\n",
      "0: []\n",
      "10: [ 3.95318532  1.95703209 -1.77142106  0.48401556 -3.66004368  1.65002282\n",
      "  3.51581126 -0.62342501 -1.43977852 -0.19810529]\n",
      "Returned   1 completed tasks. (elapsed time:  5.533)\n",
      "20: [ 1.38744086 -1.84890282  1.76892294  0.88618333 -0.45441002 -0.74875324\n",
      " -0.68359449  1.35974112 -2.72374048 -1.6864953   0.17671172  1.99400488\n",
      "  1.53733697 -1.47867413 -0.51142734 -2.19978562 -3.49982821  1.07790542\n",
      " -0.38826834  1.69827754]\n",
      "Returned   2 completed tasks. (elapsed time:  8.014)\n",
      "30: [ 1.13530849 -4.07447539  0.30959073  1.30257747  0.95060131 -3.05474103\n",
      "  2.05413706  3.70526873 -1.9819779   0.52198044 -2.42485218  2.79255394\n",
      "  0.244146    4.65404811  2.62351162  1.31775663  3.4565208   2.13435246\n",
      "  2.05918341 -0.40861993 -1.87624159 -0.52302686 -0.45058515  0.73924722\n",
      "  1.04711594 -0.14052396  2.60024071 -0.51780442 -5.92163164 -0.94569481]\n",
      "40: [ 0.75586819 -0.23227869 -1.09352479 -0.63175279  1.81580443  1.00967837\n",
      "  2.73164613 -0.76729172  0.15852797 -0.63161731  3.11799318 -0.82320063\n",
      " -3.47297453 -4.08071441  4.41191857  1.94677487  2.12247008  2.33309615\n",
      "  2.18488046 -0.99478113 -0.49590528  1.68252378  1.86507192 -2.36593973\n",
      " -1.61082161 -2.17791427  1.6361454  -3.4963533   0.49183329  2.65500718\n",
      "  0.67533248 -0.18600865  3.15706281 -0.41840903  1.57932327  0.50417131\n",
      "  1.58439188  1.10238143  2.30020779 -0.87461155]\n",
      "\n",
      "all arrays: [array([], dtype=float64), array([ 3.95318532,  1.95703209, -1.77142106,  0.48401556, -3.66004368,\n",
      "        1.65002282,  3.51581126, -0.62342501, -1.43977852, -0.19810529]), array([ 1.38744086, -1.84890282,  1.76892294,  0.88618333, -0.45441002,\n",
      "       -0.74875324, -0.68359449,  1.35974112, -2.72374048, -1.6864953 ,\n",
      "        0.17671172,  1.99400488,  1.53733697, -1.47867413, -0.51142734,\n",
      "       -2.19978562, -3.49982821,  1.07790542, -0.38826834,  1.69827754]), array([ 1.13530849, -4.07447539,  0.30959073,  1.30257747,  0.95060131,\n",
      "       -3.05474103,  2.05413706,  3.70526873, -1.9819779 ,  0.52198044,\n",
      "       -2.42485218,  2.79255394,  0.244146  ,  4.65404811,  2.62351162,\n",
      "        1.31775663,  3.4565208 ,  2.13435246,  2.05918341, -0.40861993,\n",
      "       -1.87624159, -0.52302686, -0.45058515,  0.73924722,  1.04711594,\n",
      "       -0.14052396,  2.60024071, -0.51780442, -5.92163164, -0.94569481]), array([ 0.75586819, -0.23227869, -1.09352479, -0.63175279,  1.81580443,\n",
      "        1.00967837,  2.73164613, -0.76729172,  0.15852797, -0.63161731,\n",
      "        3.11799318, -0.82320063, -3.47297453, -4.08071441,  4.41191857,\n",
      "        1.94677487,  2.12247008,  2.33309615,  2.18488046, -0.99478113,\n",
      "       -0.49590528,  1.68252378,  1.86507192, -2.36593973, -1.61082161,\n",
      "       -2.17791427,  1.6361454 , -3.4963533 ,  0.49183329,  2.65500718,\n",
      "        0.67533248, -0.18600865,  3.15706281, -0.41840903,  1.57932327,\n",
      "        0.50417131,  1.58439188,  1.10238143,  2.30020779, -0.87461155])]\n",
      "Total time: duration:  8.020 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "array_ids = [make_array.remote(n*10) for n in range(5)]\n",
    "added_array_ids = [add_arrays.remote(id, id) for id in array_ids]\n",
    "\n",
    "arrays = []\n",
    "waiting_ids = list(added_array_ids)        # Assign a working list to the full list of ids\n",
    "while len(waiting_ids) > 0:                # Loop until all tasks have completed\n",
    "    # Call ray.wait with:\n",
    "    #   1. the list of ids we're still waiting to complete,\n",
    "    #   2. tell it to return immediately as soon as TWO of them complete,\n",
    "    #   3. tell it wait up to 10 seconds before timing out.\n",
    "    return_n = 2 if len(waiting_ids) > 1 else 1\n",
    "    ready_ids, remaining_ids = ray.wait(waiting_ids, num_returns=return_n, timeout=2.5)\n",
    "    print('Returned {:3d} completed tasks. (elapsed time: {:6.3f})'.format(len(ready_ids), time.time() - start))\n",
    "    new_arrays = ray.get(ready_ids)\n",
    "    arrays.extend(new_arrays)\n",
    "    for array in new_arrays:\n",
    "        print(f'{array.size}: {array}')\n",
    "    waiting_ids = remaining_ids  # Reset this list; don't include the completed ids in the list again!\n",
    "    \n",
    "print(f\"\\nall arrays: {arrays}\")\n",
    "pd(time.time() - start, prefix=\"Total time:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a timeout of `2.5` seconds, the second call to `ray.wait()` times out before two tasks finish, so it only returns one completed task. Why did the third and last iteration not time out? (That is, they both successfully returned two items.) It's because all the tasks were running in parallel so they had time to finish. If you use a shorter timeout, you'll see more time outs, where zero or one items are returned. \n",
    "\n",
    "Try `1.5` seconds, where all but one iteration times out and returns one item. The first iteration returns two items.\n",
    "Try `0.5` seconds, where you'll get several iterations that time out and return zero items, while all the other iterations time out and return one item."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 in 03-TaskParallelism-Part2\n",
    "\n",
    "You were asked to convert the code to use Ray, especially `ray.wait()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def slow_square(n):\n",
    "    time.sleep(n)\n",
    "    return n*n\n",
    "\n",
    "start = time.time()\n",
    "ids = [slow_square.remote(n) for n in range(4)]\n",
    "squares = []\n",
    "waiting_ids = ids\n",
    "while len(waiting_ids) > 0:\n",
    "    finished_ids, waiting_ids = ray.wait(waiting_ids)  # We just assign the second list to waiting_ids...\n",
    "    squares.extend(ray.get(finished_ids))\n",
    "duration = time.time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert squares == [0, 1, 4, 9]\n",
    "assert duration < 4.1, f'duration = {duration}' "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
