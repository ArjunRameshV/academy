{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray RLlib Multi-Armed Bandits - Linear Upper Confidence Bound\n",
    "\n",
    "Â© 2019-2020, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../../images/AnyscaleAcademy_Logo_clearbanner_141x100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [previous lesson](02-Simple-Multi-Armed-Bandit.ipynb), we used _LinUCB_ (Linear Upper Confidence Bound) for the exploration-explotation strategy ([RLlib documentation](https://docs.ray.io/en/latest/rllib-algorithms.html?highlight=greedy#linear-upper-confidence-bound-contrib-linucb)), which assumes a linear dependency between the expected reward of an action and its context. \n",
    "\n",
    "Now we'll use _LinUCB_ in a recommendation environment with _parametric actions_, which are discrete actions that have continuous parameters. At each step, the agent must select which action to use and which parameters to use with that action. This increases the complexity of the context and the challenge of finding the optimal action to achieve the highest mean reward over time.\n",
    "\n",
    "See the previous discussion of UCB in [02 Exploration vs. Exploitation Strategies](02-Exploration-vs-Exploitation-Strategies.ipynb)  and the [previous lesson](03-Simple-Multi-Armed-Bandit.ipynb) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import ray\n",
    "from ray.rllib.contrib.bandits.agents.lin_ucb import UCB_CONFIG\n",
    "from ray.rllib.contrib.bandits.envs import ParametricItemRecoEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `ParametricItemRecoEnv` ([parametric.py source code](https://github.com/ray-project/ray/blob/master/rllib/contrib/bandits/envs/parametric.py)) as the environment, which is a recommendation environment (\"RecoEnv\") that generates \"items\" (the \"parameters\") with randomly-generated features, some visible and some optionally hidden. The default sizes are governed by `DEFAULT_RECO_CONFIG` also in [parametric.py](https://github.com/ray-project/ray/blob/master/rllib/contrib/bandits/envs/parametric.py)):\n",
    "\n",
    "```python\n",
    "DEFAULT_RECO_CONFIG = {\n",
    "    \"num_users\": 1,        # More than one user at a time?\n",
    "    \"num_items\": 100,      # Number of items to randomly sample.\n",
    "    \"feature_dim\": 16,     # Number of features per item, with randomly generated values\n",
    "    \"slate_size\": 1,       # More than one step at a time?\n",
    "    \"num_candidates\": 25,  # Determines the action space and the the number of items randomly sampled from the num_items items.\n",
    "    \"seed\": 1              # For randomization\n",
    "}\n",
    "```\n",
    "\n",
    "This environment is deliberately complicated and hence confusing to understand at first. So, let's look at its behavior. We'll create one using the default settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space: Discrete(25) (number of actions that can be selected)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "pire = ParametricItemRecoEnv()\n",
    "pire.reset()\n",
    "print(f'action space: {pire.action_space} (number of actions that can be selected)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_step():\n",
    "    action = pire.action_space.sample()\n",
    "    obs, reward, finished, info = pire.step(action)\n",
    "    obs_item_foo = f\"{obs['item'][:1]} ({len(obs['item'])} items)\"\n",
    "    print(f\"\"\"\n",
    "    action = {action}, \n",
    "    obs:\n",
    "        'item': {obs_item_foo}, \n",
    "        'item_id': {obs['item_id']},\n",
    "        'response': {obs['response']}, \n",
    "    reward = {reward}, \n",
    "    finished? = {finished}, \n",
    "    info = {info}\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    action = 19, \n",
      "    obs:\n",
      "        'item': [[0.0836686  0.03413296 0.3548183  0.3186919  0.05647112 0.1685622\n",
      "  0.06037586 0.21491483 0.36191626 0.18987564 0.35289666 0.39885143\n",
      "  0.38335529 0.15497378 0.12475218 0.21387429]] (25 items), \n",
      "        'item_id': [96 45 47 64 51 29 10 24 67 36 98 49 73 39 90 14 17  3 69 58 52 75 60  6\n",
      " 56],\n",
      "        'response': [0.7742432650765447], \n",
      "    reward = 0.7742432650765447, \n",
      "    finished? = True, \n",
      "    info = {'regret': 0.05152240241759887}\n",
      "    \n",
      "\n",
      "    action = 3, \n",
      "    obs:\n",
      "        'item': [[0.33545319 0.28567338 0.24924367 0.31581556 0.20958879 0.21383441\n",
      "  0.11115569 0.25297519 0.06565145 0.35436604 0.01753631 0.37512328\n",
      "  0.18226128 0.21928755 0.18862395 0.30033273]] (25 items), \n",
      "        'item_id': [91 79 50 40 15 20 93 25 35 39 47 32 64 17 37 77 58 97 92 76 44 75 16 57\n",
      " 23],\n",
      "        'response': [0.7915956008945028], \n",
      "    reward = 0.7915956008945028, \n",
      "    finished? = True, \n",
      "    info = {'regret': 0.04058009412694119}\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "take_step()\n",
    "take_step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** If you see a warning about _Box bound precision lowered by casting to float32_, you can safely ignore it.\n",
    "\n",
    "The rewards at each step are randomly computed using matrix multiplication of the various randomly-generated matrices of data, followed by selecting a response (reward), indexed by the particular action specified to `step`. However, as constructed the reward always comes out between about 0.6 and 0.9 and the regret is the maximum value over all possible actions minus the reward for the specified action. \n",
    "\n",
    "The `item` shown is the subset of all the _items_ in the environment, with the `item_id` being the corresponding indices of the items shown in the larger collection of items. This list of 25 items is randomly chosen _for each step_, as you should be able to see from these two steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following `num_candidates` steps, which defaults to 25, you may see one regret of 0.0, which happens to be when the action was selected with the maximum possible reward, but not for all runs. Which one has the lowest regret?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: reward = 0.62367, regret = 0.21503\n",
      "  1: reward = 0.77301, regret = 0.00412\n",
      "  2: reward = 0.83870, regret = 0.00000\n",
      "  3: reward = 0.69889, regret = 0.08194\n",
      "  4: reward = 0.74752, regret = 0.10743\n",
      "  5: reward = 0.84322, regret = 0.00000\n",
      "  6: reward = 0.59587, regret = 0.23830\n",
      "  7: reward = 0.59587, regret = 0.23630\n",
      "  8: reward = 0.70778, regret = 0.14716\n",
      "  9: reward = 0.76287, regret = 0.08035\n",
      " 10: reward = 0.55542, regret = 0.27676\n",
      " 11: reward = 0.59587, regret = 0.24282\n",
      " 12: reward = 0.61115, regret = 0.21461\n",
      " 13: reward = 0.66076, regret = 0.17342\n",
      " 14: reward = 0.79247, regret = 0.03329\n",
      " 15: reward = 0.77712, regret = 0.05706\n",
      " 16: reward = 0.56246, regret = 0.27624\n",
      " 17: reward = 0.76270, regret = 0.07148\n",
      " 18: reward = 0.74752, regret = 0.09118\n",
      " 19: reward = 0.70118, regret = 0.13752\n",
      " 20: reward = 0.76287, regret = 0.07131\n",
      " 21: reward = 0.56246, regret = 0.27624\n",
      " 22: reward = 0.66846, regret = 0.17024\n",
      " 23: reward = 0.66395, regret = 0.17475\n",
      " 24: reward = 0.74212, regret = 0.09206\n"
     ]
    }
   ],
   "source": [
    "for i in range(pire.num_candidates):\n",
    "    action = pire.action_space.sample()\n",
    "    obs, reward, finished, info = pire.step(action)\n",
    "    print(f'{i:3d}: reward = {reward:7.5f}, regret = {info[\"regret\"]:7.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The up shot is that training to find the optimal, mean reward will be more challenging than our previous simple bandit.\n",
    "\n",
    "Now that we've explored `ParametricItemRecoEnv`, let's use it with _LinUCB_.\n",
    "\n",
    "Note that we imported `UCB_CONFIG` above, which has the properties defined that are expected _LinUCB_. We'll add another property to it for the environment. (Subsequent lessons will show other ways to work with the configuration.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for 20 time steps\n"
     ]
    }
   ],
   "source": [
    "UCB_CONFIG[\"env\"] = ParametricItemRecoEnv\n",
    "\n",
    "# Actual training_iterations will be 20 * timesteps_per_iteration (100 by default) = 2,000\n",
    "training_iterations = 20\n",
    "\n",
    "print(\"Running training for %s time steps\" % training_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use [Ray Tune](http://tune.io) to train. First we'll ensure that Ray is properly initialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Ray is already running.\n"
     ]
    }
   ],
   "source": [
    "!../../tools/start-ray.sh --check --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-13 10:24:23,299\tWARNING worker.py:809 -- When connecting to an existing cluster, _internal_config must match the cluster's _internal_config.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.149',\n",
       " 'raylet_ip_address': '192.168.1.149',\n",
       " 'redis_address': '192.168.1.149:15832',\n",
       " 'object_store_address': '/tmp/ray/session_2020-06-12_08-58-38_626987_40764/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-06-12_08-58-38_626987_40764/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-06-12_08-58-38_626987_40764'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(address='auto', ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell will print a lot of output. Use the right-click menu, option _Enable Scrolling for Outputs_ to encapsulate the output in a scrollable text box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.1/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.27 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (4 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=76836)\u001b[0m 2020-06-13 10:25:09,454\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=76836)\u001b[0m 2020-06-13 10:25:09,456\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=76836)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=76836)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=76836)\u001b[0m 2020-06-13 10:25:09,483\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=76836)\u001b[0m 2020-06-13 10:25:09,484\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=76835)\u001b[0m 2020-06-13 10:25:09,448\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=76835)\u001b[0m 2020-06-13 10:25:09,449\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=76835)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=76835)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=76835)\u001b[0m 2020-06-13 10:25:09,465\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=76835)\u001b[0m 2020-06-13 10:25:09,465\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=76834)\u001b[0m 2020-06-13 10:25:09,455\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=76834)\u001b[0m 2020-06-13 10:25:09,456\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=76834)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=76834)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=76834)\u001b[0m 2020-06-13 10:25:09,480\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=76834)\u001b[0m 2020-06-13 10:25:09,481\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=76838)\u001b[0m 2020-06-13 10:25:09,452\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=76838)\u001b[0m 2020-06-13 10:25:09,454\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=76838)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=76838)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=76838)\u001b[0m 2020-06-13 10:25:09,474\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=76838)\u001b[0m 2020-06-13 10:25:09,474\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=76837)\u001b[0m 2020-06-13 10:25:09,449\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=76837)\u001b[0m 2020-06-13 10:25:09,450\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=76837)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=76837)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=76837)\u001b[0m 2020-06-13 10:25:09,468\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=76837)\u001b[0m 2020-06-13 10:25:09,468\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9133712794599098\n",
      "  episode_reward_mean: 0.8466168049822886\n",
      "  episode_reward_min: 0.6490375748463251\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: de203ef44a4f47ed894c387d1cc3eef0\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.541\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.541\n",
      "    learner:\n",
      "      cumulative_regret: 3.5589177776800915\n",
      "      update_latency: 0.00022602081298828125\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 1847.874\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 653.981\n",
      "    sample_time_ms: 1.529\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.5589177776800915\n",
      "    update_latency: 0.00022602081298828125\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1847.874\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 74.6\n",
      "    ram_util_percent: 66.7\n",
      "  pid: 76835\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 653.981\n",
      "  sample_time_ms: 1.529\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.25496152367922337\n",
      "    mean_inference_ms: 2.6369496147231293\n",
      "    mean_processing_ms: 0.9333780496427329\n",
      "  time_since_restore: 0.49415087699890137\n",
      "  time_this_iter_s: 0.49415087699890137\n",
      "  time_total_s: 0.49415087699890137\n",
      "  timestamp: 1592069109\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.7/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/8 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.27 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>192.168.1.149:76835</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.494151</td><td style=\"text-align: right;\"> 100</td><td style=\"text-align: right;\">0.846617</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>RUNNING </td><td>                   </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>RUNNING </td><td>                   </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>RUNNING </td><td>                   </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>RUNNING </td><td>                   </td><td style=\"text-align: right;\">      </td><td style=\"text-align: right;\">                </td><td style=\"text-align: right;\">    </td><td style=\"text-align: right;\">        </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9280944831908227\n",
      "  episode_reward_mean: 0.8694560746347274\n",
      "  episode_reward_min: 0.6353103557043434\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 56209c31bedd4affb6dff6ae552da3c4\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 0.552\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.552\n",
      "    learner:\n",
      "      cumulative_regret: 3.551424354495237\n",
      "      update_latency: 0.00023221969604492188\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 1810.856\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 706.6\n",
      "    sample_time_ms: 1.415\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.551424354495237\n",
      "    update_latency: 0.00023221969604492188\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1810.856\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 74.7\n",
      "    ram_util_percent: 66.7\n",
      "  pid: 76834\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 706.6\n",
      "  sample_time_ms: 1.415\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.2594655103022509\n",
      "    mean_inference_ms: 1.530319157213267\n",
      "    mean_processing_ms: 0.9565778297953087\n",
      "  time_since_restore: 0.48750782012939453\n",
      "  time_this_iter_s: 0.48750782012939453\n",
      "  time_total_s: 0.48750782012939453\n",
      "  timestamp: 1592069109\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9470153333930189\n",
      "  episode_reward_mean: 0.8629405330974389\n",
      "  episode_reward_min: 0.684134697042611\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 1bf5e4e7869047f88dd6e07b98e3cb24\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 0.518\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.518\n",
      "    learner:\n",
      "      cumulative_regret: 3.393412576497998\n",
      "      update_latency: 0.00020599365234375\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 1932.325\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 696.763\n",
      "    sample_time_ms: 1.435\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.393412576497998\n",
      "    update_latency: 0.00020599365234375\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1932.325\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 74.7\n",
      "    ram_util_percent: 66.7\n",
      "  pid: 76836\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 696.763\n",
      "  sample_time_ms: 1.435\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.3078455972199392\n",
      "    mean_inference_ms: 1.7161487352730027\n",
      "    mean_processing_ms: 1.3288554578724467\n",
      "  time_since_restore: 0.48331284523010254\n",
      "  time_this_iter_s: 0.48331284523010254\n",
      "  time_total_s: 0.48331284523010254\n",
      "  timestamp: 1592069109\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9352752309309447\n",
      "  episode_reward_mean: 0.868285295956571\n",
      "  episode_reward_min: 0.5595852555820684\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 273be749a763442abb221a183a6245c6\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 0.571\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.571\n",
      "    learner:\n",
      "      cumulative_regret: 3.1075944474241934\n",
      "      update_latency: 0.00022220611572265625\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 1750.69\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 751.021\n",
      "    sample_time_ms: 1.332\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.1075944474241934\n",
      "    update_latency: 0.00022220611572265625\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1750.69\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 74.6\n",
      "    ram_util_percent: 66.7\n",
      "  pid: 76838\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 751.021\n",
      "  sample_time_ms: 1.332\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.3072224041022876\n",
      "    mean_inference_ms: 1.9364498629428377\n",
      "    mean_processing_ms: 1.218113568749758\n",
      "  time_since_restore: 0.4890129566192627\n",
      "  time_this_iter_s: 0.4890129566192627\n",
      "  time_total_s: 0.4890129566192627\n",
      "  timestamp: 1592069109\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-09\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.951993446416068\n",
      "  episode_reward_mean: 0.8803088451772123\n",
      "  episode_reward_min: 0.6776020671207219\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: e5e02ba87b584bad947bd24a90249892\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 0.531\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.531\n",
      "    learner:\n",
      "      cumulative_regret: 3.9389581516729733\n",
      "      update_latency: 0.00021910667419433594\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 1883.98\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 726.576\n",
      "    sample_time_ms: 1.376\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.9389581516729733\n",
      "    update_latency: 0.00021910667419433594\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1883.98\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 74.6\n",
      "    ram_util_percent: 66.7\n",
      "  pid: 76837\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 726.576\n",
      "  sample_time_ms: 1.376\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.2591232262035409\n",
      "    mean_inference_ms: 1.6399279679402263\n",
      "    mean_processing_ms: 1.4982837261539879\n",
      "  time_since_restore: 0.49382591247558594\n",
      "  time_this_iter_s: 0.49382591247558594\n",
      "  time_total_s: 0.49382591247558594\n",
      "  timestamp: 1592069109\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.951993446416068\n",
      "  episode_reward_mean: 0.9187637486024615\n",
      "  episode_reward_min: 0.8205867306277508\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1700\n",
      "  experiment_id: e5e02ba87b584bad947bd24a90249892\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 0.728\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.728\n",
      "    learner:\n",
      "      cumulative_regret: 5.940452073077221\n",
      "      update_latency: 0.0005741119384765625\n",
      "    num_steps_sampled: 1700\n",
      "    num_steps_trained: 1700\n",
      "    opt_peak_throughput: 1373.156\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 756.017\n",
      "    sample_time_ms: 1.323\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 17\n",
      "  learner:\n",
      "    cumulative_regret: 5.940452073077221\n",
      "    update_latency: 0.0005741119384765625\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1700\n",
      "  num_steps_trained: 1700\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1373.156\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 76837\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 756.017\n",
      "  sample_time_ms: 1.323\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.22432413050737324\n",
      "    mean_inference_ms: 0.8131137390405833\n",
      "    mean_processing_ms: 0.8215487949431884\n",
      "  time_since_restore: 5.192554473876953\n",
      "  time_this_iter_s: 0.4734048843383789\n",
      "  time_total_s: 5.192554473876953\n",
      "  timestamp: 1592069115\n",
      "  timesteps_since_restore: 1700\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1700\n",
      "  training_iteration: 17\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/8 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.27 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>192.168.1.149:76835</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         5.17504</td><td style=\"text-align: right;\">1600</td><td style=\"text-align: right;\">0.882625</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>RUNNING </td><td>192.168.1.149:76836</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         4.78658</td><td style=\"text-align: right;\">1600</td><td style=\"text-align: right;\">0.897233</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>RUNNING </td><td>192.168.1.149:76834</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         4.79267</td><td style=\"text-align: right;\">1600</td><td style=\"text-align: right;\">0.90677 </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>RUNNING </td><td>192.168.1.149:76837</td><td style=\"text-align: right;\">    17</td><td style=\"text-align: right;\">         5.19255</td><td style=\"text-align: right;\">1700</td><td style=\"text-align: right;\">0.918764</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>RUNNING </td><td>192.168.1.149:76838</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">         5.06302</td><td style=\"text-align: right;\">1600</td><td style=\"text-align: right;\">0.904948</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9470153333930189\n",
      "  episode_reward_mean: 0.8946172684156892\n",
      "  episode_reward_min: 0.8196083749122994\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1700\n",
      "  experiment_id: 1bf5e4e7869047f88dd6e07b98e3cb24\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 0.912\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.912\n",
      "    learner:\n",
      "      cumulative_regret: 5.8236768922896625\n",
      "      update_latency: 0.00036406517028808594\n",
      "    num_steps_sampled: 1700\n",
      "    num_steps_trained: 1700\n",
      "    opt_peak_throughput: 1096.808\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 498.077\n",
      "    sample_time_ms: 2.008\n",
      "    update_time_ms: 0.003\n",
      "  iterations_since_restore: 17\n",
      "  learner:\n",
      "    cumulative_regret: 5.8236768922896625\n",
      "    update_latency: 0.00036406517028808594\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1700\n",
      "  num_steps_trained: 1700\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1096.808\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 76836\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 498.077\n",
      "  sample_time_ms: 2.008\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.23144164693698957\n",
      "    mean_inference_ms: 0.8732463807515853\n",
      "    mean_processing_ms: 0.8466867472689552\n",
      "  time_since_restore: 5.2934956550598145\n",
      "  time_this_iter_s: 0.506911039352417\n",
      "  time_total_s: 5.2934956550598145\n",
      "  timestamp: 1592069115\n",
      "  timesteps_since_restore: 1700\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1700\n",
      "  training_iteration: 17\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.003\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9280944831908227\n",
      "  episode_reward_mean: 0.9042530814687378\n",
      "  episode_reward_min: 0.8268586485652003\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1700\n",
      "  experiment_id: 56209c31bedd4affb6dff6ae552da3c4\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 1.143\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.143\n",
      "    learner:\n",
      "      cumulative_regret: 6.911855606794676\n",
      "      update_latency: 0.0005562305450439453\n",
      "    num_steps_sampled: 1700\n",
      "    num_steps_trained: 1700\n",
      "    opt_peak_throughput: 874.579\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 434.593\n",
      "    sample_time_ms: 2.301\n",
      "    update_time_ms: 0.003\n",
      "  iterations_since_restore: 17\n",
      "  learner:\n",
      "    cumulative_regret: 6.911855606794676\n",
      "    update_latency: 0.0005562305450439453\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1700\n",
      "  num_steps_trained: 1700\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 874.579\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 69.6\n",
      "    ram_util_percent: 67.5\n",
      "  pid: 76834\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 434.593\n",
      "  sample_time_ms: 2.301\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.2337050115550566\n",
      "    mean_inference_ms: 0.8364786196287628\n",
      "    mean_processing_ms: 0.9330663170834138\n",
      "  time_since_restore: 5.299342632293701\n",
      "  time_this_iter_s: 0.5066711902618408\n",
      "  time_total_s: 5.299342632293701\n",
      "  timestamp: 1592069115\n",
      "  timesteps_since_restore: 1700\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1700\n",
      "  training_iteration: 17\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.003\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9352752309309447\n",
      "  episode_reward_mean: 0.9035681453503167\n",
      "  episode_reward_min: 0.8339375913375026\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1700\n",
      "  experiment_id: 273be749a763442abb221a183a6245c6\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 0.88\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.88\n",
      "    learner:\n",
      "      cumulative_regret: 6.023490526022882\n",
      "      update_latency: 0.0005421638488769531\n",
      "    num_steps_sampled: 1700\n",
      "    num_steps_trained: 1700\n",
      "    opt_peak_throughput: 1136.237\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 662.995\n",
      "    sample_time_ms: 1.508\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 17\n",
      "  learner:\n",
      "    cumulative_regret: 6.023490526022882\n",
      "    update_latency: 0.0005421638488769531\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1700\n",
      "  num_steps_trained: 1700\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1136.237\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 69.6\n",
      "    ram_util_percent: 67.5\n",
      "  pid: 76838\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 662.995\n",
      "  sample_time_ms: 1.508\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.22223148536569998\n",
      "    mean_inference_ms: 0.9102776497690064\n",
      "    mean_processing_ms: 0.8136760761007572\n",
      "  time_since_restore: 5.34118127822876\n",
      "  time_this_iter_s: 0.27815699577331543\n",
      "  time_total_s: 5.34118127822876\n",
      "  timestamp: 1592069115\n",
      "  timesteps_since_restore: 1700\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1700\n",
      "  training_iteration: 17\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-15\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9133712794599098\n",
      "  episode_reward_mean: 0.8851291888454241\n",
      "  episode_reward_min: 0.7893902656999698\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1700\n",
      "  experiment_id: de203ef44a4f47ed894c387d1cc3eef0\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.8\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.8\n",
      "    learner:\n",
      "      cumulative_regret: 5.615516355521155\n",
      "      update_latency: 0.0005099773406982422\n",
      "    num_steps_sampled: 1700\n",
      "    num_steps_trained: 1700\n",
      "    opt_peak_throughput: 1249.458\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 764.199\n",
      "    sample_time_ms: 1.309\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 17\n",
      "  learner:\n",
      "    cumulative_regret: 5.615516355521155\n",
      "    update_latency: 0.0005099773406982422\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1700\n",
      "  num_steps_trained: 1700\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1249.458\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 69.5\n",
      "    ram_util_percent: 67.5\n",
      "  pid: 76835\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 764.199\n",
      "  sample_time_ms: 1.309\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.2606634109739273\n",
      "    mean_inference_ms: 0.9707543935444971\n",
      "    mean_processing_ms: 0.8783810002743536\n",
      "  time_since_restore: 5.439068555831909\n",
      "  time_this_iter_s: 0.26403188705444336\n",
      "  time_total_s: 5.439068555831909\n",
      "  timestamp: 1592069115\n",
      "  timesteps_since_restore: 1700\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1700\n",
      "  training_iteration: 17\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-15\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.951993446416068\n",
      "  episode_reward_mean: 0.9172070349238539\n",
      "  episode_reward_min: 0.841316661932367\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2000\n",
      "  experiment_id: e5e02ba87b584bad947bd24a90249892\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 0.646\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.646\n",
      "    learner:\n",
      "      cumulative_regret: 6.1047712334022926\n",
      "      update_latency: 0.00035881996154785156\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    opt_peak_throughput: 1547.314\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 799.555\n",
      "    sample_time_ms: 1.251\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 20\n",
      "  learner:\n",
      "    cumulative_regret: 6.1047712334022926\n",
      "    update_latency: 0.00035881996154785156\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 2000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1547.314\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 70.6\n",
      "    ram_util_percent: 67.6\n",
      "  pid: 76837\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 799.555\n",
      "  sample_time_ms: 1.251\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.24201844943159526\n",
      "    mean_inference_ms: 0.7984602469196919\n",
      "    mean_processing_ms: 0.8078025377493749\n",
      "  time_since_restore: 6.0925164222717285\n",
      "  time_this_iter_s: 0.4376850128173828\n",
      "  time_total_s: 6.0925164222717285\n",
      "  timestamp: 1592069115\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 20\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-16\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9470153333930189\n",
      "  episode_reward_mean: 0.8925219573989573\n",
      "  episode_reward_min: 0.8163333138225245\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2000\n",
      "  experiment_id: 1bf5e4e7869047f88dd6e07b98e3cb24\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 0.726\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.726\n",
      "    learner:\n",
      "      cumulative_regret: 5.939344778172683\n",
      "      update_latency: 0.0005009174346923828\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    opt_peak_throughput: 1377.666\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 687.625\n",
      "    sample_time_ms: 1.454\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 20\n",
      "  learner:\n",
      "    cumulative_regret: 5.939344778172683\n",
      "    update_latency: 0.0005009174346923828\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 2000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1377.666\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 70.6\n",
      "    ram_util_percent: 67.6\n",
      "  pid: 76836\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 687.625\n",
      "  sample_time_ms: 1.454\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.22609718795539976\n",
      "    mean_inference_ms: 0.8518881704853755\n",
      "    mean_processing_ms: 0.8482110911402208\n",
      "  time_since_restore: 6.1651201248168945\n",
      "  time_this_iter_s: 0.4319608211517334\n",
      "  time_total_s: 6.1651201248168945\n",
      "  timestamp: 1592069116\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 20\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-16\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9280944831908227\n",
      "  episode_reward_mean: 0.9059237069178941\n",
      "  episode_reward_min: 0.8482847429331071\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2000\n",
      "  experiment_id: 56209c31bedd4affb6dff6ae552da3c4\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 0.75\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.75\n",
      "    learner:\n",
      "      cumulative_regret: 7.127574883039357\n",
      "      update_latency: 0.00046181678771972656\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    opt_peak_throughput: 1333.345\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 693.996\n",
      "    sample_time_ms: 1.441\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 20\n",
      "  learner:\n",
      "    cumulative_regret: 7.127574883039357\n",
      "    update_latency: 0.00046181678771972656\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 2000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1333.345\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 70.6\n",
      "    ram_util_percent: 67.6\n",
      "  pid: 76834\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 693.996\n",
      "  sample_time_ms: 1.441\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.2271290244846449\n",
      "    mean_inference_ms: 0.8161351538967456\n",
      "    mean_processing_ms: 0.9113189758270279\n",
      "  time_since_restore: 6.170010328292847\n",
      "  time_this_iter_s: 0.42610692977905273\n",
      "  time_total_s: 6.170010328292847\n",
      "  timestamp: 1592069116\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 20\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-16\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9352752309309447\n",
      "  episode_reward_mean: 0.8972682371775885\n",
      "  episode_reward_min: 0.8374938687669817\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2000\n",
      "  experiment_id: 273be749a763442abb221a183a6245c6\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 0.95\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.95\n",
      "    learner:\n",
      "      cumulative_regret: 6.208545007514373\n",
      "      update_latency: 0.0006358623504638672\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    opt_peak_throughput: 1052.523\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 573.635\n",
      "    sample_time_ms: 1.743\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 20\n",
      "  learner:\n",
      "    cumulative_regret: 6.208545007514373\n",
      "    update_latency: 0.0006358623504638672\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 2000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1052.523\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 70.6\n",
      "    ram_util_percent: 67.6\n",
      "  pid: 76838\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 573.635\n",
      "  sample_time_ms: 1.743\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.21707672050510396\n",
      "    mean_inference_ms: 0.8755698911789834\n",
      "    mean_processing_ms: 0.7890195384256726\n",
      "  time_since_restore: 6.176144123077393\n",
      "  time_this_iter_s: 0.27402782440185547\n",
      "  time_total_s: 6.176144123077393\n",
      "  timestamp: 1592069116\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 20\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-13_10-25-16\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9133712794599098\n",
      "  episode_reward_mean: 0.8870760687100611\n",
      "  episode_reward_min: 0.8294642448903196\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2000\n",
      "  experiment_id: de203ef44a4f47ed894c387d1cc3eef0\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.8\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.8\n",
      "    learner:\n",
      "      cumulative_regret: 5.694018912077152\n",
      "      update_latency: 0.0007898807525634766\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    opt_peak_throughput: 1250.314\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 595.883\n",
      "    sample_time_ms: 1.678\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 20\n",
      "  learner:\n",
      "    cumulative_regret: 5.694018912077152\n",
      "    update_latency: 0.0007898807525634766\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 2000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1250.314\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 76835\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 595.883\n",
      "  sample_time_ms: 1.678\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.25102735935956577\n",
      "    mean_inference_ms: 0.948165786796543\n",
      "    mean_processing_ms: 0.8523777566630503\n",
      "  time_since_restore: 6.318816900253296\n",
      "  time_this_iter_s: 0.24887776374816895\n",
      "  time_total_s: 6.318816900253296\n",
      "  timestamp: 1592069116\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 20\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.8/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/3.81 GiB heap, 0.0/1.27 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6.31882</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">0.887076</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6.16512</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">0.892522</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6.17001</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">0.905924</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6.09252</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">0.917207</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         6.17614</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">0.897268</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trials took 14.795217990875244 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "analysis = ray.tune.run(\n",
    "    \"contrib/LinUCB\",\n",
    "    config=UCB_CONFIG,\n",
    "    stop={\"training_iteration\": training_iterations},\n",
    "    num_samples=5,\n",
    "    verbose=2,  # Change to 0 or 1 to reduce the output.\n",
    "    ray_auto_init=False,    # Don't allow Tune to initialize Ray.\n",
    ")\n",
    "\n",
    "print(\"The trials took\", time.time() - start_time, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_steps_trained</th>\n",
       "      <th>num_steps_sampled</th>\n",
       "      <th>sample_time_ms</th>\n",
       "      <th>grad_time_ms</th>\n",
       "      <th>update_time_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>config/seed</th>\n",
       "      <th>config/shuffle_buffer_size</th>\n",
       "      <th>config/soft_horizon</th>\n",
       "      <th>config/synchronize_filters</th>\n",
       "      <th>config/tf_session_args</th>\n",
       "      <th>config/timesteps_per_iteration</th>\n",
       "      <th>config/train_batch_size</th>\n",
       "      <th>config/use_exec_api</th>\n",
       "      <th>config/use_pytorch</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913371</td>\n",
       "      <td>0.829464</td>\n",
       "      <td>0.887076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.678</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'allow_soft_placement': True, 'device_count':...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.947015</td>\n",
       "      <td>0.816333</td>\n",
       "      <td>0.892522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.454</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'allow_soft_placement': True, 'device_count':...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.928094</td>\n",
       "      <td>0.848285</td>\n",
       "      <td>0.905924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.441</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'allow_soft_placement': True, 'device_count':...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.951993</td>\n",
       "      <td>0.841317</td>\n",
       "      <td>0.917207</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.251</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'allow_soft_placement': True, 'device_count':...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.935275</td>\n",
       "      <td>0.837494</td>\n",
       "      <td>0.897268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.743</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'allow_soft_placement': True, 'device_count':...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0            0.913371            0.829464             0.887076   \n",
       "1            0.947015            0.816333             0.892522   \n",
       "2            0.928094            0.848285             0.905924   \n",
       "3            0.951993            0.841317             0.917207   \n",
       "4            0.935275            0.837494             0.897268   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_steps_trained  num_steps_sampled  \\\n",
       "0               1.0                 100               2000               2000   \n",
       "1               1.0                 100               2000               2000   \n",
       "2               1.0                 100               2000               2000   \n",
       "3               1.0                 100               2000               2000   \n",
       "4               1.0                 100               2000               2000   \n",
       "\n",
       "   sample_time_ms  grad_time_ms  update_time_ms  ...  config/seed  \\\n",
       "0           1.678         0.800           0.002  ...         None   \n",
       "1           1.454         0.726           0.002  ...         None   \n",
       "2           1.441         0.750           0.002  ...         None   \n",
       "3           1.251         0.646           0.002  ...         None   \n",
       "4           1.743         0.950           0.002  ...         None   \n",
       "\n",
       "   config/shuffle_buffer_size  config/soft_horizon  \\\n",
       "0                           0                False   \n",
       "1                           0                False   \n",
       "2                           0                False   \n",
       "3                           0                False   \n",
       "4                           0                False   \n",
       "\n",
       "   config/synchronize_filters  \\\n",
       "0                        True   \n",
       "1                        True   \n",
       "2                        True   \n",
       "3                        True   \n",
       "4                        True   \n",
       "\n",
       "                              config/tf_session_args  \\\n",
       "0  {'allow_soft_placement': True, 'device_count':...   \n",
       "1  {'allow_soft_placement': True, 'device_count':...   \n",
       "2  {'allow_soft_placement': True, 'device_count':...   \n",
       "3  {'allow_soft_placement': True, 'device_count':...   \n",
       "4  {'allow_soft_placement': True, 'device_count':...   \n",
       "\n",
       "   config/timesteps_per_iteration  config/train_batch_size  \\\n",
       "0                             100                        1   \n",
       "1                             100                        1   \n",
       "2                             100                        1   \n",
       "3                             100                        1   \n",
       "4                             100                        1   \n",
       "\n",
       "   config/use_exec_api  config/use_pytorch  \\\n",
       "0                False                True   \n",
       "1                False                True   \n",
       "2                False                True   \n",
       "3                False                True   \n",
       "4                False                True   \n",
       "\n",
       "                                              logdir  \n",
       "0  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "1  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "2  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "3  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "4  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = analysis.dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the `episode_reward_mean` values. Now let's analyze the _cumulative regrets_ of the trials. It's inevitable that we sometimes pick a suboptimal action, but was this done less often as time progressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the columns in the trial dataframes is the `learner/cumulative_regret`. Let's combine the trail DataFrames into a single DataFrame, then group over the `number_steps_trained` and project out the `learner/cumulative_regret`. Finally, aggregate for each `number_steps_trained` to compute the `mean`, `max`, `min`, and `std` (standard deviation) for the cumulative regret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame()\n",
    "\n",
    "for key, df in analysis.trial_dataframes.items():\n",
    "    frame = frame.append(df, ignore_index=True)\n",
    "\n",
    "df = frame.groupby(\"num_steps_trained\")[\n",
    "    \"learner/cumulative_regret\"].aggregate([\"mean\", \"max\", \"min\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_steps_trained</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.510061</td>\n",
       "      <td>3.938958</td>\n",
       "      <td>3.107594</td>\n",
       "      <td>0.301512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>4.051401</td>\n",
       "      <td>4.317260</td>\n",
       "      <td>3.648172</td>\n",
       "      <td>0.249409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>4.408159</td>\n",
       "      <td>4.781662</td>\n",
       "      <td>4.232443</td>\n",
       "      <td>0.222284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>4.662473</td>\n",
       "      <td>5.035561</td>\n",
       "      <td>4.466877</td>\n",
       "      <td>0.219358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>4.902268</td>\n",
       "      <td>5.236158</td>\n",
       "      <td>4.716805</td>\n",
       "      <td>0.201651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>5.110317</td>\n",
       "      <td>5.535199</td>\n",
       "      <td>4.862963</td>\n",
       "      <td>0.259140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>5.268552</td>\n",
       "      <td>5.753674</td>\n",
       "      <td>4.976128</td>\n",
       "      <td>0.299698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>5.397890</td>\n",
       "      <td>5.978279</td>\n",
       "      <td>5.077381</td>\n",
       "      <td>0.343824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>5.488008</td>\n",
       "      <td>6.080962</td>\n",
       "      <td>5.126822</td>\n",
       "      <td>0.355669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5.590762</td>\n",
       "      <td>6.180468</td>\n",
       "      <td>5.222625</td>\n",
       "      <td>0.354345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>5.661271</td>\n",
       "      <td>6.302441</td>\n",
       "      <td>5.287928</td>\n",
       "      <td>0.379144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>5.742637</td>\n",
       "      <td>6.411080</td>\n",
       "      <td>5.389454</td>\n",
       "      <td>0.388859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>5.803205</td>\n",
       "      <td>6.480700</td>\n",
       "      <td>5.415587</td>\n",
       "      <td>0.399334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>5.871553</td>\n",
       "      <td>6.592197</td>\n",
       "      <td>5.467843</td>\n",
       "      <td>0.423798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>5.933233</td>\n",
       "      <td>6.690691</td>\n",
       "      <td>5.523851</td>\n",
       "      <td>0.444859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>5.993502</td>\n",
       "      <td>6.842632</td>\n",
       "      <td>5.533003</td>\n",
       "      <td>0.500176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>6.062998</td>\n",
       "      <td>6.911856</td>\n",
       "      <td>5.615516</td>\n",
       "      <td>0.498661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>6.105954</td>\n",
       "      <td>7.006760</td>\n",
       "      <td>5.635777</td>\n",
       "      <td>0.526556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>6.140968</td>\n",
       "      <td>7.046833</td>\n",
       "      <td>5.667452</td>\n",
       "      <td>0.532845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>6.214851</td>\n",
       "      <td>7.127575</td>\n",
       "      <td>5.694019</td>\n",
       "      <td>0.545984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean       max       min       std\n",
       "num_steps_trained                                        \n",
       "100                3.510061  3.938958  3.107594  0.301512\n",
       "200                4.051401  4.317260  3.648172  0.249409\n",
       "300                4.408159  4.781662  4.232443  0.222284\n",
       "400                4.662473  5.035561  4.466877  0.219358\n",
       "500                4.902268  5.236158  4.716805  0.201651\n",
       "600                5.110317  5.535199  4.862963  0.259140\n",
       "700                5.268552  5.753674  4.976128  0.299698\n",
       "800                5.397890  5.978279  5.077381  0.343824\n",
       "900                5.488008  6.080962  5.126822  0.355669\n",
       "1000               5.590762  6.180468  5.222625  0.354345\n",
       "1100               5.661271  6.302441  5.287928  0.379144\n",
       "1200               5.742637  6.411080  5.389454  0.388859\n",
       "1300               5.803205  6.480700  5.415587  0.399334\n",
       "1400               5.871553  6.592197  5.467843  0.423798\n",
       "1500               5.933233  6.690691  5.523851  0.444859\n",
       "1600               5.993502  6.842632  5.533003  0.500176\n",
       "1700               6.062998  6.911856  5.615516  0.498661\n",
       "1800               6.105954  7.006760  5.635777  0.526556\n",
       "1900               6.140968  7.046833  5.667452  0.532845\n",
       "2000               6.214851  7.127575  5.694019  0.545984"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be easier to understand these results with a graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\": \"JpP8FXbgAZLkfur7LiK3j9AGBhHNIvF742meBJrjO2ShJDhCG2I1uVvW+0DUtrmc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\": \"xZlADit0Q04ISQEdKg2k3L4W9AwQBAuDs9nJL9fM/WwzL1tEU9VPNezOFX0nLEAz\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\": \"4BuPRZkdMKSnj3zoxiNrQ86XgNw0rYmBOxe7nshquXwwcauupgBF2DHLVG1WuZlV\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\": \"Dv1SQ87hmDqK6S5OhBf0bCuwAEvL5QYL0PuR/F1SPVhCS/r/abjkbpKDYL2zeM19\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\": \"JpP8FXbgAZLkfur7LiK3j9AGBhHNIvF742meBJrjO2ShJDhCG2I1uVvW+0DUtrmc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\": \"xZlADit0Q04ISQEdKg2k3L4W9AwQBAuDs9nJL9fM/WwzL1tEU9VPNezOFX0nLEAz\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\": \"4BuPRZkdMKSnj3zoxiNrQ86XgNw0rYmBOxe7nshquXwwcauupgBF2DHLVG1WuZlV\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\": \"Dv1SQ87hmDqK6S5OhBf0bCuwAEvL5QYL0PuR/F1SPVhCS/r/abjkbpKDYL2zeM19\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh_util import plot_cumulative_regret\n",
    "# The next two lines prevent Bokeh from opening the graph in a new window.\n",
    "import bokeh\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"dc01119d-9b07-4f88-9704-fcb6b5d727a3\" data-root-id=\"1004\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"20a9f590-536c-4056-bd1e-eeb38e568ec0\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1012\"}],\"center\":[{\"id\":\"1015\"},{\"id\":\"1019\"},{\"id\":\"1042\"}],\"left\":[{\"id\":\"1016\"}],\"plot_height\":500,\"plot_width\":800,\"renderers\":[{\"id\":\"1035\"},{\"id\":\"1040\"}],\"title\":{\"id\":\"1046\"},\"toolbar\":{\"id\":\"1026\"},\"x_range\":{\"id\":\"1005\"},\"x_scale\":{\"id\":\"1008\"},\"y_range\":{\"id\":\"1003\"},\"y_scale\":{\"id\":\"1010\"}},\"id\":\"1004\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"end\":6.831880158587396,\"start\":3.1375042204160786},\"id\":\"1003\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"1021\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"1038\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1053\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1013\",\"type\":\"BasicTicker\"},{\"attributes\":{\"data_source\":{\"id\":\"1002\"},\"glyph\":{\"id\":\"1033\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1034\"},\"selection_glyph\":null,\"view\":{\"id\":\"1036\"}},\"id\":\"1035\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"overlay\":{\"id\":\"1025\"}},\"id\":\"1022\",\"type\":\"BoxZoomTool\"},{\"attributes\":{\"data_source\":{\"id\":\"1002\"},\"glyph\":{\"id\":\"1038\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1039\"},\"selection_glyph\":null,\"view\":{\"id\":\"1041\"}},\"id\":\"1040\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1002\"}},\"id\":\"1041\",\"type\":\"CDSView\"},{\"attributes\":{\"axis_label\":\"step\",\"formatter\":{\"id\":\"1050\"},\"ticker\":{\"id\":\"1013\"}},\"id\":\"1012\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"lower\":{\"__ndarray__\":\"+gBNNxyrCUBT4p+cemoOQGQyoQNWvhBA8Czk97/FEUDGeIV9bs0SQJ8KlPuaZxNAoxFxRBvgE0DIEKPgXDcUQDQZC82DhxRA7YJqbRfyFEBwQana5SAVQGXzlKREahVAYlsPZpCdFUA4ttAxgMoVQAglxmoY9BVAHCSPPSr5FUDdaaCU4UEWQPRGJqZNURZA3NalkLduFkBxi0mX66wWQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"max\":{\"__ndarray__\":\"9fvNffyCD0AP8evq30QRQHURTR5sIBNA+lrMOGokFECaRI5M0/EUQLgVhh0LJBZAWPEKHMMDF0A0VcwDwukXQP5U/sLnUhhAlflAu8y4GEBhA0coszUZQAHbPUHypBlArOgDpzzsGUBYBV33aF4aQPm4fIZEwxpA4SSg4dpeG0Dybed5vaUbQK+uLTPsBhxA7vNNFvUvHEC/x3n9ooIcQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"mean\":{\"__ndarray__\":\"OJmCGpsUDEA2/blcojQQQENUIFz0oRFAFFH5Wl+mEkCbQAoe7JsTQFaZGw33cBRAXVCwLf8SFUDT26pdcJcVQGAZ+mC48xVA0E2TxfBcFkB2YpQ1JKUWQFxEyM11+BZAw9UtW3s2F0A2o55reHwXQDUKu3mhuxdAsHHRe1j5F0B/v7mfgkAYQEr9ViF/bBhAbeGHzVmQGEDzqgvkAdwYQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"min\":{\"__ndarray__\":\"RVhHelrcCEBkpvsBdS8NQE/lo50F7hBAUXGdExXeEUAZw2MHAt4SQIdYCKWscxNAUDXqB47nE0Cw8JPgPE8UQLBsnqndgRRA9mis6ffjFEBoo8t41iYVQIAkPCbNjhVAfovRi4+pFUDpbHpBEt8VQC7fH0lsGBZAPoPtiMshFkBFd2TrSXYWQL7dKhUJixZAMUzuaHirFkAetcjkrMYWQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"num_steps_trained\":[100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000],\"std\":{\"__ndarray__\":\"7sGsGfdL0z+XgUHNoezPP+I75A/Lc8w/d4SkYuwTzD+V+pgQtM/JP3breBjBldA/ouvzkz4u0z+qsHzQNwHWP8EC8D5Jw9Y/M66MgpWt1j9aELKu5UPYP3APNZMS49g/F6bnUa+O2T/lz96cgx/bP8pSTu+QeNw/o2wS8nEB4D8fWpWxEOrfP6+yhdmL2eA/hVQQ5xEN4T8P/BBmsnjhPw==\",\"dtype\":\"float64\",\"shape\":[20]},\"upper\":{\"__ndarray__\":\"djG4/Rl+DkBDCSRrBzQRQCJ2n7SShRJAOHUOvv6GE0BwCI++aWoUQA0oox5TehVAF4/vFuNFFkDeprLag/cWQIwZ6fTsXxdAsxi8HcrHF0B8g3+QYikYQFOV+/amhhhAJFBMUGbPGEA0kGylcC4ZQGLvr4gqgxlARL8Tuob5GUAhFdOqIz8aQKCzh5ywhxpA/utpCvyxGkB1ys0wGAsbQA==\",\"dtype\":\"float64\",\"shape\":[20]}},\"selected\":{\"id\":\"1054\"},\"selection_policy\":{\"id\":\"1053\"}},\"id\":\"1002\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1023\",\"type\":\"ResetTool\"},{\"attributes\":{\"base\":{\"field\":\"num_steps_trained\",\"units\":\"data\"},\"fill_alpha\":0.3,\"level\":\"underlay\",\"line_color\":\"blue\",\"lower\":{\"field\":\"lower\",\"units\":\"data\"},\"source\":{\"id\":\"1002\"},\"upper\":{\"field\":\"upper\",\"units\":\"data\"}},\"id\":\"1042\",\"type\":\"Band\"},{\"attributes\":{},\"id\":\"1050\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"1017\",\"type\":\"BasicTicker\"},{\"attributes\":{},\"id\":\"1024\",\"type\":\"SaveTool\"},{\"attributes\":{},\"id\":\"1008\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"1010\",\"type\":\"LinearScale\"},{\"attributes\":{\"line_alpha\":0.1,\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"1039\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1054\",\"type\":\"Selection\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.3},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"blue\"},\"size\":{\"units\":\"screen\",\"value\":3},\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"1033\",\"type\":\"Scatter\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"num_steps_trained\",\"$x\"],[\"mean\",\"$y\"]]},\"id\":\"1044\",\"type\":\"HoverTool\"},{\"attributes\":{\"text\":\"Cumulative Regret\"},\"id\":\"1046\",\"type\":\"Title\"},{\"attributes\":{\"axis\":{\"id\":\"1012\"},\"grid_line_alpha\":0.5,\"ticker\":null},\"id\":\"1015\",\"type\":\"Grid\"},{\"attributes\":{\"source\":{\"id\":\"1002\"}},\"id\":\"1036\",\"type\":\"CDSView\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1020\"},{\"id\":\"1021\"},{\"id\":\"1022\"},{\"id\":\"1023\"},{\"id\":\"1024\"},{\"id\":\"1044\"}]},\"id\":\"1026\",\"type\":\"Toolbar\"},{\"attributes\":{\"axis\":{\"id\":\"1016\"},\"dimension\":1,\"grid_line_alpha\":0.5,\"ticker\":null},\"id\":\"1019\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":\"cumulative regret\",\"formatter\":{\"id\":\"1052\"},\"ticker\":{\"id\":\"1017\"}},\"id\":\"1016\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"1005\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1052\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1025\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"blue\"},\"size\":{\"units\":\"screen\",\"value\":3},\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"1034\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"1020\",\"type\":\"PanTool\"}],\"root_ids\":[\"1004\"]},\"title\":\"Bokeh Application\",\"version\":\"2.0.1\"}};\n",
       "  var render_items = [{\"docid\":\"20a9f590-536c-4056-bd1e-eeb38e568ec0\",\"root_ids\":[\"1004\"],\"roots\":{\"1004\":\"dc01119d-9b07-4f88-9704-fcb6b5d727a3\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1004"
      }
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=76840)\u001b[0m 2020-06-13 10:30:43,014\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=76840)\u001b[0m 2020-06-13 10:30:43,015\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=76840)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=76840)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=76840)\u001b[0m 2020-06-13 10:30:43,024\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=76840)\u001b[0m 2020-06-13 10:30:43,025\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=76844)\u001b[0m 2020-06-13 10:30:43,013\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=76844)\u001b[0m 2020-06-13 10:30:43,014\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=76844)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=76844)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=76844)\u001b[0m 2020-06-13 10:30:43,024\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=76844)\u001b[0m 2020-06-13 10:30:43,024\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "plot_cumulative_regret(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "([image](../../images/rllib/LinUCB-Cumulative-Regret.png))\n",
    "\n",
    "So the _cummulative_ regret increases for the entire number of training steps for all five trials, but for larger step numbers, the amount of regret added decreases as we learn, so the graph begins to level off as the system gets better at optimizing the mean reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment we're using randomly generates data on every step, so there will always be some regret even if we train for a longer period of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Change the `training_iterations` from 20 to 40. Does the characteristic behavior of cumulative regret change at higher steps?\n",
    "\n",
    "See the [solutions notebook](solutions/Multi-Armed-Bandits-Solutions.ipynb) for discussion of this and the following exercises."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
