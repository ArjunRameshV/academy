{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray RLlib - Linear Upper Confidence Bound\n",
    "\n",
    "© 2019-2020, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../../images/AnyscaleAcademy_Logo_clearbanner_141x100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the [previous lesson](02-Simple-Multi-Armed-Bandit.ipynb), we used _LinUCB_ (Linear Upper Confidence Bound) for the exploration-explotation strategy ([RLlib documentation](https://docs.ray.io/en/latest/rllib-algorithms.html?highlight=greedy#linear-upper-confidence-bound-contrib-linucb)), which assumes a linear dependency between the expected reward of an action and its context. We pointed out that a linear function is of the form $z = ax + by + c$, for example, where $x$, $y$, and $z$ are variables and $a$, $b$, and $c$ are constants. LinUCB models the representation space using a set of linear predictors.\n",
    "\n",
    "Now we'll explore _LinUCB_ in a recommendation environment with _parametric actions_, which are discrete actions that have continuous parameters. At each step, the agent must select which action to use and which parameters to use with that action. \n",
    "\n",
    "From [Sutton 2018](../06-RL-References.ipynb#Books), LinUCB "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References for LinUCB and parameterized actions:\n",
    "\n",
    "* Lihong Li, Wei Chu, John Langford, Robert E. Schapire, \"A contextual-bandit approach to personalized news article recommendation\", Proceedings of the 19th International Conference on World Wide Web (WWW 2010), [pdf](https://arxiv.org/abs/1003.0146).\n",
    "* Wei Chu, Lihong Li, Lev Reyzin, Robert E. Schapire (), \"Contextual bandits with linear payoff functions\" (PDF), Proceedings of the 14th International Conference on Artificial Intelligence and Statistics (AISTATS 2011), [pdf](https://arxiv.org/abs/1003.0146).\n",
    "* T.L. Lai, Herbert Robbins, “Asymptotically efficient adaptive allocation rules”, Advances in Applied Mathematics, Volume 6, Issue 1 (1985), pp 4-22, [link](https://doi.org/10.1016/0196-8858(85)90002-8).\n",
    "* M N Katehakis and H Robbins, “Sequential choice from several populations”, Proc Natl Acad Sci U S A. 1995 Sep 12; 92(19): 8584–8585, [link](https://doi.org/10.1073/pnas.92.19.8584).\n",
    "* Warrick Masson, Pravesh Ranchod, George Konidaris, \"Reinforcement Learning with Parameterized Actions\" [pdf](https://arxiv.org/abs/1509.01644)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from ray import tune\n",
    "from ray.rllib.contrib.bandits.agents import LinUCBTrainer\n",
    "from ray.rllib.contrib.bandits.agents.lin_ucb import UCB_CONFIG\n",
    "from ray.rllib.contrib.bandits.envs import ParametricItemRecoEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `ParametricItemRecoEnv` ([parametric.py](https://github.com/ray-project/ray/blob/master/rllib/contrib/bandits/envs/parametric.py)) as the environment, which is a recommendation environment (\"RecoEnv\") that generates \"items\" with randomly-generated features, some visible and optionally some hidden. The default sizes are governed by `DEFAULT_RECO_CONFIG` also in [parametric.py](https://github.com/ray-project/ray/blob/master/rllib/contrib/bandits/envs/parametric.py)):\n",
    "\n",
    "```python\n",
    "DEFAULT_RECO_CONFIG = {\n",
    "    \"num_users\": 1,        # More than one user at a time?\n",
    "    \"num_items\": 100,      # Number of items to randomly sample.\n",
    "    \"feature_dim\": 16,     # Number of features per item, with randomly generated values\n",
    "    \"slate_size\": 1,       # More than one step at a time?\n",
    "    \"num_candidates\": 25,  # Determines the action space and the the number of items randomly sampled from the num_items items.\n",
    "    \"seed\": 1              # For randomization\n",
    "}\n",
    "```\n",
    "\n",
    "Let's look at the default behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action space: Discrete(25)\n",
      "\n",
      "action = 4, \n",
      "obs:\n",
      "    'item': [[0.10202451 0.19664231 0.44530743 0.25907888 0.1517713  0.20830519\n",
      "  0.39972454 0.26024591 0.09253173 0.19719537 0.16187536 0.43700101\n",
      "  0.0049241  0.34413293 0.0666158  0.06370218]] (25 items), \n",
      "    'item_id': [ 7 74 16 18 62 25 51 48 33 94 85 34 41 69 53 24 77  9 71 45 66  0  5  2\n",
      " 20],\n",
      "    'response': [0.7306249741937558], \n",
      "reward = 0.7306249741937558, \n",
      "finished? = True, \n",
      "info = {'regret': 0.16393385117766057}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pire = ParametricItemRecoEnv()\n",
    "pire.reset()\n",
    "print(f'action space: {pire.action_space}')\n",
    "action = pire.action_space.sample()\n",
    "obs, reward, finished, info = pire.step(action)\n",
    "obs_item_foo = f\"{obs['item'][:1]} ({len(obs['item'])} items)\"\n",
    "print(f\"\"\"\n",
    "action = {action}, \n",
    "obs:\n",
    "    'item': {obs_item_foo}, \n",
    "    'item_id': {obs['item_id']},\n",
    "    'response': {obs['response']}, \n",
    "reward = {reward}, \n",
    "finished? = {finished}, \n",
    "info = {info}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rewards at each step are randomly computed using matrix multiplication of the various randomly-generated matrices of data, followed by selecting a response indexed by the particular action specified to `step`. However, as constructed the reward always comes out between about .64 and .87 and the regret is the maximum value over all possible actions minus the reward for the specified action. In the following `num_candidates` steps, which defaults to 25, you should see one regret of 0.0, which happens to be the maximum possible reward. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0: reward = 0.7055033114274591, regret = 0.1411572092375436\n",
      "  1: reward = 0.7802960917713582, regret = 0.12002323247687607\n",
      "  2: reward = 0.7055033114274591, regret = 0.15768762623138977\n",
      "  3: reward = 0.8461772423074813, regret = 0.04838158306393514\n",
      "  4: reward = 0.8466605206650027, regret = 0.0\n",
      "  5: reward = 0.7992618174651833, regret = 0.10105750678305092\n",
      "  6: reward = 0.6390725545541198, regret = 0.2612467696941144\n",
      "  7: reward = 0.6156676430300783, regret = 0.284651681218156\n",
      "  8: reward = 0.7714667319285453, regret = 0.09575891178979923\n",
      "  9: reward = 0.8461772423074813, regret = 0.021048401410863282\n",
      " 10: reward = 0.7714667319285453, regret = 0.0930994725548352\n",
      " 11: reward = 0.7714667319285453, regret = 0.0930994725548352\n",
      " 12: reward = 0.8001591804210235, regret = 0.04650134024397923\n",
      " 13: reward = 0.6993927265111476, regret = 0.20092659773708665\n",
      " 14: reward = 0.8418776391141665, regret = 0.025348004604178076\n",
      " 15: reward = 0.6467887151108733, regret = 0.2139794535191073\n",
      " 16: reward = 0.621290507114848, regret = 0.2732683182565684\n",
      " 17: reward = 0.7736096803209915, regret = 0.09095652416238897\n",
      " 18: reward = 0.7974956525069589, regret = 0.055077108550380394\n",
      " 19: reward = 0.8645662044833805, regret = 0.0\n",
      " 20: reward = 0.7754896369309914, regret = 0.08527853169898925\n",
      " 21: reward = 0.8297962505893712, regret = 0.07052307365886301\n",
      " 22: reward = 0.7306249741937558, regret = 0.13394123028962468\n",
      " 23: reward = 0.6587764416444625, regret = 0.19379631941287678\n",
      " 24: reward = 0.8299430825373995, regret = 0.06461574283401694\n"
     ]
    }
   ],
   "source": [
    "for i in range(pire.num_candidates):\n",
    "    action = pire.action_space.sample()\n",
    "    obs, reward, finished, info = pire.step(action)\n",
    "    print(f'{i:3d}: reward = {reward}, regret = {info[\"regret\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've explored `ParametricItemRecoEnv`, let's use it with _LinUCB_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running training for 20 time steps\n"
     ]
    }
   ],
   "source": [
    "UCB_CONFIG[\"env\"] = ParametricItemRecoEnv\n",
    "\n",
    "# Actual training_iterations will be 20 * timesteps_per_iteration (100 by default) = 2,000\n",
    "training_iterations = 20\n",
    "\n",
    "print(\"Running training for %s time steps\" % training_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# first argument should no longer be `LinUCBTrainer`\n",
    "\n",
    "analysis = tune.run(\n",
    "    \"contrib/LinUCB\",\n",
    "    config=UCB_CONFIG,\n",
    "    stop={\"training_iteration\": training_iterations},\n",
    "    num_samples=5,\n",
    "    checkpoint_at_end=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 11.0/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 1/8 CPUs, 0/0 GPUs, 0.0/4.2 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (4 PENDING, 1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>PENDING </td><td>     </td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>PENDING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=22756)\u001b[0m 2020-06-08 17:18:32,657\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=22756)\u001b[0m 2020-06-08 17:18:32,658\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=22756)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=22756)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=22755)\u001b[0m 2020-06-08 17:18:32,656\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=22755)\u001b[0m 2020-06-08 17:18:32,657\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=22755)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=22755)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=22759)\u001b[0m 2020-06-08 17:18:32,655\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=22759)\u001b[0m 2020-06-08 17:18:32,656\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=22759)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=22759)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=22756)\u001b[0m 2020-06-08 17:18:32,676\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=22756)\u001b[0m 2020-06-08 17:18:32,676\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=22755)\u001b[0m 2020-06-08 17:18:32,675\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=22755)\u001b[0m 2020-06-08 17:18:32,675\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=22759)\u001b[0m 2020-06-08 17:18:32,673\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=22759)\u001b[0m 2020-06-08 17:18:32,674\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=22757)\u001b[0m 2020-06-08 17:18:32,668\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=22757)\u001b[0m 2020-06-08 17:18:32,669\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=22757)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=22757)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=22757)\u001b[0m 2020-06-08 17:18:32,685\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=22757)\u001b[0m 2020-06-08 17:18:32,685\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "\u001b[2m\u001b[36m(pid=22760)\u001b[0m 2020-06-08 17:18:32,664\tINFO trainer.py:421 -- Tip: set 'eager': true or the --eager flag to enable TensorFlow eager execution\n",
      "\u001b[2m\u001b[36m(pid=22760)\u001b[0m 2020-06-08 17:18:32,666\tINFO trainer.py:580 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(pid=22760)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=22760)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=22760)\u001b[0m 2020-06-08 17:18:32,681\tINFO trainable.py:217 -- Getting current IP.\n",
      "\u001b[2m\u001b[36m(pid=22760)\u001b[0m 2020-06-08 17:18:32,681\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-32\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9193421198898067\n",
      "  episode_reward_mean: 0.8504730639472935\n",
      "  episode_reward_min: 0.648981019691059\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: b06937e7bd4549d4981054d56bd9b0c4\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 0.505\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.505\n",
      "    learner:\n",
      "      cumulative_regret: 3.562272111952385\n",
      "      update_latency: 0.00022792816162109375\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 1979.192\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 696.138\n",
      "    sample_time_ms: 1.436\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.562272111952385\n",
      "    update_latency: 0.00022792816162109375\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1979.192\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 36.9\n",
      "    ram_util_percent: 59.5\n",
      "  pid: 22755\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 696.138\n",
      "  sample_time_ms: 1.436\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.149540381856484\n",
      "    mean_inference_ms: 0.5127581039277633\n",
      "    mean_processing_ms: 0.5190679342439859\n",
      "  time_since_restore: 0.18093609809875488\n",
      "  time_this_iter_s: 0.18093609809875488\n",
      "  time_total_s: 0.18093609809875488\n",
      "  timestamp: 1591661912\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-32\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9375964020601999\n",
      "  episode_reward_mean: 0.8778926704491999\n",
      "  episode_reward_min: 0.6861754491365665\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 603bd38d17124c299d063d39e9f6a262\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 0.472\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.472\n",
      "    learner:\n",
      "      cumulative_regret: 3.602027464895079\n",
      "      update_latency: 0.00019788742065429688\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 2120.049\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 844.451\n",
      "    sample_time_ms: 1.184\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.602027464895079\n",
      "    update_latency: 0.00019788742065429688\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 2120.049\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 36.9\n",
      "    ram_util_percent: 59.5\n",
      "  pid: 22756\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 844.451\n",
      "  sample_time_ms: 1.184\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.14472479867463067\n",
      "    mean_inference_ms: 0.5178994471483892\n",
      "    mean_processing_ms: 0.5531216611956606\n",
      "  time_since_restore: 0.1861867904663086\n",
      "  time_this_iter_s: 0.1861867904663086\n",
      "  time_total_s: 0.1861867904663086\n",
      "  timestamp: 1591661912\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.001\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-32\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8619566422683141\n",
      "  episode_reward_mean: 0.7967517743345232\n",
      "  episode_reward_min: 0.49676967619884926\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: 5f052f26fe604c458e58f04a7b4945ad\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.41\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.41\n",
      "    learner:\n",
      "      cumulative_regret: 3.0690116576021875\n",
      "      update_latency: 0.00018787384033203125\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 2439.116\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 926.202\n",
      "    sample_time_ms: 1.08\n",
      "    update_time_ms: 0.001\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.0690116576021875\n",
      "    update_latency: 0.00018787384033203125\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 2439.116\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 35.7\n",
      "    ram_util_percent: 59.5\n",
      "  pid: 22760\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 926.202\n",
      "  sample_time_ms: 1.08\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.1438891533577796\n",
      "    mean_inference_ms: 0.5135512588047745\n",
      "    mean_processing_ms: 0.5129799984469274\n",
      "  time_since_restore: 0.18122100830078125\n",
      "  time_this_iter_s: 0.18122100830078125\n",
      "  time_total_s: 0.18122100830078125\n",
      "  timestamp: 1591661912\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.001\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-32\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9571880359594797\n",
      "  episode_reward_mean: 0.8768071923367375\n",
      "  episode_reward_min: 0.6743774129388362\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: f43f5309cf454998b4536481c33692a0\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 0.497\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.497\n",
      "    learner:\n",
      "      cumulative_regret: 3.265864204121952\n",
      "      update_latency: 0.0002040863037109375\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 2010.596\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 778.381\n",
      "    sample_time_ms: 1.285\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.265864204121952\n",
      "    update_latency: 0.0002040863037109375\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 2010.596\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 35.7\n",
      "    ram_util_percent: 59.5\n",
      "  pid: 22757\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 778.381\n",
      "  sample_time_ms: 1.285\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.13886347855671802\n",
      "    mean_inference_ms: 0.49309919376184447\n",
      "    mean_processing_ms: 0.5077347897066931\n",
      "  time_since_restore: 0.1739208698272705\n",
      "  time_this_iter_s: 0.1739208698272705\n",
      "  time_total_s: 0.1739208698272705\n",
      "  timestamp: 1591661912\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-32\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9231359674818838\n",
      "  episode_reward_mean: 0.8606859459594375\n",
      "  episode_reward_min: 0.6701725038912261\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 100\n",
      "  experiment_id: fe0a9b9679544688ac0fa819a55d90e1\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 0.423\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.423\n",
      "    learner:\n",
      "      cumulative_regret: 3.3251517747850166\n",
      "      update_latency: 0.00022912025451660156\n",
      "    num_steps_sampled: 100\n",
      "    num_steps_trained: 100\n",
      "    opt_peak_throughput: 2363.787\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 885.715\n",
      "    sample_time_ms: 1.129\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 1\n",
      "  learner:\n",
      "    cumulative_regret: 3.3251517747850166\n",
      "    update_latency: 0.00022912025451660156\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 100\n",
      "  num_steps_trained: 100\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 2363.787\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 35.7\n",
      "    ram_util_percent: 59.5\n",
      "  pid: 22759\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 885.715\n",
      "  sample_time_ms: 1.129\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.14453831285533342\n",
      "    mean_inference_ms: 0.5404642312833579\n",
      "    mean_processing_ms: 0.5316545467565554\n",
      "  time_since_restore: 0.1864020824432373\n",
      "  time_this_iter_s: 0.1864020824432373\n",
      "  time_total_s: 0.1864020824432373\n",
      "  timestamp: 1591661912\n",
      "  timesteps_since_restore: 100\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 100\n",
      "  training_iteration: 1\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 9.5/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/8 CPUs, 0/0 GPUs, 0.0/4.2 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>192.168.1.149:22760</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.181221</td><td style=\"text-align: right;\"> 100</td><td style=\"text-align: right;\">0.796752</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>RUNNING </td><td>192.168.1.149:22757</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.173921</td><td style=\"text-align: right;\"> 100</td><td style=\"text-align: right;\">0.876807</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>RUNNING </td><td>192.168.1.149:22759</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.186402</td><td style=\"text-align: right;\"> 100</td><td style=\"text-align: right;\">0.860686</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>RUNNING </td><td>192.168.1.149:22755</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        0.398609</td><td style=\"text-align: right;\"> 200</td><td style=\"text-align: right;\">0.877462</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>RUNNING </td><td>192.168.1.149:22756</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.186187</td><td style=\"text-align: right;\"> 100</td><td style=\"text-align: right;\">0.877893</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-37\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9571880359594797\n",
      "  episode_reward_mean: 0.9068167257285522\n",
      "  episode_reward_min: 0.8661255888998514\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1800\n",
      "  experiment_id: f43f5309cf454998b4536481c33692a0\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 0.755\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.755\n",
      "    learner:\n",
      "      cumulative_regret: 6.284078888789494\n",
      "      update_latency: 0.0005629062652587891\n",
      "    num_steps_sampled: 1800\n",
      "    num_steps_trained: 1800\n",
      "    opt_peak_throughput: 1324.963\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 194.274\n",
      "    sample_time_ms: 5.147\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 18\n",
      "  learner:\n",
      "    cumulative_regret: 6.284078888789494\n",
      "    update_latency: 0.0005629062652587891\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1800\n",
      "  num_steps_trained: 1800\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1324.963\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 76.0\n",
      "    ram_util_percent: 64.1\n",
      "  pid: 22757\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 194.274\n",
      "  sample_time_ms: 5.147\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.18629082569077837\n",
      "    mean_inference_ms: 0.7561243354843964\n",
      "    mean_processing_ms: 0.6842389495951277\n",
      "  time_since_restore: 4.893651008605957\n",
      "  time_this_iter_s: 0.28208112716674805\n",
      "  time_total_s: 4.893651008605957\n",
      "  timestamp: 1591661917\n",
      "  timesteps_since_restore: 1800\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1800\n",
      "  training_iteration: 18\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-37\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9193421198898067\n",
      "  episode_reward_mean: 0.8853485236525167\n",
      "  episode_reward_min: 0.8098975312529358\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1900\n",
      "  experiment_id: b06937e7bd4549d4981054d56bd9b0c4\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 0.766\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.766\n",
      "    learner:\n",
      "      cumulative_regret: 5.405762417343519\n",
      "      update_latency: 0.00037407875061035156\n",
      "    num_steps_sampled: 1900\n",
      "    num_steps_trained: 1900\n",
      "    opt_peak_throughput: 1305.457\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 733.014\n",
      "    sample_time_ms: 1.364\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 19\n",
      "  learner:\n",
      "    cumulative_regret: 5.405762417343519\n",
      "    update_latency: 0.00037407875061035156\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1900\n",
      "  num_steps_trained: 1900\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1305.457\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 76.0\n",
      "    ram_util_percent: 64.1\n",
      "  pid: 22755\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 733.014\n",
      "  sample_time_ms: 1.364\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.19078202024376562\n",
      "    mean_inference_ms: 0.7007428058381461\n",
      "    mean_processing_ms: 0.722097510227964\n",
      "  time_since_restore: 5.055028915405273\n",
      "  time_this_iter_s: 0.2836289405822754\n",
      "  time_total_s: 5.055028915405273\n",
      "  timestamp: 1591661917\n",
      "  timesteps_since_restore: 1900\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1900\n",
      "  training_iteration: 19\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-38\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9375964020601999\n",
      "  episode_reward_mean: 0.9073429613331007\n",
      "  episode_reward_min: 0.8322799452530216\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1900\n",
      "  experiment_id: 603bd38d17124c299d063d39e9f6a262\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 0.796\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.796\n",
      "    learner:\n",
      "      cumulative_regret: 6.217773705543488\n",
      "      update_latency: 0.00039196014404296875\n",
      "    num_steps_sampled: 1900\n",
      "    num_steps_trained: 1900\n",
      "    opt_peak_throughput: 1256.57\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 686.185\n",
      "    sample_time_ms: 1.457\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 19\n",
      "  learner:\n",
      "    cumulative_regret: 6.217773705543488\n",
      "    update_latency: 0.00039196014404296875\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1900\n",
      "  num_steps_trained: 1900\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1256.57\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 22756\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 686.185\n",
      "  sample_time_ms: 1.457\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.19114823920798266\n",
      "    mean_inference_ms: 0.7042720529796069\n",
      "    mean_processing_ms: 0.8190776849031323\n",
      "  time_since_restore: 5.144121885299683\n",
      "  time_this_iter_s: 0.2770507335662842\n",
      "  time_total_s: 5.144121885299683\n",
      "  timestamp: 1591661918\n",
      "  timesteps_since_restore: 1900\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1900\n",
      "  training_iteration: 19\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.002\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.3/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 5/8 CPUs, 0/0 GPUs, 0.0/4.2 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>RUNNING </td><td>192.168.1.149:22760</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         4.89113</td><td style=\"text-align: right;\">1800</td><td style=\"text-align: right;\">0.828919</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>RUNNING </td><td>192.168.1.149:22757</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         4.89365</td><td style=\"text-align: right;\">1800</td><td style=\"text-align: right;\">0.906817</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>RUNNING </td><td>192.168.1.149:22759</td><td style=\"text-align: right;\">    18</td><td style=\"text-align: right;\">         4.8371 </td><td style=\"text-align: right;\">1800</td><td style=\"text-align: right;\">0.891643</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>RUNNING </td><td>192.168.1.149:22755</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         5.05503</td><td style=\"text-align: right;\">1900</td><td style=\"text-align: right;\">0.885349</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>RUNNING </td><td>192.168.1.149:22756</td><td style=\"text-align: right;\">    19</td><td style=\"text-align: right;\">         5.14412</td><td style=\"text-align: right;\">1900</td><td style=\"text-align: right;\">0.907343</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-38\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8619566422683141\n",
      "  episode_reward_mean: 0.8281987895570359\n",
      "  episode_reward_min: 0.7403604095551464\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1900\n",
      "  experiment_id: 5f052f26fe604c458e58f04a7b4945ad\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.995\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.995\n",
      "    learner:\n",
      "      cumulative_regret: 5.545677306202458\n",
      "      update_latency: 0.0006070137023925781\n",
      "    num_steps_sampled: 1900\n",
      "    num_steps_trained: 1900\n",
      "    opt_peak_throughput: 1004.648\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 601.696\n",
      "    sample_time_ms: 1.662\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 19\n",
      "  learner:\n",
      "    cumulative_regret: 5.545677306202458\n",
      "    update_latency: 0.0006070137023925781\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1900\n",
      "  num_steps_trained: 1900\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1004.648\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 22760\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 601.696\n",
      "  sample_time_ms: 1.662\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.20420519945685453\n",
      "    mean_inference_ms: 0.7889413758367693\n",
      "    mean_processing_ms: 0.6860618149839156\n",
      "  time_since_restore: 5.181869983673096\n",
      "  time_this_iter_s: 0.290740966796875\n",
      "  time_total_s: 5.181869983673096\n",
      "  timestamp: 1591661918\n",
      "  timesteps_since_restore: 1900\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1900\n",
      "  training_iteration: 19\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-38\n",
      "  done: false\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9231359674818838\n",
      "  episode_reward_mean: 0.8885584163302904\n",
      "  episode_reward_min: 0.8218078783202872\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 1900\n",
      "  experiment_id: fe0a9b9679544688ac0fa819a55d90e1\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 0.841\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.841\n",
      "    learner:\n",
      "      cumulative_regret: 5.9735240518050565\n",
      "      update_latency: 0.0006120204925537109\n",
      "    num_steps_sampled: 1900\n",
      "    num_steps_trained: 1900\n",
      "    opt_peak_throughput: 1189.469\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 647.949\n",
      "    sample_time_ms: 1.543\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 19\n",
      "  learner:\n",
      "    cumulative_regret: 5.9735240518050565\n",
      "    update_latency: 0.0006120204925537109\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 1900\n",
      "  num_steps_trained: 1900\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1189.469\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 22759\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 647.949\n",
      "  sample_time_ms: 1.543\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.20556898884620245\n",
      "    mean_inference_ms: 0.8430512311394627\n",
      "    mean_processing_ms: 0.7008550544590274\n",
      "  time_since_restore: 5.09878945350647\n",
      "  time_this_iter_s: 0.2616877555847168\n",
      "  time_total_s: 5.09878945350647\n",
      "  timestamp: 1591661918\n",
      "  timesteps_since_restore: 1900\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 1900\n",
      "  training_iteration: 19\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00003:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-38\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9193421198898067\n",
      "  episode_reward_mean: 0.8866355994334978\n",
      "  episode_reward_min: 0.8229061435149527\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2000\n",
      "  experiment_id: b06937e7bd4549d4981054d56bd9b0c4\n",
      "  experiment_tag: '3'\n",
      "  grad_time_ms: 0.753\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.753\n",
      "    learner:\n",
      "      cumulative_regret: 5.405762417343519\n",
      "      update_latency: 0.0006091594696044922\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    opt_peak_throughput: 1328.867\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 660.292\n",
      "    sample_time_ms: 1.514\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 20\n",
      "  learner:\n",
      "    cumulative_regret: 5.405762417343519\n",
      "    update_latency: 0.0006091594696044922\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 2000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1328.867\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 22755\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 660.292\n",
      "  sample_time_ms: 1.514\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.19030985624893848\n",
      "    mean_inference_ms: 0.7010549977086653\n",
      "    mean_processing_ms: 0.7181260539316523\n",
      "  time_since_restore: 5.310741901397705\n",
      "  time_this_iter_s: 0.25571298599243164\n",
      "  time_total_s: 5.310741901397705\n",
      "  timestamp: 1591661918\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 20\n",
      "  trial_id: '00003'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00004:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-38\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9375964020601999\n",
      "  episode_reward_mean: 0.9063083114126159\n",
      "  episode_reward_min: 0.8344304647101557\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2000\n",
      "  experiment_id: 603bd38d17124c299d063d39e9f6a262\n",
      "  experiment_tag: '4'\n",
      "  grad_time_ms: 0.852\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.852\n",
      "    learner:\n",
      "      cumulative_regret: 6.294415141957784\n",
      "      update_latency: 0.0005848407745361328\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    opt_peak_throughput: 1173.757\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 651.877\n",
      "    sample_time_ms: 1.534\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 20\n",
      "  learner:\n",
      "    cumulative_regret: 6.294415141957784\n",
      "    update_latency: 0.0005848407745361328\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 2000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1173.757\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 22756\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 651.877\n",
      "  sample_time_ms: 1.534\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.19347935780949854\n",
      "    mean_inference_ms: 0.7018112409478242\n",
      "    mean_processing_ms: 0.8112232069085087\n",
      "  time_since_restore: 5.3999316692352295\n",
      "  time_this_iter_s: 0.2558097839355469\n",
      "  time_total_s: 5.3999316692352295\n",
      "  timestamp: 1591661918\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 20\n",
      "  trial_id: '00004'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00000:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-38\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.8619566422683141\n",
      "  episode_reward_mean: 0.8283982086051721\n",
      "  episode_reward_min: 0.7471522199381206\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2000\n",
      "  experiment_id: 5f052f26fe604c458e58f04a7b4945ad\n",
      "  experiment_tag: '0'\n",
      "  grad_time_ms: 0.737\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.737\n",
      "    learner:\n",
      "      cumulative_regret: 5.581993672584786\n",
      "      update_latency: 0.0007529258728027344\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    opt_peak_throughput: 1356.063\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 691.981\n",
      "    sample_time_ms: 1.445\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 20\n",
      "  learner:\n",
      "    cumulative_regret: 5.581993672584786\n",
      "    update_latency: 0.0007529258728027344\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 2000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1356.063\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf: {}\n",
      "  pid: 22760\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 691.981\n",
      "  sample_time_ms: 1.445\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.20239616500801108\n",
      "    mean_inference_ms: 0.7799403301660327\n",
      "    mean_processing_ms: 0.6814023246174153\n",
      "  time_since_restore: 5.413013935089111\n",
      "  time_this_iter_s: 0.23114395141601562\n",
      "  time_total_s: 5.413013935089111\n",
      "  timestamp: 1591661918\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 20\n",
      "  trial_id: '00000'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00001:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-38\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9571880359594797\n",
      "  episode_reward_mean: 0.9102775931332352\n",
      "  episode_reward_min: 0.8437131242437164\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2000\n",
      "  experiment_id: f43f5309cf454998b4536481c33692a0\n",
      "  experiment_tag: '1'\n",
      "  grad_time_ms: 0.902\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 0.902\n",
      "    learner:\n",
      "      cumulative_regret: 6.484602645732837\n",
      "      update_latency: 0.0007300376892089844\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    opt_peak_throughput: 1108.9\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 611.308\n",
      "    sample_time_ms: 1.636\n",
      "    update_time_ms: 0.002\n",
      "  iterations_since_restore: 20\n",
      "  learner:\n",
      "    cumulative_regret: 6.484602645732837\n",
      "    update_latency: 0.0007300376892089844\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 2000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 1108.9\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 77.8\n",
      "    ram_util_percent: 64.8\n",
      "  pid: 22757\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 611.308\n",
      "  sample_time_ms: 1.636\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.18551693982568052\n",
      "    mean_inference_ms: 0.7427944534126373\n",
      "    mean_processing_ms: 0.6774332093215476\n",
      "  time_since_restore: 5.384052991867065\n",
      "  time_this_iter_s: 0.23162007331848145\n",
      "  time_total_s: 5.384052991867065\n",
      "  timestamp: 1591661918\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 20\n",
      "  trial_id: '00001'\n",
      "  update_time_ms: 0.002\n",
      "  \n",
      "Result for contrib_LinUCB_ParametricItemRecoEnv_00002:\n",
      "  custom_metrics: {}\n",
      "  date: 2020-06-08_17-18-38\n",
      "  done: true\n",
      "  episode_len_mean: 1.0\n",
      "  episode_reward_max: 0.9231359674818838\n",
      "  episode_reward_mean: 0.8846147782506328\n",
      "  episode_reward_min: 0.8165427971787758\n",
      "  episodes_this_iter: 100\n",
      "  episodes_total: 2000\n",
      "  experiment_id: fe0a9b9679544688ac0fa819a55d90e1\n",
      "  experiment_tag: '2'\n",
      "  grad_time_ms: 1.051\n",
      "  hostname: DWAnyscaleMBP.local\n",
      "  info:\n",
      "    grad_time_ms: 1.051\n",
      "    learner:\n",
      "      cumulative_regret: 6.038770370716369\n",
      "      update_latency: 0.0007081031799316406\n",
      "    num_steps_sampled: 2000\n",
      "    num_steps_trained: 2000\n",
      "    opt_peak_throughput: 951.068\n",
      "    opt_samples: 1.0\n",
      "    sample_peak_throughput: 532.874\n",
      "    sample_time_ms: 1.877\n",
      "    update_time_ms: 0.003\n",
      "  iterations_since_restore: 20\n",
      "  learner:\n",
      "    cumulative_regret: 6.038770370716369\n",
      "    update_latency: 0.0007081031799316406\n",
      "  node_ip: 192.168.1.149\n",
      "  num_healthy_workers: 0\n",
      "  num_steps_sampled: 2000\n",
      "  num_steps_trained: 2000\n",
      "  off_policy_estimator: {}\n",
      "  opt_peak_throughput: 951.068\n",
      "  opt_samples: 1.0\n",
      "  optimizer_steps_this_iter: 100\n",
      "  perf:\n",
      "    cpu_util_percent: 76.9\n",
      "    ram_util_percent: 64.7\n",
      "  pid: 22759\n",
      "  policy_reward_max: {}\n",
      "  policy_reward_mean: {}\n",
      "  policy_reward_min: {}\n",
      "  sample_peak_throughput: 532.874\n",
      "  sample_time_ms: 1.877\n",
      "  sampler_perf:\n",
      "    mean_env_wait_ms: 0.204299462550524\n",
      "    mean_inference_ms: 0.8329695787863511\n",
      "    mean_processing_ms: 0.6974206931110859\n",
      "  time_since_restore: 5.3472654819488525\n",
      "  time_this_iter_s: 0.2484760284423828\n",
      "  time_total_s: 5.3472654819488525\n",
      "  timestamp: 1591661918\n",
      "  timesteps_since_restore: 2000\n",
      "  timesteps_this_iter: 100\n",
      "  timesteps_total: 2000\n",
      "  training_iteration: 20\n",
      "  trial_id: '00002'\n",
      "  update_time_ms: 0.003\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 10.4/16.0 GiB<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/8 CPUs, 0/0 GPUs, 0.0/4.2 GiB heap, 0.0/1.42 GiB objects<br>Result logdir: /Users/deanwampler/ray_results/contrib/LinUCB<br>Number of trials: 5 (5 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                                </th><th>status    </th><th>loc  </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  ts</th><th style=\"text-align: right;\">  reward</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00000</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5.41301</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">0.828398</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00001</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5.38405</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">0.910278</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00002</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5.34727</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">0.884615</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00003</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5.31074</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">0.886636</td></tr>\n",
       "<tr><td>contrib_LinUCB_ParametricItemRecoEnv_00004</td><td>TERMINATED</td><td>     </td><td style=\"text-align: right;\">    20</td><td style=\"text-align: right;\">         5.39993</td><td style=\"text-align: right;\">2000</td><td style=\"text-align: right;\">0.906308</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The trials took 10.629887104034424 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"The trials took\", time.time() - start_time, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_reward_max</th>\n",
       "      <th>episode_reward_min</th>\n",
       "      <th>episode_reward_mean</th>\n",
       "      <th>episode_len_mean</th>\n",
       "      <th>episodes_this_iter</th>\n",
       "      <th>num_steps_trained</th>\n",
       "      <th>num_steps_sampled</th>\n",
       "      <th>sample_time_ms</th>\n",
       "      <th>grad_time_ms</th>\n",
       "      <th>update_time_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>config/seed</th>\n",
       "      <th>config/shuffle_buffer_size</th>\n",
       "      <th>config/soft_horizon</th>\n",
       "      <th>config/synchronize_filters</th>\n",
       "      <th>config/tf_session_args</th>\n",
       "      <th>config/timesteps_per_iteration</th>\n",
       "      <th>config/train_batch_size</th>\n",
       "      <th>config/use_exec_api</th>\n",
       "      <th>config/use_pytorch</th>\n",
       "      <th>logdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.861957</td>\n",
       "      <td>0.747152</td>\n",
       "      <td>0.828398</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.445</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'allow_soft_placement': True, 'device_count':...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.957188</td>\n",
       "      <td>0.843713</td>\n",
       "      <td>0.910278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.636</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'allow_soft_placement': True, 'device_count':...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.923136</td>\n",
       "      <td>0.816543</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.877</td>\n",
       "      <td>1.051</td>\n",
       "      <td>0.003</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'allow_soft_placement': True, 'device_count':...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.919342</td>\n",
       "      <td>0.822906</td>\n",
       "      <td>0.886636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.514</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'allow_soft_placement': True, 'device_count':...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.937596</td>\n",
       "      <td>0.834430</td>\n",
       "      <td>0.906308</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1.534</td>\n",
       "      <td>0.852</td>\n",
       "      <td>0.002</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>{'allow_soft_placement': True, 'device_count':...</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>/Users/deanwampler/ray_results/contrib/LinUCB/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_reward_max  episode_reward_min  episode_reward_mean  \\\n",
       "0            0.861957            0.747152             0.828398   \n",
       "1            0.957188            0.843713             0.910278   \n",
       "2            0.923136            0.816543             0.884615   \n",
       "3            0.919342            0.822906             0.886636   \n",
       "4            0.937596            0.834430             0.906308   \n",
       "\n",
       "   episode_len_mean  episodes_this_iter  num_steps_trained  num_steps_sampled  \\\n",
       "0               1.0                 100               2000               2000   \n",
       "1               1.0                 100               2000               2000   \n",
       "2               1.0                 100               2000               2000   \n",
       "3               1.0                 100               2000               2000   \n",
       "4               1.0                 100               2000               2000   \n",
       "\n",
       "   sample_time_ms  grad_time_ms  update_time_ms  ...  config/seed  \\\n",
       "0           1.445         0.737           0.002  ...         None   \n",
       "1           1.636         0.902           0.002  ...         None   \n",
       "2           1.877         1.051           0.003  ...         None   \n",
       "3           1.514         0.753           0.002  ...         None   \n",
       "4           1.534         0.852           0.002  ...         None   \n",
       "\n",
       "   config/shuffle_buffer_size  config/soft_horizon  \\\n",
       "0                           0                False   \n",
       "1                           0                False   \n",
       "2                           0                False   \n",
       "3                           0                False   \n",
       "4                           0                False   \n",
       "\n",
       "   config/synchronize_filters  \\\n",
       "0                        True   \n",
       "1                        True   \n",
       "2                        True   \n",
       "3                        True   \n",
       "4                        True   \n",
       "\n",
       "                              config/tf_session_args  \\\n",
       "0  {'allow_soft_placement': True, 'device_count':...   \n",
       "1  {'allow_soft_placement': True, 'device_count':...   \n",
       "2  {'allow_soft_placement': True, 'device_count':...   \n",
       "3  {'allow_soft_placement': True, 'device_count':...   \n",
       "4  {'allow_soft_placement': True, 'device_count':...   \n",
       "\n",
       "   config/timesteps_per_iteration  config/train_batch_size  \\\n",
       "0                             100                        1   \n",
       "1                             100                        1   \n",
       "2                             100                        1   \n",
       "3                             100                        1   \n",
       "4                             100                        1   \n",
       "\n",
       "   config/use_exec_api  config/use_pytorch  \\\n",
       "0                False                True   \n",
       "1                False                True   \n",
       "2                False                True   \n",
       "3                False                True   \n",
       "4                False                True   \n",
       "\n",
       "                                              logdir  \n",
       "0  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "1  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "2  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "3  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "4  /Users/deanwampler/ray_results/contrib/LinUCB/...  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = analysis.dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze cumulative regrets of the trials\n",
    "frame = pd.DataFrame()\n",
    "\n",
    "for key, df in analysis.trial_dataframes.items():\n",
    "    frame = frame.append(df, ignore_index=True)\n",
    "\n",
    "df = frame.groupby(\"num_steps_trained\")[\n",
    "    \"learner/cumulative_regret\"].aggregate([\"mean\", \"max\", \"min\", \"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_steps_trained</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3.364865</td>\n",
       "      <td>3.602027</td>\n",
       "      <td>3.069012</td>\n",
       "      <td>0.220297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>3.988380</td>\n",
       "      <td>4.367711</td>\n",
       "      <td>3.842540</td>\n",
       "      <td>0.219889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>4.303345</td>\n",
       "      <td>4.760648</td>\n",
       "      <td>4.115545</td>\n",
       "      <td>0.261865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>4.649001</td>\n",
       "      <td>4.978133</td>\n",
       "      <td>4.445932</td>\n",
       "      <td>0.223887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>4.859206</td>\n",
       "      <td>5.296558</td>\n",
       "      <td>4.560299</td>\n",
       "      <td>0.291189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>5.012710</td>\n",
       "      <td>5.385695</td>\n",
       "      <td>4.717595</td>\n",
       "      <td>0.282159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>5.103951</td>\n",
       "      <td>5.428125</td>\n",
       "      <td>4.740504</td>\n",
       "      <td>0.282206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>5.217915</td>\n",
       "      <td>5.556915</td>\n",
       "      <td>4.822609</td>\n",
       "      <td>0.328547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>5.325117</td>\n",
       "      <td>5.666710</td>\n",
       "      <td>4.924149</td>\n",
       "      <td>0.338508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>5.410992</td>\n",
       "      <td>5.780081</td>\n",
       "      <td>4.950459</td>\n",
       "      <td>0.397302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>5.455029</td>\n",
       "      <td>5.830055</td>\n",
       "      <td>4.976492</td>\n",
       "      <td>0.402286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>5.520911</td>\n",
       "      <td>5.920652</td>\n",
       "      <td>5.026786</td>\n",
       "      <td>0.414034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>5.576687</td>\n",
       "      <td>6.032741</td>\n",
       "      <td>5.111148</td>\n",
       "      <td>0.415110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>5.640186</td>\n",
       "      <td>6.057465</td>\n",
       "      <td>5.200415</td>\n",
       "      <td>0.391022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>5.683631</td>\n",
       "      <td>6.086379</td>\n",
       "      <td>5.228284</td>\n",
       "      <td>0.380996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>5.730266</td>\n",
       "      <td>6.160778</td>\n",
       "      <td>5.240823</td>\n",
       "      <td>0.406403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>5.787357</td>\n",
       "      <td>6.216348</td>\n",
       "      <td>5.281487</td>\n",
       "      <td>0.420176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>5.849899</td>\n",
       "      <td>6.284079</td>\n",
       "      <td>5.379045</td>\n",
       "      <td>0.413243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>5.908594</td>\n",
       "      <td>6.400233</td>\n",
       "      <td>5.405762</td>\n",
       "      <td>0.426047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>5.961109</td>\n",
       "      <td>6.484603</td>\n",
       "      <td>5.405762</td>\n",
       "      <td>0.459159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       mean       max       min       std\n",
       "num_steps_trained                                        \n",
       "100                3.364865  3.602027  3.069012  0.220297\n",
       "200                3.988380  4.367711  3.842540  0.219889\n",
       "300                4.303345  4.760648  4.115545  0.261865\n",
       "400                4.649001  4.978133  4.445932  0.223887\n",
       "500                4.859206  5.296558  4.560299  0.291189\n",
       "600                5.012710  5.385695  4.717595  0.282159\n",
       "700                5.103951  5.428125  4.740504  0.282206\n",
       "800                5.217915  5.556915  4.822609  0.328547\n",
       "900                5.325117  5.666710  4.924149  0.338508\n",
       "1000               5.410992  5.780081  4.950459  0.397302\n",
       "1100               5.455029  5.830055  4.976492  0.402286\n",
       "1200               5.520911  5.920652  5.026786  0.414034\n",
       "1300               5.576687  6.032741  5.111148  0.415110\n",
       "1400               5.640186  6.057465  5.200415  0.391022\n",
       "1500               5.683631  6.086379  5.228284  0.380996\n",
       "1600               5.730266  6.160778  5.240823  0.406403\n",
       "1700               5.787357  6.216348  5.281487  0.420176\n",
       "1800               5.849899  6.284079  5.379045  0.413243\n",
       "1900               5.908594  6.400233  5.405762  0.426047\n",
       "2000               5.961109  6.484603  5.405762  0.459159"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\": \"JpP8FXbgAZLkfur7LiK3j9AGBhHNIvF742meBJrjO2ShJDhCG2I1uVvW+0DUtrmc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\": \"xZlADit0Q04ISQEdKg2k3L4W9AwQBAuDs9nJL9fM/WwzL1tEU9VPNezOFX0nLEAz\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\": \"4BuPRZkdMKSnj3zoxiNrQ86XgNw0rYmBOxe7nshquXwwcauupgBF2DHLVG1WuZlV\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\": \"Dv1SQ87hmDqK6S5OhBf0bCuwAEvL5QYL0PuR/F1SPVhCS/r/abjkbpKDYL2zeM19\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\": \"JpP8FXbgAZLkfur7LiK3j9AGBhHNIvF742meBJrjO2ShJDhCG2I1uVvW+0DUtrmc\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\": \"xZlADit0Q04ISQEdKg2k3L4W9AwQBAuDs9nJL9fM/WwzL1tEU9VPNezOFX0nLEAz\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\": \"4BuPRZkdMKSnj3zoxiNrQ86XgNw0rYmBOxe7nshquXwwcauupgBF2DHLVG1WuZlV\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\": \"Dv1SQ87hmDqK6S5OhBf0bCuwAEvL5QYL0PuR/F1SPVhCS/r/abjkbpKDYL2zeM19\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.0.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.0.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.models import Band, ColumnDataSource, Range1d\n",
    "import bokeh.io\n",
    "# The next two lines prevent Bokeh from opening the graph in a new window.\n",
    "bokeh.io.reset_output()\n",
    "bokeh.io.output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"b44576bd-f29a-40c5-9959-ea4ee9b17632\" data-root-id=\"2333\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"76a8df43-84e9-4da9-8d90-c9d51b8a9a49\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"2341\"}],\"center\":[{\"id\":\"2344\"},{\"id\":\"2348\"},{\"id\":\"2366\"}],\"left\":[{\"id\":\"2345\"}],\"renderers\":[{\"id\":\"2364\"}],\"title\":{\"id\":\"2368\"},\"toolbar\":{\"id\":\"2355\"},\"x_range\":{\"id\":\"2334\"},\"x_scale\":{\"id\":\"2337\"},\"y_range\":{\"id\":\"2332\"},\"y_scale\":{\"id\":\"2339\"}},\"id\":\"2333\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"axis\":{\"id\":\"2341\"},\"grid_line_alpha\":0.5,\"ticker\":null},\"id\":\"2344\",\"type\":\"Grid\"},{\"attributes\":{\"axis\":{\"id\":\"2345\"},\"dimension\":1,\"grid_line_alpha\":0.5,\"ticker\":null},\"id\":\"2348\",\"type\":\"Grid\"},{\"attributes\":{\"axis_label\":\"Regret\",\"formatter\":{\"id\":\"2453\"},\"ticker\":{\"id\":\"2346\"}},\"id\":\"2345\",\"type\":\"LinearAxis\"},{\"attributes\":{\"base\":{\"field\":\"num_steps_trained\",\"units\":\"data\"},\"fill_alpha\":0.3,\"level\":\"underlay\",\"line_color\":\"blue\",\"lower\":{\"field\":\"lower\",\"units\":\"data\"},\"source\":{\"id\":\"2331\"},\"upper\":{\"field\":\"upper\",\"units\":\"data\"}},\"id\":\"2366\",\"type\":\"Band\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"2363\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"2346\",\"type\":\"BasicTicker\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"2354\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.3},\"fill_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":5},\"x\":{\"field\":\"num_steps_trained\"},\"y\":{\"field\":\"mean\"}},\"id\":\"2362\",\"type\":\"Scatter\"},{\"attributes\":{},\"id\":\"2349\",\"type\":\"PanTool\"},{\"attributes\":{\"end\":6.420267898429099,\"start\":3.1445684268875578},\"id\":\"2332\",\"type\":\"Range1d\"},{\"attributes\":{},\"id\":\"2334\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data\":{\"index\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],\"lower\":{\"__ndarray__\":\"PCHMfRMoCUA7QPbd3iUOQPAgq6x5KhBA5kQtPlGzEUB5BT5NpkUSQK4NyXwV7BJANaiYsXdJE0AyfVd0to4TQAwSfaxJ8hNA4DJZ7QQOFECrSO0vAjYUQOVNYS1xbRRANK54P3SlFEAbzXioJP8UQEcZ6R7mNRVA3AeSrKJLFUDm46B8/ncVQFRKzNIivxVAgw+KxCDuFUCqe+wg/wEWQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"max\":{\"__ndarray__\":\"LCWIxvPQDEA9ips7iXgRQKqNpFvnChNAlAIespvpE0BdZVvvrC8VQFH3MJnzihVACRfBdGa2FUCIva/fRzoWQPl29Ce2qhZALI9od80eF0BpvhHw+VEXQNbTNIe/rhdAJGGOw4YhGEApbvwE2DoYQKW3FaRzWBhAJSFaFaOkGECxm9dCit0YQO9Wg5PlIhlAHDg4mdaZGUAT6QutO/AZQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"mean\":{\"__ndarray__\":\"ELa9kj7rCkAQqxXMM+gPQPPhYf2fNhFASMnhwZOYEkAn4vym028TQNqrasoDDRRAKINmNXJqFEAA2EkgJd8UQCNYNpnrTBVAfzoxM9ukFUBmHu0Z89EVQDpZe5hpFRZAfld26IZOFkCsOffWjI8WQKqTl9YJvBZALHaRv8rrFkDm85j7QCYXQDvH+fxLZhdANYd7eWaiF0Bj3RTrLNgXQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"min\":{\"__ndarray__\":\"nI3j+1WNCECMaganhb0OQK+T8olRdhBANl/CdaLIEUACt6j8vj0SQGh0nVDR3hJAzd2cw0b2EkA9PtUBWkoTQHjcnyVUshNAnPcVLkXNE0Cs+yaU7ecTQHbyObBtGxRA8wGs3NBxFEC0wYh2Oc0UQBlVQlnD6RRAWgfwY5r2FEAWXss7PiAVQLfkUWMkhBVAyr7hLoCfFUDKvuEugJ8VQA==\",\"dtype\":\"float64\",\"shape\":[20]},\"num_steps_trained\":[100,200,300,400,500,600,700,800,900,1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000],\"std\":{\"__ndarray__\":\"Pk0ZT7EyzD9LrfbhTiXMPzgQbAtlwtA/RIyQdlCozD/kyu2b1aLSP8LiGdrkDtI/Ma/dPKgP0j/ZrCW/6gbVP21hlMseqtU/83mAXWRt2T+3W/2fDr/ZP0u1oLGGf9o/nZTajyqR2j8UyebnggbZPzam53o7Ytg/BeX2L4EC2j8HAIHvJ+TaP2vO16KScto/HXsXT1tE2z+WG4ai3GLdPw==\",\"dtype\":\"float64\",\"shape\":[20]},\"upper\":{\"__ndarray__\":\"5Eqvp2muDEDyihpdRNUQQPaiGE7GQhJAqk2WRdZ9E0DVvrsAAZoUQAZKDBjyLRVAG140uWyLFUDOMjzMky8WQDqe74WNpxZAHkIJebE7F0Ah9OwD5G0XQI9klQNivRdAyAB0kZn3F0A9pnUF9R8YQA0ORo4tQhhAfOSQ0vKLGEDmA5F6g9QYQCJEJyd1DRlA5/5sLqxWGUAcPz21Wq4ZQA==\",\"dtype\":\"float64\",\"shape\":[20]}},\"selected\":{\"id\":\"2457\"},\"selection_policy\":{\"id\":\"2456\"}},\"id\":\"2331\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"source\":{\"id\":\"2331\"}},\"id\":\"2365\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"2350\",\"type\":\"WheelZoomTool\"},{\"attributes\":{\"text\":\"Cumulative Regret\"},\"id\":\"2368\",\"type\":\"Title\"},{\"attributes\":{\"overlay\":{\"id\":\"2354\"}},\"id\":\"2351\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"2456\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"2457\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"2352\",\"type\":\"ResetTool\"},{\"attributes\":{\"axis_label\":\"Training Steps\",\"formatter\":{\"id\":\"2455\"},\"ticker\":{\"id\":\"2342\"}},\"id\":\"2341\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"2453\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"2353\",\"type\":\"SaveTool\"},{\"attributes\":{\"data_source\":{\"id\":\"2331\"},\"glyph\":{\"id\":\"2362\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"2363\"},\"selection_glyph\":null,\"view\":{\"id\":\"2365\"}},\"id\":\"2364\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"2349\"},{\"id\":\"2350\"},{\"id\":\"2351\"},{\"id\":\"2352\"},{\"id\":\"2353\"}]},\"id\":\"2355\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"2339\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"2455\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"2337\",\"type\":\"LinearScale\"},{\"attributes\":{},\"id\":\"2342\",\"type\":\"BasicTicker\"}],\"root_ids\":[\"2333\"]},\"title\":\"Bokeh Application\",\"version\":\"2.0.1\"}};\n",
       "  var render_items = [{\"docid\":\"76a8df43-84e9-4da9-8d90-c9d51b8a9a49\",\"root_ids\":[\"2333\"],\"roots\":{\"2333\":\"b44576bd-f29a-40c5-9959-ea4ee9b17632\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "2333"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['lower'] = df['mean'] - df['std']\n",
    "df['upper'] = df['mean'] + df['std']\n",
    "ymin=df['lower'].min()\n",
    "ymax=df['upper'].max()\n",
    "\n",
    "source = ColumnDataSource(df.reset_index())\n",
    "\n",
    "TOOLS = \"pan,wheel_zoom,box_zoom,reset,save\"\n",
    "p = figure(tools=TOOLS, y_range=Range1d(ymin,ymax))\n",
    "\n",
    "p.scatter(x='num_steps_trained', y='mean', line_color='black', fill_alpha=0.3, size=5, source=source)\n",
    "band = Band(base='num_steps_trained', lower='lower', upper='upper', source=source, level='underlay',\n",
    "            fill_alpha=0.3, line_width=1, line_color='blue')\n",
    "p.add_layout(band)\n",
    "\n",
    "p.title.text = \"Cumulative Regret\"\n",
    "p.xgrid[0].grid_line_alpha=0.5\n",
    "p.ygrid[0].grid_line_alpha=0.5\n",
    "p.xaxis.axis_label = 'Training Steps'\n",
    "p.yaxis.axis_label = 'Regret'\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the cummulative regret increases, then begins to level off as the system gets better at optimizing the mean reward."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
