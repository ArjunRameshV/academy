{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray RLlib - Explore RLlib - Custom Environments and Reward Shaping\n",
    "\n",
    "Â© 2019-2020, Anyscale. All Rights Reserved\n",
    "\n",
    "![Anyscale Academy](../../images/AnyscaleAcademy_Logo_clearbanner_141x100.png)\n",
    "\n",
    "This lesson demonstrates how to adapt your own problem to use [Ray RLlib](http://rllib.io).\n",
    "\n",
    "We cover two important concepts: \n",
    "\n",
    "1. How to create your own _Markov Decision Process_ abstraction.\n",
    "2. How to shape the reward of your environment so make your agent more effective. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json, os, shutil, sys\n",
    "import gym\n",
    "\n",
    "import ray\n",
    "from ray.rllib.agents.ppo import PPOTrainer, DEFAULT_CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../..') # so we can import from \"util\"\n",
    "from util.line_plots import plot_line, plot_line_with_min_max, plot_line_with_stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Ray is already running.\n"
     ]
    }
   ],
   "source": [
    "!../../tools/start-ray.sh --check --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.149',\n",
       " 'raylet_ip_address': '192.168.1.149',\n",
       " 'redis_address': '192.168.1.149:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-06-28_07-02-18_715649_66267/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-06-28_07-02-18_715649_66267/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-06-28_07-02-18_715649_66267'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(address='auto', ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard URL: http://localhost:8265\n"
     ]
    }
   ],
   "source": [
    "print(f'Dashboard URL: http://{ray.get_webui_url()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do when formulating an RL problem is to specify the dimensions of your observation space and action space. Abstractions for these are provided in Gym. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Different Actions to Their Corresponding Space\n",
    "\n",
    "Let's familiarize ourselves with different Gym spaces. For example:\n",
    "\n",
    "    discrete = spaces.Discrete(10)\n",
    "    print(\"Random sample of this space: \", [discrete.sample() for i in range(4)])\n",
    "\n",
    "Use `help(gym.spaces)` or `help([specific space])` (i.e., `help(gym.spaces.Discrete)`) for more info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package gym.spaces in gym:\n",
      "\n",
      "NAME\n",
      "    gym.spaces\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    box\n",
      "    dict\n",
      "    discrete\n",
      "    multi_binary\n",
      "    multi_discrete\n",
      "    space\n",
      "    tests (package)\n",
      "    tuple\n",
      "    utils\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        gym.spaces.space.Space\n",
      "            gym.spaces.box.Box\n",
      "            gym.spaces.dict.Dict\n",
      "            gym.spaces.discrete.Discrete\n",
      "            gym.spaces.multi_binary.MultiBinary\n",
      "            gym.spaces.multi_discrete.MultiDiscrete\n",
      "            gym.spaces.tuple.Tuple\n",
      "    \n",
      "    class Box(gym.spaces.space.Space)\n",
      "     |  Box(low, high, shape=None, dtype=<class 'numpy.float32'>)\n",
      "     |  \n",
      "     |  A (possibly unbounded) box in R^n. Specifically, a Box represents the\n",
      "     |  Cartesian product of n closed intervals. Each interval has the form of one\n",
      "     |  of [a, b], (-oo, b], [a, oo), or (-oo, oo).\n",
      "     |  \n",
      "     |  There are two common use cases:\n",
      "     |  \n",
      "     |  * Identical bound for each dimension::\n",
      "     |      >>> Box(low=-1.0, high=2.0, shape=(3, 4), dtype=np.float32)\n",
      "     |      Box(3, 4)\n",
      "     |      \n",
      "     |  * Independent bound for each dimension::\n",
      "     |      >>> Box(low=np.array([-1.0, -2.0]), high=np.array([2.0, 4.0]), dtype=np.float32)\n",
      "     |      Box(2,)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Box\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __init__(self, low, high, shape=None, dtype=<class 'numpy.float32'>)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  is_bounded(self, manner='both')\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Generates a single random sample inside of the Box. \n",
      "     |      \n",
      "     |      In creating a sample of the box, each coordinate is sampled according to\n",
      "     |      the form of the interval:\n",
      "     |      \n",
      "     |      * [a, b] : uniform distribution \n",
      "     |      * [a, oo) : shifted exponential distribution\n",
      "     |      * (-oo, b] : shifted negative exponential distribution\n",
      "     |      * (-oo, oo) : normal distribution\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Dict(gym.spaces.space.Space)\n",
      "     |  Dict(spaces=None, **spaces_kwargs)\n",
      "     |  \n",
      "     |  A dictionary of simpler spaces.\n",
      "     |  \n",
      "     |  Example usage:\n",
      "     |  self.observation_space = spaces.Dict({\"position\": spaces.Discrete(2), \"velocity\": spaces.Discrete(3)})\n",
      "     |  \n",
      "     |  Example usage [nested]:\n",
      "     |  self.nested_observation_space = spaces.Dict({\n",
      "     |      'sensors':  spaces.Dict({\n",
      "     |          'position': spaces.Box(low=-100, high=100, shape=(3,)),\n",
      "     |          'velocity': spaces.Box(low=-1, high=1, shape=(3,)),\n",
      "     |          'front_cam': spaces.Tuple((\n",
      "     |              spaces.Box(low=0, high=1, shape=(10, 10, 3)),\n",
      "     |              spaces.Box(low=0, high=1, shape=(10, 10, 3))\n",
      "     |          )),\n",
      "     |          'rear_cam': spaces.Box(low=0, high=1, shape=(10, 10, 3)),\n",
      "     |      }),\n",
      "     |      'ext_controller': spaces.MultiDiscrete((5, 2, 2)),\n",
      "     |      'inner_state':spaces.Dict({\n",
      "     |          'charge': spaces.Discrete(100),\n",
      "     |          'system_checks': spaces.MultiBinary(10),\n",
      "     |          'job_status': spaces.Dict({\n",
      "     |              'task': spaces.Discrete(5),\n",
      "     |              'progress': spaces.Box(low=0, high=100, shape=()),\n",
      "     |          })\n",
      "     |      })\n",
      "     |  })\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Dict\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __getitem__(self, key)\n",
      "     |  \n",
      "     |  __init__(self, spaces=None, **spaces_kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Discrete(gym.spaces.space.Space)\n",
      "     |  Discrete(n)\n",
      "     |  \n",
      "     |  A discrete space in :math:`\\{ 0, 1, \\\\dots, n-1 \\}`. \n",
      "     |  \n",
      "     |  Example::\n",
      "     |  \n",
      "     |      >>> Discrete(2)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Discrete\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __init__(self, n)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MultiBinary(gym.spaces.space.Space)\n",
      "     |  MultiBinary(n)\n",
      "     |  \n",
      "     |  An n-dimensional binary space. \n",
      "     |  \n",
      "     |  The argument to MultiBinary defines n.\n",
      "     |  \n",
      "     |  Example Usage:\n",
      "     |  \n",
      "     |  >> self.observation_space = spaces.MultiBinary(5)\n",
      "     |  \n",
      "     |  >> self.observation_space.sample()\n",
      "     |  \n",
      "     |      array([0,1,0,1,0], dtype =int8)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MultiBinary\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __init__(self, n)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class MultiDiscrete(gym.spaces.space.Space)\n",
      "     |  MultiDiscrete(nvec)\n",
      "     |  \n",
      "     |  - The multi-discrete action space consists of a series of discrete action spaces with different number of actions in eachs\n",
      "     |  - It is useful to represent game controllers or keyboards where each key can be represented as a discrete action space\n",
      "     |  - It is parametrized by passing an array of positive integers specifying number of actions for each discrete action space\n",
      "     |  \n",
      "     |  Note: Some environment wrappers assume a value of 0 always represents the NOOP action.\n",
      "     |  \n",
      "     |  e.g. Nintendo Game Controller\n",
      "     |  - Can be conceptualized as 3 discrete action spaces:\n",
      "     |  \n",
      "     |      1) Arrow Keys: Discrete 5  - NOOP[0], UP[1], RIGHT[2], DOWN[3], LEFT[4]  - params: min: 0, max: 4\n",
      "     |      2) Button A:   Discrete 2  - NOOP[0], Pressed[1] - params: min: 0, max: 1\n",
      "     |      3) Button B:   Discrete 2  - NOOP[0], Pressed[1] - params: min: 0, max: 1\n",
      "     |  \n",
      "     |  - Can be initialized as\n",
      "     |  \n",
      "     |      MultiDiscrete([ 5, 2, 2 ])\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MultiDiscrete\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __init__(self, nvec)\n",
      "     |      nvec: vector of counts of each categorical variable\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Space(builtins.object)\n",
      "     |  Space(shape=None, dtype=None)\n",
      "     |  \n",
      "     |  Defines the observation and action spaces, so you can write generic\n",
      "     |  code that applies to any Env. For example, you can choose a random\n",
      "     |  action.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  __init__(self, shape=None, dtype=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class Tuple(gym.spaces.space.Space)\n",
      "     |  Tuple(spaces)\n",
      "     |  \n",
      "     |  A tuple (i.e., product) of simpler spaces\n",
      "     |  \n",
      "     |  Example usage:\n",
      "     |  self.observation_space = spaces.Tuple((spaces.Discrete(2), spaces.Discrete(3)))\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Tuple\n",
      "     |      gym.spaces.space.Space\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __eq__(self, other)\n",
      "     |      Return self==value.\n",
      "     |  \n",
      "     |  __getitem__(self, index)\n",
      "     |  \n",
      "     |  __init__(self, spaces)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  contains(self, x)\n",
      "     |      Return boolean specifying if x is a valid\n",
      "     |      member of this space\n",
      "     |  \n",
      "     |  from_jsonable(self, sample_n)\n",
      "     |      Convert a JSONable data type to a batch of samples from this space.\n",
      "     |  \n",
      "     |  sample(self)\n",
      "     |      Randomly sample an element of this space. Can be \n",
      "     |      uniform or non-uniform sampling based on boundedness of space.\n",
      "     |  \n",
      "     |  seed(self, seed=None)\n",
      "     |      Seed the PRNG of this space.\n",
      "     |  \n",
      "     |  to_jsonable(self, sample_n)\n",
      "     |      Convert a batch of samples from this space to a JSONable data type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __contains__(self, x)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from gym.spaces.space.Space:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    flatdim(space)\n",
      "    \n",
      "    flatten(space, x)\n",
      "    \n",
      "    unflatten(space, x)\n",
      "\n",
      "DATA\n",
      "    __all__ = ['Space', 'Box', 'Discrete', 'MultiDiscrete', 'MultiBinary',...\n",
      "\n",
      "FILE\n",
      "    /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/spaces/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gym.spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Discrete in module gym.spaces.discrete:\n",
      "\n",
      "class Discrete(gym.spaces.space.Space)\n",
      " |  Discrete(n)\n",
      " |  \n",
      " |  A discrete space in :math:`\\{ 0, 1, \\\\dots, n-1 \\}`. \n",
      " |  \n",
      " |  Example::\n",
      " |  \n",
      " |      >>> Discrete(2)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Discrete\n",
      " |      gym.spaces.space.Space\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __eq__(self, other)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __init__(self, n)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  contains(self, x)\n",
      " |      Return boolean specifying if x is a valid\n",
      " |      member of this space\n",
      " |  \n",
      " |  sample(self)\n",
      " |      Randomly sample an element of this space. Can be \n",
      " |      uniform or non-uniform sampling based on boundedness of space.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gym.spaces.space.Space:\n",
      " |  \n",
      " |  __contains__(self, x)\n",
      " |  \n",
      " |  from_jsonable(self, sample_n)\n",
      " |      Convert a JSONable data type to a batch of samples from this space.\n",
      " |  \n",
      " |  seed(self, seed=None)\n",
      " |      Seed the PRNG of this space.\n",
      " |  \n",
      " |  to_jsonable(self, sample_n)\n",
      " |      Convert a batch of samples from this space to a JSONable data type.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gym.spaces.space.Space:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(gym.spaces.Discrete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the following example values in `action_space_examples` that the correspond to the declares spaces in `action_space_map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float64\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from gym import spaces\n",
    "\n",
    "action_space_map = {\n",
    "    \"discrete_10\": spaces.Discrete(10),\n",
    "    \"box_1\": spaces.Box(0, 1, shape=(1,), dtype=np.float64),  # the dtype can be omitted.\n",
    "    \"box_3x1\": spaces.Box(-2, 2, shape=(3, 1), dtype=np.float64),\n",
    "    \"multi_discrete\": spaces.MultiDiscrete([ 5, 2, 2, 4 ])\n",
    "}\n",
    "\n",
    "action_space_examples = {\n",
    "    \"discrete_10\": 1,\n",
    "    \"box_1\": np.array([0.89089584]),\n",
    "    \"box_3x1\": np.array([[-1.2657754], [-1.6528835], [ 0.5982418]]),\n",
    "    \"multi_discrete\": np.array([0, 0, 0, 2]),\n",
    "}\n",
    "\n",
    "for space_id, state in action_space_examples.items():\n",
    "    assert action_space_map[space_id].contains(state), (f'Looks like {space_id} to {state} is matched incorrectly.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a space with 10 discrete values, 0 through 9, from which we sample and then update a counts map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 15, 1: 24, 2: 16, 3: 19, 4: 21, 5: 24, 6: 22, 7: 11, 8: 27, 9: 21}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = {key:0 for key in range(10)}\n",
    "counts\n",
    "\n",
    "for i in range(200):\n",
    "    key = spaces.Discrete(10).sample()\n",
    "    counts[key] = counts[key] + 1\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have more than one dimension of discrete (or continuous) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4, 1, 0, 2]),\n",
       " array([4, 0, 0, 0]),\n",
       " array([1, 1, 0, 1]),\n",
       " array([2, 0, 0, 0]),\n",
       " array([2, 0, 1, 0]),\n",
       " array([1, 0, 0, 2]),\n",
       " array([3, 0, 0, 0]),\n",
       " array([1, 0, 1, 2]),\n",
       " array([1, 0, 0, 2]),\n",
       " array([3, 0, 0, 0]),\n",
       " array([3, 1, 0, 0]),\n",
       " array([0, 0, 1, 3]),\n",
       " array([2, 1, 0, 0]),\n",
       " array([1, 0, 0, 1]),\n",
       " array([2, 0, 0, 0]),\n",
       " array([2, 0, 1, 1]),\n",
       " array([0, 0, 1, 3]),\n",
       " array([2, 1, 0, 2]),\n",
       " array([2, 0, 0, 2]),\n",
       " array([1, 1, 1, 0])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md = spaces.MultiDiscrete([ 5, 2, 2, 4 ])\n",
    "[md.sample() for _ in range(20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the values for each dimension in the discrete space are inclusive, but zero-offset. For example, in the samples shown, the first integer returned in the array is 0-4, inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.21508895, -0.95937773],\n",
       "        [-0.84855983,  0.24701504],\n",
       "        [ 0.62692108,  1.8701334 ]]),\n",
       " array([[-0.65042381, -1.14259923],\n",
       "        [-0.20224788, -0.72529317],\n",
       "        [-1.95928477, -1.65749218]]),\n",
       " array([[-1.79506632,  1.06640788],\n",
       "        [-0.13193177,  1.39794078],\n",
       "        [ 0.31178606,  1.97095426]]),\n",
       " array([[-0.97017207,  0.29517695],\n",
       "        [-1.07587172,  1.34458648],\n",
       "        [-0.55446192, -0.80038273]]),\n",
       " array([[-1.55730893,  1.73353339],\n",
       "        [ 0.83212828, -0.5899059 ],\n",
       "        [ 0.21135169,  0.5654232 ]]),\n",
       " array([[ 0.7636343 , -1.87491873],\n",
       "        [ 0.58766069,  0.69793298],\n",
       "        [-1.44319028, -0.32817514]]),\n",
       " array([[ 1.57448007,  0.21163613],\n",
       "        [ 0.83482313, -0.9489593 ],\n",
       "        [-0.23429545,  1.58978036]]),\n",
       " array([[ 1.71631837, -1.38578722],\n",
       "        [ 1.73922473,  1.36287033],\n",
       "        [-1.69934275, -0.1863998 ]]),\n",
       " array([[ 0.93703627,  1.85544766],\n",
       "        [ 0.98367903, -1.5482977 ],\n",
       "        [-1.23829554, -0.72698416]]),\n",
       " array([[ 1.28911485,  0.49043503],\n",
       "        [-1.5059944 , -1.79701963],\n",
       "        [ 1.73342683,  1.85221137]]),\n",
       " array([[-1.41914944,  1.85655314],\n",
       "        [ 1.32340335,  1.4670649 ],\n",
       "        [ 1.44691031, -1.87564391]]),\n",
       " array([[ 1.86164497, -1.72500137],\n",
       "        [ 1.70178869,  1.92426538],\n",
       "        [-1.70359314,  1.42987733]]),\n",
       " array([[-1.58395131, -0.32936977],\n",
       "        [-0.09005571, -1.76329479],\n",
       "        [-0.33678248, -0.97922592]]),\n",
       " array([[-0.71375731,  1.74930427],\n",
       "        [-0.97536523,  0.26173631],\n",
       "        [-1.60062407,  0.13300923]]),\n",
       " array([[ 0.12551118,  1.32210599],\n",
       "        [ 1.71119538, -0.37408438],\n",
       "        [ 1.92824914,  1.80330041]]),\n",
       " array([[ 0.66710251,  0.60855252],\n",
       "        [-0.10245495, -1.95769485],\n",
       "        [ 1.42077118, -0.21749604]]),\n",
       " array([[-0.04007469, -0.0511689 ],\n",
       "        [-1.73649892,  0.79016795],\n",
       "        [ 0.05771089,  0.11776989]]),\n",
       " array([[ 0.38124203, -1.18472043],\n",
       "        [-0.98355519, -0.39563055],\n",
       "        [ 0.72632291,  1.53814286]]),\n",
       " array([[-0.01273823,  0.27268077],\n",
       "        [-1.29923651, -0.96189824],\n",
       "        [ 1.60063814,  0.96050904]]),\n",
       " array([[-1.12847575, -1.69956378],\n",
       "        [ 1.90775593, -1.2867272 ],\n",
       "        [-1.91156569, -0.47750857]])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box = spaces.Box(-2, 2, shape=(3,2), dtype=np.float64)\n",
    "[box.sample() for _ in range(20)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: A Custom Environment with Rewards\n",
    "\n",
    "Now we'll create an `n-Chain` environment, which represents moves along a linear chain of states, with two actions:\n",
    "\n",
    "* (0) **forward**: move along the chain but returns no reward\n",
    "* (1) **backward**: returns to the beginning and has a small reward\n",
    "\n",
    "The end of the chain, however, provides a large reward, and by moving **forward** at the end of the chain, this large reward can be repeated.\n",
    "\n",
    "#### Step 1: Implement `ChainEnv._setup_spaces`\n",
    "\n",
    "Use a `spaces.Discrete` action space and observation space. Implement `ChainEnv._setup_spaces` in `ChainEnv` so that `self.action_space` and `self.obseration_space` are proper gym spaces.\n",
    "  \n",
    "1. The observation space is an integer in the range `[0 to n-1]`.\n",
    "2. The action space is an integer in `[0, 1]`.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "self.action_space = spaces.Discrete(2)\n",
    "self.observation_space = ...\n",
    "```\n",
    "\n",
    "You should see a message indicating tests passing when done correctly!\n",
    "\n",
    "#### Step 2: Implement a reward function.\n",
    "\n",
    "When `env.step` is called, it returns a tuple of `(state, reward, done, info)`. Right now, the reward is always 0. Modify `step()` so that the following rewards are returned for the given actions: \n",
    "\n",
    "1. `action == 1` will return `self.small_reward`.\n",
    "2. `action == 0` will return 0 if `self.state < self.n - 1`.\n",
    "3. `action == 0` will return `self.large_reward` if `self.state == self.n - 1`.\n",
    "\n",
    "You should see a message indicating tests passing when done correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_exercises import test_chain_env_spaces, test_chain_env_reward, test_chain_env_behavior\n",
    "from gym import spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if spaces have been setup correctly...\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Action Space not implemented!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-727e988fd1d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Tests here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mtest_chain_env_spaces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChainEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mtest_chain_env_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChainEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/anyscale/academy/academy-git/ray-rllib/explore-rllib/test_exercises.py\u001b[0m in \u001b[0;36mtest_chain_env_spaces\u001b[0;34m(chain_env_cls)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtest_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchain_env_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing if spaces have been setup correctly...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Action Space not implemented!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Observation Space not implemented!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtest_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Action Space is only [0, 1]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Action Space not implemented!"
     ]
    }
   ],
   "source": [
    "class ChainEnv(gym.Env):\n",
    "    \n",
    "    def __init__(self, env_config = None):\n",
    "        env_config = env_config or {}\n",
    "        self.n = env_config.get(\"n\", 20)\n",
    "        self.small_reward = env_config.get(\"small\", 2)  # payout for 'backwards' action\n",
    "        self.large_reward = env_config.get(\"large\", 10)  # payout at end of chain for 'forwards' action\n",
    "        self.state = 0  # Start at beginning of the chain\n",
    "        self._horizon = self.n\n",
    "        self._counter = 0  # For terminating the episode\n",
    "        self._setup_spaces()\n",
    "    \n",
    "    def _setup_spaces(self):\n",
    "        ##############\n",
    "        # TODO: Implement this so that it passes tests\n",
    "        self.action_space = None\n",
    "        self.observation_space = None\n",
    "        ##############\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        if action == 1:  # 'backwards': go back to the beginning, get small reward\n",
    "            ##############\n",
    "            # TODO 2: Implement this so that it passes tests\n",
    "            reward = -1\n",
    "            ##############\n",
    "            self.state = 0\n",
    "        elif self.state < self.n - 1:  # 'forwards': go up along the chain\n",
    "            ##############\n",
    "            # TODO 2: Implement this so that it passes tests\n",
    "            reward = -1\n",
    "            self.state += 1\n",
    "        else:  # 'forwards': stay at the end of the chain, collect large reward\n",
    "            ##############\n",
    "            # TODO 2: Implement this so that it passes tests\n",
    "            reward = -1\n",
    "            ##############\n",
    "        self._counter += 1\n",
    "        done = self._counter >= self._horizon\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = 0\n",
    "        self._counter = 0\n",
    "        return self.state\n",
    "    \n",
    "# Tests here:\n",
    "test_chain_env_spaces(ChainEnv)\n",
    "test_chain_env_reward(ChainEnv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Policy on the Environment \n",
    "\n",
    "Now we'll train a policy on the environment and evaluate the policy. You'll see that despite an extremely high reward, the policy has barely explored the state space. \n",
    "\n",
    "In order to proceed, we'll import an implementation of the previous exercise, but you should actually comment-out the next cell once you complete the previous exercise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chain_env import ChainEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = DEFAULT_CONFIG.copy()\n",
    "trainer_config['num_workers'] = 1\n",
    "trainer_config[\"train_batch_size\"] = 400\n",
    "trainer_config[\"sgd_minibatch_size\"] = 64\n",
    "trainer_config[\"num_sgd_iter\"] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_training(chainEnvClass, config = trainer_config, iterations=20):\n",
    "    trainer = PPOTrainer(config, chainEnvClass)\n",
    "    print(f'Training iterations: ', end='')\n",
    "    for i in range(iterations):\n",
    "        print('.', end='')\n",
    "        trainer.train()\n",
    "    print('')\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-28 07:57:58,270\tINFO trainer.py:585 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2020-06-28 07:57:58,271\tINFO trainer.py:612 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2020-06-28 07:58:00,447\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iterations: .\u001b[2m\u001b[36m(pid=67534)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=67534)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "...................\n"
     ]
    }
   ],
   "source": [
    "trainer = do_training(ChainEnv, config=trainer_config, iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulative reward you received is: 40. Congratulations!\n",
      "Max state you visited is: 0. This is out of 20 states.\n"
     ]
    }
   ],
   "source": [
    "env = ChainEnv({})\n",
    "state = env.reset()\n",
    "\n",
    "done = False\n",
    "max_state = -1\n",
    "cumulative_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action = trainer.compute_action(state)\n",
    "    state, reward, done, results = env.step(action)\n",
    "    max_state = max(max_state, state)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(f'Cumulative reward you received is: {cumulative_reward}. Congratulations!')\n",
    "print(f'Max state you visited is: {max_state}. This is out of {env.n} states.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only visited a small number of states, maybe only 1 or 2 (max == 0 or 1?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shaping the Reward to Encourage Desired Behavior\n",
    "\n",
    "We see that despite an extremely high reward, the policy has barely explored the state space. This is often the situation - where the reward designed to encourage a particular solution is suboptimal, and the behavior created is unintended.\n",
    "\n",
    "### Exercise 2: Improve the Policy\n",
    "\n",
    "Modify `ShapedChainEnvVisited.step()` in the next cell to return rewards that encourage the policy to traverse the chain (not just stick to 0). Do not change the behavior of the environment. That is, the action -> state behavior should be the same. You can change the reward to be whatever you wish. We'll test it in the next section.\n",
    "\n",
    "This implementation also adds a constructor argument `done_percentage`, which specifies what percentage of states, between `0.0` and `1.0` must be visited before `done` is reached. Play with this number when you modify the rewards to gain a sense of how long it takes to explore the action space. Note that there is a \"safety\"; it stops after `10*env.n` iterations, even if the percentage of visited states isn't reached. As the code exists in the following cell, it will always hit this safety!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing if behavior has been changed...\n",
      "Success! Behavior of environment is correct.\n"
     ]
    }
   ],
   "source": [
    "class ShapedChainEnvVisited(ChainEnv):\n",
    "\n",
    "    def __init__(self, env_config = None):\n",
    "        super().__init__(env_config)\n",
    "        self.visited = set()\n",
    "        self.done_percentage = 0.5\n",
    "        self.done_n = self.done_percentage * self.n\n",
    "        \n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        self.visited.add(self.state)\n",
    "        if action == 1:  # 'backwards': go back to the beginning\n",
    "            reward = self.small_reward\n",
    "            self.state = 0\n",
    "        elif self.state < self.n - 1:  # 'forwards': go up along the chain\n",
    "            reward = 0\n",
    "            self.state += 1\n",
    "        else:  # 'forwards': stay at the end of the chain\n",
    "            reward = self.large_reward\n",
    "        self._counter += 1\n",
    "        done = len(self.visited) >= self.done_n\n",
    "        if not done and self._counter > (self.n*10):\n",
    "            done = True\n",
    "            visited_per = (len(self.visited)*100.0)/self.n\n",
    "            print(f'Stopping after {self.n*10} iterations. Visited {visited_per:6.2f}% of the states.')\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "test_chain_env_behavior(ShapedChainEnvVisited)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate `ShapedChainEnv` by Running the Cell(s) Below\n",
    "\n",
    "This trains PPO on the new env and counts the number of states seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "2020-06-28 08:06:00,284\tWARNING util.py:37 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training iterations: .\u001b[2m\u001b[36m(pid=67715)\u001b[0m /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(pid=67715)\u001b[0m   warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n",
      "\u001b[2m\u001b[36m(pid=67715)\u001b[0m Stopping after 200 iterations. Visited  40.00% of the states.\n",
      ".\u001b[2m\u001b[36m(pid=67715)\u001b[0m Stopping after 200 iterations. Visited  40.00% of the states.\n",
      "..................\n"
     ]
    }
   ],
   "source": [
    "trainer = do_training(ShapedChainEnvVisited, config=trainer_config, iterations=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how long it takes to get to 50% (the value hard-coded for `done_percentage`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping after 200 iterations. Visited   5.00% of the states.\n",
      "Cumulative reward you received is: 402!\n",
      "Max state you visited is: 0. (There are 20 states.)\n",
      "This policy traversed  5.0% of the available states.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": " 5.0% is less than the desired percentage of 50.0%.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-f527d80f8d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_state\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m  \u001b[0;31m# add one because of zero indexing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"This policy traversed {actual*100:4.1f}% of the available states.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mactual\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mdesired\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{actual*100:4.1f}% is less than the desired percentage of {desired*100:4.1f}%.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m:  5.0% is less than the desired percentage of 50.0%."
     ]
    }
   ],
   "source": [
    "env = ShapedChainEnvVisited({})\n",
    "\n",
    "state = env.reset()\n",
    "done = False\n",
    "max_state = -1\n",
    "cumulative_reward = 0\n",
    "while not done:\n",
    "    action = trainer.compute_action(state)\n",
    "    state, reward, done, results = env.step(action)\n",
    "    max_state = max(max_state, state)\n",
    "    cumulative_reward += reward\n",
    "\n",
    "print(f'Cumulative reward you received is: {cumulative_reward}!')\n",
    "print(f'Max state you visited is: {max_state}. (There are {env.n} states.)')\n",
    "desired = env.done_percentage\n",
    "actual = (max_state+1)/env.n  # add one because of zero indexing\n",
    "print(f\"This policy traversed {actual*100:4.1f}% of the available states.\")\n",
    "assert actual > desired, f\"{actual*100:4.1f}% is less than the desired percentage of {desired*100:4.1f}%.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
