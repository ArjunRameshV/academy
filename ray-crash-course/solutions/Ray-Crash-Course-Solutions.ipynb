{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Crash Course - Exercise Solutions\n",
    "\n",
    "This notebook discusses solutions for the exercises in the _crash course_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Ray Crash Course - Tasks - Exercise 1\n",
    "\n",
    "As currently written, the memory footprint of `estimate_pi` scales linearly with `N`, because it allocates two NumPy arrays of size `N`. This limits the size of `N` we can evaluate (as I confirmed by locking up my laptop...). However, this isn't actually necessary. We could do the same calculation in \"blocks, for example `m` blocks of size `N/m` and then combine the results. Furthermore, there's no dependencies between the calculations with those blocks, giving us further potential speed-up by parellelizing them with Ray.\n",
    "\n",
    "Adapt `ray_estimate_pi` to use this technique. Pick some `N` value above which the calculation is done in blocks. Compare the performance of the old vs. new implementation. \n",
    "\n",
    "As you do this exercise, you might ponder the fact that we often averaged multiple trials for a given `N` and then ask yourself, what's the difference between averaging `10` trials for `N = 1000` vs. `1` trial for `N = 10000`, for example?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import things we need and redefine functions and data we need from the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, time, statistics, math\n",
    "import ray\n",
    "sys.path.append('..')\n",
    "from pi_calc import str_large_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-04-30 12:09:01,221\tINFO resource_spec.py:212 -- Starting Ray with 4.54 GiB memory available for workers and up to 2.29 GiB for objects. You can adjust these settings with ray.init(memory=<bytes>, object_store_memory=<bytes>).\n",
      "2020-04-30 12:09:01,547\tINFO services.py:1148 -- View the Ray dashboard at \u001b[1m\u001b[32mlocalhost:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.149',\n",
       " 'redis_address': '192.168.1.149:51488',\n",
       " 'object_store_address': '/tmp/ray/session_2020-04-30_12-09-01_213619_3147/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-04-30_12-09-01_213619_3147/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-04-30_12-09-01_213619_3147'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(address='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard URL: http://localhost:8265\n"
     ]
    }
   ],
   "source": [
    "print(f'Dashboard URL: http://{ray.get_webui_url()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's `estimate_pi` again, but now we'll also return the counts, for reasons we'll discuss shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_pi(num_samples):\n",
    "    xs = np.random.uniform(low=-1.0, high=1.0, size=num_samples)   # Generate num_samples random samples for the x coordinate.\n",
    "    ys = np.random.uniform(low=-1.0, high=1.0, size=num_samples)   # Generate num_samples random samples for the y coordinate.\n",
    "    xys = np.stack((xs, ys), axis=-1)                              # Like Python's \"zip(a,b)\"; creates np.array([(x1,y1), (x2,y2), ...]).\n",
    "    inside = xs*xs + ys*ys <= 1.0                                  # Creates a predicate over all the array elements.\n",
    "    xys_inside = xys[inside]                                       # Selects only those \"zipped\" array elements inside the circle.\n",
    "    in_circle = xys_inside.shape[0]                                # Return the number of elements inside the circle.\n",
    "    approx_pi = 4.0*in_circle/num_samples                          # The Pi estimate.\n",
    "    return approx_pi, in_circle, num_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the original `ray_estimate_pi`, but now it will also return the counts, not just $\\pi$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def ray_estimate_pi(num_samples):\n",
    "    return estimate_pi(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt = '{:10.5f} seconds: pi ~ {:7.6f}, stddev = {:5.4f}, error = {:5.4f}%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's `ray_try_it`, but now we handle the additional returned values from `ray_estimate_pi`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_try_it(n, trials):\n",
    "    print('trials = {:5d}, N = {:s}: '.format(trials, str_large_n(n, padding=15)), end='')   # str_large_n imported above.\n",
    "    start = time.time()\n",
    "    ids = [ray_estimate_pi.remote(n) for _ in range(trials)]\n",
    "    pis_counts = ray.get(ids)\n",
    "    pis = list(map(lambda t: t[0], pis_counts))\n",
    "    approx_pi = statistics.mean(pis)\n",
    "    stdev = 0.0 if trials == 1 else statistics.stdev(pis)\n",
    "    duration = time.time() - start\n",
    "    error = (100.0*abs(approx_pi-np.pi)/np.pi)\n",
    "    print(fmt.format(duration, approx_pi, stdev, error))   # str_large_n imported above.\n",
    "    return trials, n, duration, approx_pi, stdev, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's look at the \"ponder\" question at the end, just using the original implementation. We'll do a few runs of the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trials = 10000, N =           1,000:    2.11654 seconds: pi ~ 3.142452, stddev = 0.0513, error = 0.0274%\n",
      "trials =  1000, N =          10,000:    0.23774 seconds: pi ~ 3.142216, stddev = 0.0162, error = 0.0198%\n",
      "trials =   100, N =         100,000:    0.12214 seconds: pi ~ 3.141495, stddev = 0.0050, error = 0.0031%\n",
      "trials =    10, N =       1,000,000:    0.17723 seconds: pi ~ 3.141891, stddev = 0.0019, error = 0.0095%\n",
      "trials =     1, N =      10,000,000:    0.64956 seconds: pi ~ 3.141460, stddev = 0.0000, error = 0.0042%\n"
     ]
    }
   ],
   "source": [
    "for n in [1000, 10000, 100000, 1000000, 10000000]:\n",
    "    ray_try_it(n, round(10000000/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trials = 10000, N =           1,000:    2.21157 seconds: pi ~ 3.142165, stddev = 0.0520, error = 0.0182%\n",
      "trials =  1000, N =          10,000:    0.25916 seconds: pi ~ 3.141835, stddev = 0.0167, error = 0.0077%\n",
      "trials =   100, N =         100,000:    0.13249 seconds: pi ~ 3.142105, stddev = 0.0056, error = 0.0163%\n",
      "trials =    10, N =       1,000,000:    0.17565 seconds: pi ~ 3.141208, stddev = 0.0020, error = 0.0122%\n",
      "trials =     1, N =      10,000,000:    0.65809 seconds: pi ~ 3.141775, stddev = 0.0000, error = 0.0058%\n"
     ]
    }
   ],
   "source": [
    "for n in [1000, 10000, 100000, 1000000, 10000000]:\n",
    "    ray_try_it(n, round(10000000/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trials = 10000, N =           1,000:    2.15662 seconds: pi ~ 3.142175, stddev = 0.0523, error = 0.0185%\n",
      "trials =  1000, N =          10,000:    0.23714 seconds: pi ~ 3.141688, stddev = 0.0163, error = 0.0030%\n",
      "trials =   100, N =         100,000:    0.13763 seconds: pi ~ 3.141859, stddev = 0.0055, error = 0.0085%\n",
      "trials =    10, N =       1,000,000:    0.17017 seconds: pi ~ 3.141774, stddev = 0.0021, error = 0.0058%\n",
      "trials =     1, N =      10,000,000:    0.65895 seconds: pi ~ 3.141655, stddev = 0.0000, error = 0.0020%\n"
     ]
    }
   ],
   "source": [
    "for n in [1000, 10000, 100000, 1000000, 10000000]:\n",
    "    ray_try_it(n, round(10000000/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation is misleading now, because the number of trials change. The errors are roughly within an order of magnitude, due in part to expected statistical variation. Generally speaking, larger `N` and lower `trials` had lower errors. This may be due to the other big source of variation, the inevitable rounding error computing $\\pi$ (`4 * inside_count/N`), one time per trial (`1` to `10,000` times). Experiments are supposed to eliminate as many extraneous variables as possible, so I would argue that sticking to one value for `trials` and varying `N` is more meaningful. In fact, in the implementation that follows, we'll eliminate the potential rounding error variation by keep track of the inside and total counts, then computing $\\pi$ once at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a function to return sample sizes for a given `N` and `m`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sizes(N, m):\n",
    "    ranges = [(m*i, m*(i+1)) for i in range(math.ceil(N/m))]\n",
    "    if ranges[-1][1] > N:\n",
    "        ranges[-1] = (ranges[-1][0], N)\n",
    "    return list(map(lambda x: x[1]-x[0], ranges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def ray_estimate_pi_blocks(num_samples, m):\n",
    "    \"\"\"\n",
    "    Perform the estimate in blocks up to ``m`` samples in size. A more user-friendly solution would embed logic to\n",
    "    determine an reasonably good ``m`` value, but for our purposes, passing in ``m`` is more convenient.\n",
    "    \"\"\"\n",
    "    sizes = sample_sizes(num_samples, m)\n",
    "    ids = [ray_estimate_pi.remote(size) for size in sizes]\n",
    "    values = ray.get(ids)  # Not using ray.wait() is okay; the tasks are all roughly the same size\n",
    "    inside_count = 0\n",
    "    total_count = 0\n",
    "    for _, icount, tcount in values:    # Toss the pi value returned\n",
    "        inside_count += icount\n",
    "        total_count += tcount\n",
    "    return 4.0*inside_count/total_count, inside_count, total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m = 10000:\n",
      "           1000: duration = 0.0044899 seconds, pi =  3.108, # inside/outside =          777/1000\n",
      "          10000: duration = 0.0027683 seconds, pi = 3.1544, # inside/outside =         7886/10000\n",
      "         100000: duration = 0.007292 seconds, pi = 3.1398, # inside/outside =        78495/100000\n",
      "        1000000: duration = 0.017121 seconds, pi = 3.1414, # inside/outside =       785359/1000000\n",
      "       10000000: duration = 0.12724 seconds, pi = 3.1412, # inside/outside =      7853049/10000000\n",
      "      100000000: duration = 1.1888 seconds, pi = 3.1416, # inside/outside =     78541126/100000000\n",
      "m = 100000:\n",
      "           1000: duration = 0.0024719 seconds, pi =  3.132, # inside/outside =          783/1000\n",
      "          10000: duration = 0.0020089 seconds, pi = 3.1368, # inside/outside =         7842/10000\n",
      "         100000: duration = 0.0055439 seconds, pi =  3.149, # inside/outside =        78725/100000\n",
      "        1000000: duration = 0.013774 seconds, pi = 3.1419, # inside/outside =       785463/1000000\n",
      "       10000000: duration = 0.12174 seconds, pi =  3.141, # inside/outside =      7852426/10000000\n",
      "      100000000: duration = 1.1893 seconds, pi = 3.1415, # inside/outside =     78537430/100000000\n",
      "m = 1000000:\n",
      "           1000: duration = 0.0029519 seconds, pi =    3.2, # inside/outside =          800/1000\n",
      "          10000: duration = 0.0022299 seconds, pi =  3.126, # inside/outside =         7815/10000\n",
      "         100000: duration = 0.005197 seconds, pi = 3.1531, # inside/outside =        78827/100000\n",
      "        1000000: duration = 0.014729 seconds, pi = 3.1442, # inside/outside =       786058/1000000\n",
      "       10000000: duration = 0.12053 seconds, pi = 3.1409, # inside/outside =      7852172/10000000\n",
      "      100000000: duration = 1.2103 seconds, pi = 3.1414, # inside/outside =     78535501/100000000\n"
     ]
    }
   ],
   "source": [
    "for m in [10000, 100000, 1000000]:\n",
    "    print(f'm = {m}:')\n",
    "    for n in [1000, 10000, 100000, 1000000, 10000000, 100000000]:\n",
    "        start = time.time()\n",
    "        approx_pi, inside_count, total_count = ray.get(ray_estimate_pi_blocks.remote(n, 100000))\n",
    "        duration = time.time() - start\n",
    "        print(f'{n:15}: duration = {duration:6.5} seconds, pi = {approx_pi:6.5}, # inside/outside = {inside_count:12}/{total_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare to the original implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           1000: duration = 0.0014429 seconds, pi =  3.152, # inside/outside =          788/1000\n",
      "          10000: duration = 0.022624 seconds, pi = 3.1488, # inside/outside =         7872/10000\n",
      "         100000: duration = 0.03082 seconds, pi = 3.1402, # inside/outside =        78504/100000\n",
      "        1000000: duration = 0.063138 seconds, pi = 3.1413, # inside/outside =       785318/1000000\n",
      "       10000000: duration = 0.65805 seconds, pi = 3.1417, # inside/outside =      7854147/10000000\n",
      "      100000000: duration = 9.6115 seconds, pi = 3.1419, # inside/outside =     78547002/100000000\n"
     ]
    }
   ],
   "source": [
    "for n in [1000, 10000, 100000, 1000000, 10000000, 100000000]:\n",
    "    start = time.time()\n",
    "    approx_pi, inside_count, total_count = ray.get(ray_estimate_pi.remote(n))\n",
    "    duration = time.time() - start\n",
    "    print(f'{n:15}: duration = {duration:6.5} seconds, pi = {approx_pi:6.5}, # inside/outside = {inside_count:12}/{total_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for larger `N`, `ray_estimate_pi_blocks` time scale noticeably slower than the original implementation, e.g., for the highest `N`, `100,000,000`, the durations are approximately `1.2` seconds vs. `9.6` seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Ray Crash Course - Tasks - Exercise 2\n",
    "\n",
    "What `N` value is needed to get a reliable estimate to five decimal places, `3.1415` (for some definition of \"reliable\")? If you have a powerful machine or a cluster, you could try a higher accuracy. You'll need to use the solution to Exercise 1 or you can make a guess based on the results we've already seen in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the solution from Exercise 1, we'll need a modified `ray_try_it` to add the `m` blocks parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_try_it_blocks(n, m, trials):\n",
    "    print('trials = {:5d}, N = {:s}: '.format(trials, str_large_n(n, padding=15)), end='')   # str_large_n imported above.\n",
    "    start = time.time()\n",
    "    ids = [ray_estimate_pi_blocks.remote(n, m) for _ in range(trials)]\n",
    "    pis_counts = ray.get(ids)\n",
    "    pis = list(map(lambda t: t[0], pis_counts))\n",
    "    approx_pi = statistics.mean(pis)\n",
    "    stdev = 0.0 if trials == 1 else statistics.stdev(pis)\n",
    "    duration = time.time() - start\n",
    "    error = (100.0*abs(approx_pi-np.pi)/np.pi)\n",
    "    print(fmt.format(duration, approx_pi, stdev, error))   # str_large_n imported above.\n",
    "    return trials, n, duration, approx_pi, stdev, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the error we would have to achieve for this accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002949255362150871"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_error = 100*abs(3.1415 - np.pi)/np.pi\n",
    "target_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's keep trying bigger `N` until we get to this number, but now we need to pick a definition of \"reliable\", because the results will depend on the number of `trials` we do. Also, some experiments will get \"lucky\" for relatively low `N` values.\n",
    "\n",
    "> **WARNING:** This could take a while. You could choose a less accurate error goal if you have limited compute resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trials =     5, N =           1,000:    0.00670 seconds: pi ~ 3.151200, stddev = 0.0134, error = 0.3058%\n",
      "trials =     5, N =          10,000:    0.00622 seconds: pi ~ 3.143440, stddev = 0.0188, error = 0.0588%\n",
      "trials =     5, N =         100,000:    0.01528 seconds: pi ~ 3.142992, stddev = 0.0049, error = 0.0445%\n",
      "trials =     5, N =       1,000,000:    0.09161 seconds: pi ~ 3.141640, stddev = 0.0016, error = 0.0015%\n",
      "1000000 samples is sufficient to get the error below 0.002949255362150871%\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "error = 10.0\n",
    "while error > target_error:\n",
    "    N *= 10\n",
    "    _, _, duration, approx_pi, _, error = ray_try_it_blocks(N, 1000000, trials)\n",
    "    if N > 100000000:\n",
    "        print(\"Stopping so we don't crash the machine...\")\n",
    "        break\n",
    "print(f'{N} samples is sufficient to get the error below {target_error}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should run the previous cell several times. Some runs might succeed with `N = 100,000`, while more often it will be above 1M or 10M."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Ray Crash Course - Tasks - Exercise 3\n",
    "\n",
    "For small computation problems, Ray adds enough overhead that its benefits are outweighed. You can see from the performance graphs in the lesson that smaller `N` or smaller trial values will likely cause the performance curves to cross. Try small values of `N` and small trial numbers. When do the lines cross? Try timing individual runs for small `N` around the crossing point. What can you infer from this \"tipping point\" about appropriate sizing of tasks, at least for your test environment?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, here is more code from the notebook. Here is `try_it`, modified to handle the extra return values from the modified `estimate_pi`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_it(n, trials):\n",
    "    print('trials = {:3d}, N = {:s}: '.format(trials, str_large_n(n, padding=12)), end='')   # str_large_n imported above.\n",
    "    start = time.time()\n",
    "    pis_counts = [estimate_pi(n) for _ in range(trials)]\n",
    "    pis = list(map(lambda t: t[0], pis_counts))\n",
    "    approx_pi = statistics.mean(pis)\n",
    "    stdev = statistics.stdev(pis)\n",
    "    duration = time.time() - start\n",
    "    error = (100.0*abs(approx_pi-np.pi)/np.pi)\n",
    "    print(fmt.format(duration, approx_pi, stdev, error))   # str_large_n imported above.\n",
    "    return trials, n, duration, approx_pi, stdev, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ns = [1, 10, 100, 1000, 10000, 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trials =   5, N =            1:    0.00038 seconds: pi ~ 3.200000, stddev = 1.7889, error = 1.8592%\n",
      "trials =   5, N =           10:    0.00028 seconds: pi ~ 3.120000, stddev = 0.1789, error = 0.6873%\n",
      "trials =   5, N =          100:    0.00032 seconds: pi ~ 3.080000, stddev = 0.0748, error = 1.9606%\n",
      "trials =   5, N =        1,000:    0.00212 seconds: pi ~ 3.130400, stddev = 0.0661, error = 0.3563%\n",
      "trials =   5, N =       10,000:    0.00213 seconds: pi ~ 3.139040, stddev = 0.0188, error = 0.0813%\n",
      "trials =   5, N =      100,000:    0.01813 seconds: pi ~ 3.141728, stddev = 0.0021, error = 0.0043%\n"
     ]
    }
   ],
   "source": [
    "data_ns = [try_it(n, trials) for n in small_ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trials =     5, N =               1:    0.00300 seconds: pi ~ 2.400000, stddev = 2.1909, error = 23.6056%\n",
      "trials =     5, N =              10:    0.00241 seconds: pi ~ 3.040000, stddev = 0.2191, error = 3.2338%\n",
      "trials =     5, N =             100:    0.00214 seconds: pi ~ 3.144000, stddev = 0.1345, error = 0.0766%\n",
      "trials =     5, N =           1,000:    0.00243 seconds: pi ~ 3.102400, stddev = 0.0378, error = 1.2475%\n",
      "trials =     5, N =          10,000:    0.00324 seconds: pi ~ 3.144480, stddev = 0.0118, error = 0.0919%\n",
      "trials =     5, N =         100,000:    0.01032 seconds: pi ~ 3.140808, stddev = 0.0046, error = 0.0250%\n"
     ]
    }
   ],
   "source": [
    "ray_data_ns = [ray_try_it(n, trials) for n in small_ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data_ns         = np.array(data_ns)\n",
    "np_ray_data_ns     = np.array(ray_data_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh_util import two_lines_plot, means_stddevs_plot  # Some plotting utilities in `./bokeh_util.py`.\n",
    "from bokeh.plotting import show, figure\n",
    "from bokeh.layouts import gridplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "  <div class=\"bk-root\" id=\"93cf91c9-e1d1-4c21-b1bd-2c97878e2958\" data-root-id=\"1560\"></div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"d9eda571-20a2-4f75-97a1-066975d40ea8\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1571\"}],\"center\":[{\"id\":\"1574\"},{\"id\":\"1578\"},{\"id\":\"1606\"}],\"left\":[{\"id\":\"1575\"}],\"renderers\":[{\"id\":\"1598\"},{\"id\":\"1611\"},{\"id\":\"1616\"},{\"id\":\"1632\"}],\"title\":{\"id\":\"1561\"},\"toolbar\":{\"id\":\"1587\"},\"x_range\":{\"id\":\"1563\"},\"x_scale\":{\"id\":\"1567\"},\"y_range\":{\"id\":\"1565\"},\"y_scale\":{\"id\":\"1569\"}},\"id\":\"1560\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"items\":[{\"id\":\"1607\"},{\"id\":\"1628\"}],\"location\":\"top_left\"},\"id\":\"1606\",\"type\":\"Legend\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#B2DF8A\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1615\",\"type\":\"Line\"},{\"attributes\":{\"axis\":{\"id\":\"1575\"},\"dimension\":1,\"grid_line_alpha\":0.3,\"ticker\":null},\"id\":\"1578\",\"type\":\"Grid\"},{\"attributes\":{\"data\":{\"x\":{\"__ndarray__\":\"AAAAAAAA8D8AAAAAAAAkQAAAAAAAAFlAAAAAAABAj0AAAAAAAIjDQAAAAAAAavhA\",\"dtype\":\"float64\",\"shape\":[6]},\"y\":{\"__ndarray__\":\"AAAAAACaaD8AAAAAALpjPwAAAAAAkmE/AAAAAADeYz8AAAAAgIxqPwAAAABAJIU/\",\"dtype\":\"float64\",\"shape\":[6]}},\"selected\":{\"id\":\"1688\"},\"selection_policy\":{\"id\":\"1687\"}},\"id\":\"1629\",\"type\":\"ColumnDataSource\"},{\"attributes\":{},\"id\":\"1685\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"line_color\":\"#B2DF8A\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1614\",\"type\":\"Line\"},{\"attributes\":{\"data_source\":{\"id\":\"1608\"},\"glyph\":{\"id\":\"1609\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1610\"},\"selection_glyph\":null,\"view\":{\"id\":\"1612\"}},\"id\":\"1611\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"data_source\":{\"id\":\"1595\"},\"glyph\":{\"id\":\"1596\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"No Ray\",\"nonselection_glyph\":{\"id\":\"1597\"},\"selection_glyph\":null,\"view\":{\"id\":\"1599\"}},\"id\":\"1598\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"bottom_units\":\"screen\",\"fill_alpha\":0.5,\"fill_color\":\"lightgrey\",\"left_units\":\"screen\",\"level\":\"overlay\",\"line_alpha\":1.0,\"line_color\":\"black\",\"line_dash\":[4,4],\"line_width\":2,\"render_mode\":\"css\",\"right_units\":\"screen\",\"top_units\":\"screen\"},\"id\":\"1585\",\"type\":\"BoxAnnotation\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#A6CEE3\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#A6CEE3\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1610\",\"type\":\"Circle\"},{\"attributes\":{\"fill_color\":{\"value\":\"#A6CEE3\"},\"line_color\":{\"value\":\"#A6CEE3\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1609\",\"type\":\"Circle\"},{\"attributes\":{\"data\":{\"x\":{\"__ndarray__\":\"AAAAAAAA8D8AAAAAAAAkQAAAAAAAAFlAAAAAAABAj0AAAAAAAIjDQAAAAAAAavhA\",\"dtype\":\"float64\",\"shape\":[6]},\"y\":{\"__ndarray__\":\"AAAAAADkOD8AAAAAAJwyPwAAAAAAuDQ/AAAAAABaYT8AAAAAgGhhPwAAAADwkJI/\",\"dtype\":\"float64\",\"shape\":[6]}},\"selected\":{\"id\":\"1624\"},\"selection_policy\":{\"id\":\"1623\"}},\"id\":\"1595\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"name\",\"$name\"],[\"array size\",\"$x\"],[\"time\",\"$y\"]]},\"id\":\"1586\",\"type\":\"HoverTool\"},{\"attributes\":{\"line_color\":\"#A6CEE3\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1596\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1579\",\"type\":\"PanTool\"},{\"attributes\":{\"text\":\"N vs. Execution Times (Smaller Is Better)\"},\"id\":\"1561\",\"type\":\"Title\"},{\"attributes\":{\"label\":{\"value\":\"No Ray\"},\"renderers\":[{\"id\":\"1598\"}]},\"id\":\"1607\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1567\",\"type\":\"LogScale\"},{\"attributes\":{},\"id\":\"1580\",\"type\":\"WheelZoomTool\"},{\"attributes\":{},\"id\":\"1687\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1579\"},{\"id\":\"1580\"},{\"id\":\"1581\"},{\"id\":\"1582\"},{\"id\":\"1583\"},{\"id\":\"1584\"},{\"id\":\"1586\"}]},\"id\":\"1587\",\"type\":\"Toolbar\"},{\"attributes\":{},\"id\":\"1563\",\"type\":\"DataRange1d\"},{\"attributes\":{\"data_source\":{\"id\":\"1629\"},\"glyph\":{\"id\":\"1630\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1631\"},\"selection_glyph\":null,\"view\":{\"id\":\"1633\"}},\"id\":\"1632\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"overlay\":{\"id\":\"1585\"}},\"id\":\"1581\",\"type\":\"BoxZoomTool\"},{\"attributes\":{},\"id\":\"1626\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1686\",\"type\":\"Selection\"},{\"attributes\":{\"source\":{\"id\":\"1613\"}},\"id\":\"1617\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1582\",\"type\":\"SaveTool\"},{\"attributes\":{\"label\":{\"value\":\"Ray\"},\"renderers\":[{\"id\":\"1616\"}]},\"id\":\"1628\",\"type\":\"LegendItem\"},{\"attributes\":{},\"id\":\"1565\",\"type\":\"DataRange1d\"},{\"attributes\":{\"line_alpha\":0.1,\"line_color\":\"#A6CEE3\",\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1597\",\"type\":\"Line\"},{\"attributes\":{},\"id\":\"1583\",\"type\":\"ResetTool\"},{\"attributes\":{\"fill_color\":{\"value\":\"#B2DF8A\"},\"line_color\":{\"value\":\"#B2DF8A\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1630\",\"type\":\"Square\"},{\"attributes\":{\"source\":{\"id\":\"1595\"}},\"id\":\"1599\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"1584\",\"type\":\"HelpTool\"},{\"attributes\":{\"ticker\":null},\"id\":\"1603\",\"type\":\"LogTickFormatter\"},{\"attributes\":{},\"id\":\"1688\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1569\",\"type\":\"LogScale\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#B2DF8A\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#B2DF8A\"},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"1631\",\"type\":\"Square\"},{\"attributes\":{\"data_source\":{\"id\":\"1613\"},\"glyph\":{\"id\":\"1614\"},\"hover_glyph\":null,\"muted_glyph\":null,\"name\":\"Ray\",\"nonselection_glyph\":{\"id\":\"1615\"},\"selection_glyph\":null,\"view\":{\"id\":\"1617\"}},\"id\":\"1616\",\"type\":\"GlyphRenderer\"},{\"attributes\":{\"source\":{\"id\":\"1608\"}},\"id\":\"1612\",\"type\":\"CDSView\"},{\"attributes\":{\"ticker\":null},\"id\":\"1601\",\"type\":\"LogTickFormatter\"},{\"attributes\":{\"axis_label\":\"N\",\"formatter\":{\"id\":\"1601\"},\"ticker\":{\"id\":\"1572\"}},\"id\":\"1571\",\"type\":\"LogAxis\"},{\"attributes\":{\"num_minor_ticks\":10},\"id\":\"1576\",\"type\":\"LogTicker\"},{\"attributes\":{},\"id\":\"1623\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1625\",\"type\":\"UnionRenderers\"},{\"attributes\":{\"data\":{\"x\":{\"__ndarray__\":\"AAAAAAAA8D8AAAAAAAAkQAAAAAAAAFlAAAAAAABAj0AAAAAAAIjDQAAAAAAAavhA\",\"dtype\":\"float64\",\"shape\":[6]},\"y\":{\"__ndarray__\":\"AAAAAACaaD8AAAAAALpjPwAAAAAAkmE/AAAAAADeYz8AAAAAgIxqPwAAAABAJIU/\",\"dtype\":\"float64\",\"shape\":[6]}},\"selected\":{\"id\":\"1686\"},\"selection_policy\":{\"id\":\"1685\"}},\"id\":\"1613\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"num_minor_ticks\":10},\"id\":\"1572\",\"type\":\"LogTicker\"},{\"attributes\":{},\"id\":\"1624\",\"type\":\"Selection\"},{\"attributes\":{\"axis\":{\"id\":\"1571\"},\"grid_line_alpha\":0.3,\"ticker\":null},\"id\":\"1574\",\"type\":\"Grid\"},{\"attributes\":{\"data\":{\"x\":{\"__ndarray__\":\"AAAAAAAA8D8AAAAAAAAkQAAAAAAAAFlAAAAAAABAj0AAAAAAAIjDQAAAAAAAavhA\",\"dtype\":\"float64\",\"shape\":[6]},\"y\":{\"__ndarray__\":\"AAAAAADkOD8AAAAAAJwyPwAAAAAAuDQ/AAAAAABaYT8AAAAAgGhhPwAAAADwkJI/\",\"dtype\":\"float64\",\"shape\":[6]}},\"selected\":{\"id\":\"1626\"},\"selection_policy\":{\"id\":\"1625\"}},\"id\":\"1608\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"source\":{\"id\":\"1629\"}},\"id\":\"1633\",\"type\":\"CDSView\"},{\"attributes\":{\"axis_label\":\"Time\",\"formatter\":{\"id\":\"1603\"},\"ticker\":{\"id\":\"1576\"}},\"id\":\"1575\",\"type\":\"LogAxis\"}],\"root_ids\":[\"1560\"]},\"title\":\"Bokeh Application\",\"version\":\"2.0.1\"}};\n",
       "  var render_items = [{\"docid\":\"d9eda571-20a2-4f75-97a1-066975d40ea8\",\"root_ids\":[\"1560\"],\"roots\":{\"1560\":\"93cf91c9-e1d1-4c21-b1bd-2c97878e2958\"}}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else {\n",
       "        attempts++;\n",
       "        if (attempts > 100) {\n",
       "          clearInterval(timer);\n",
       "          console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
       "        }\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "1560"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "two_lines = two_lines_plot(\n",
    "    \"N vs. Execution Times (Smaller Is Better)\", 'N', 'Time', 'No Ray', 'Ray', \n",
    "    np_data_ns[:,1], np_data_ns[:,2], np_ray_data_ns[:,1], np_ray_data_ns[:,2],\n",
    "    x_axis_type='log', y_axis_type='log')\n",
    "show(two_lines, plot_width=800, plot_height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(If you can't see it, click [here](../../images/Pi-small-Ns-vs-times.png).)\n",
    "\n",
    "Let's calculate the `N` where they cross:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crossing point: N = 100000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(small_ns)):\n",
    "    if data_ns[i] >= ray_data_ns[i]:\n",
    "        print(f'Crossing point: N = {small_ns[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Ray Crash Course - Actors - Exercise 1\n",
    "\n",
    "You are asked these questions about the `Counter` vs. `RayCounter` performance:\n",
    "\n",
    "> Ignoring pause = 0, can you explain why the Ray times are almost, but slightly larger than the non-ray times consistently? Study the implementations for `ray_counter_trial` and `RayCounter`. What code is synchronous and blocking vs. concurrent? In fact, is there _any_ code that is actually concurrent when you have just one instance of `Counter` or `RayCounter`?\n",
    "\n",
    "Here is `ray_counter_trial` again, with comments about concurrency vs. synchronous blocking calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_counter_trial(count_to, num_counters = 1, pause = 0.01):\n",
    "    print('ray:     count_to = {:5d}, num counters = {:4d}, pause = {:5.3f}: '.format(count_to, num_counters, pause), end='')\n",
    "    start = time.time()\n",
    "    final_count_futures = []\n",
    "    # Actor instantiation blocks, but returns almost immediately. The actor creation overhead is low. It is a little bit larger\n",
    "    # than normal class instantiation, but insignificant for overall performance.\n",
    "    counters = [RayCounter.remote(pause) for _ in range(num_counters)]\n",
    "    for i in range(num_counters):\n",
    "        for n in range(count_to):\n",
    "            counters[i].next.remote()                                # Nonblocking, so will be faster for long pause scenarios...\n",
    "        final_count_futures.append(counters[i].get_count.remote())  \n",
    "    ray.get(final_count_futures)                                     # but block until all invocations are finished!\n",
    "    duration = time.time() - start\n",
    "    print('time = {:9.5f} seconds'.format(duration))\n",
    "    return count_to, num_counters, pause, duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both `next` methods in `Counter` and `RayCounter`, call `time.sleep(pause)` before completing, but for `RayCounter` it runs asynchronously, while it blocks for `Counter`. You do have to block to get the current count and if lots of async invocations of `next` are being processed, a call to `ray.get(actor.get_counter())` will block until all of them are finished.\n",
    "\n",
    "Hence, the reason a single `RayCounter` instance never outperforms a `Counter` instance is because _all_ the code in `ray_counter_trial` becomes effectively _synchronous_ because of the single line `ray.get(final_count_futures)`. Since the Ray implementation has extra overhead for Ray, it will always take a little longer.\n",
    "\n",
    "The real benefit is running many counters concurrently. `ray_counter_trial` does this seamlessly, while `counter_trial` remains fully synchronous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the exercise is this statement and question:\n",
    "\n",
    "> Once past zero pauses, the Ray overhead is constant. It doesn't grow with the pause time. Can you explain why it doesn't grow?\n",
    "\n",
    "The Ray overhead doesn't change because the number of Ray-related invocations don't change as the pause time grows. We still use one counter instance and ten invocations of it. Hence the overhead is a constant, even though the method invocations will take longer to complete, depending on the `pause` value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
