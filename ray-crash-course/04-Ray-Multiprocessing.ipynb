{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ray Crash Course - Python Multiprocessing with Ray\n",
    "\n",
    "This lesson explores how to replace two popular multiprocessing libraries with Ray replacements to break the one-machine boundary:\n",
    "\n",
    "* [`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) for general management of process pools.\n",
    "* [`joblib`](https://joblib.readthedocs.io/en/latest/), the underpinnings of [scikit-learn](https://scikit-learn.org/stable/), which Ray can scale to a cluster.\n",
    "\n",
    "We also examine how Ray can work with Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html).\n",
    "\n",
    "> **Tip:** For more about Ray, see [ray.io](https://ray.io) or the [Ray documentation](https://docs.ray.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray, time, sys, os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ray already running or successfully started\n"
     ]
    }
   ],
   "source": [
    "!../tools/start-ray.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-22 08:24:49,725\tERROR worker.py:700 -- Calling ray.init() again after it has already been called.\n"
     ]
    }
   ],
   "source": [
    "ray.init(address='auto', ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop-in Replacements for Popular Single-node, Multiprocessing Libraries\n",
    "\n",
    "The Python community has three popular libraries for breaking out of Python's _global interpreter lock_ to enable better multiprocessing and concurrency. Ray now offers drop-in replacements for two of them, [`multiprocessing.Pool`](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) and [`joblib`](https://joblib.readthedocs.io/en/latest/), and integration with the third, Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html).\n",
    "\n",
    "This section explores the `multiprocessing.Pool` and `joblib` replacements.\n",
    "\n",
    "| Library | Library Docs | Ray Docs | Description |\n",
    "| :------ | :----------- | :------- | :---------- |\n",
    "| `multiprocessing.Pool` | [docs](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) | [Ray](https://docs.ray.io/en/latest/multiprocessing.html) | Create a pool of processes for running work. The Ray replacement allows scaling to a cluster. |\n",
    "| `joblib` | [docs](https://joblib.readthedocs.io/en/latest/) | [Ray](https://docs.ray.io/en/latest/joblib.html) | Ray supports running distributed [scikit-learn](https://scikit-learn.org/stable/) programs by implementing a Ray backend for `joblib` using Ray Actors instead of local processes. This makes it easy to scale existing applications that use scikit-learn from a single node to a cluster. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiprocessing.Pool\n",
    "\n",
    "If your application already uses `multiprocessing.Pool`, then scaling beyond a single just requires replacing your import statements from this:\n",
    "\n",
    "```python\n",
    "from multiprocessing.pool import Pool\n",
    "```\n",
    "\n",
    "To this:\n",
    "\n",
    "```python\n",
    "from ray.util.multiprocessing.pool import Pool\n",
    "```\n",
    "\n",
    "A local Ray cluster will be started the first time you create a Pool and your tasks will be distributed across it. See [Run on a Cluster](https://docs.ray.io/en/latest/multiprocessing.html#run-on-a-cluster) in the Ray documentation for details on how to use a multi-node Ray cluster instead.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26|27|28|29|30|31|32|33|34|35|36|37|38|39|40|41|42|43|44|45|46|47|48|49|50|51|52|53|54|55|56|57|58|59|60|61|62|63|64|65|66|67|68|69|70|71|72|73|74|75|76|77|78|79|80|81|82|83|84|85|86|87|88|89|90|91|92|93|94|95|96|97|98|99|"
     ]
    }
   ],
   "source": [
    "from ray.util.multiprocessing import Pool\n",
    "\n",
    "def f(index):\n",
    "    return index\n",
    "\n",
    "pool = Pool()\n",
    "for result in pool.map(f, range(100)):\n",
    "    print(f'{result}|', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full `multiprocessing.Pool` API is currently supported. Please see the [multiprocessing documentation](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.pool) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joblib\n",
    "\n",
    "Ray supports running distributed [scikit-learn](https://scikit-learn.org/) programs by implementing a Ray backend for [joblib](https://joblib.readthedocs.io/) using Ray Actors instead of local processes. This makes it easy to scale existing applications that use scikit-learn from a single node to a cluster.\n",
    "\n",
    "> **Note:** This API is new and may be revised in the future. Please [report any issues](https://github.com/ray-project/ray/issues) you encounter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, use `from ray.util.joblib import register_ray` and then run `register_ray()`. This will register Ray as a `joblib` backend for `scikit-learn` to use. Then run your original `scikit-learn` code inside `with joblib.parallel_backend('ray')`. This will start a local Ray cluster. \n",
    "\n",
    "See [Run on a Cluster](https://docs.ray.io/en/latest/joblib.html#run-on-a-cluster) in the Ray documentation for details on how to use a multi-node Ray cluster instead.\n",
    "\n",
    "Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "param_space = {\n",
    "    'C': np.logspace(-6, 6, 30),\n",
    "    'gamma': np.logspace(-8, 8, 30),\n",
    "    'tol': np.logspace(-4, -1, 30),\n",
    "    'class_weight': [None, 'balanced'],\n",
    "}\n",
    "model = SVC(kernel='rbf')\n",
    "search = RandomizedSearchCV(model, param_space, cv=5, n_iter=300, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from ray.util.joblib import register_ray\n",
    "register_ray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** The next cell will take a while!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-22 08:28:48,808\tWARNING pool.py:340 -- The 'context' argument is not supported using ray. Please refer to the documentation for how to control ray initialization.\n"
     ]
    }
   ],
   "source": [
    "with joblib.parallel_backend('ray'):\n",
    "    search.fit(digits.data, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Ray with asyncio\n",
    "\n",
    "Python's [`asyncio`](https://docs.python.org/3/library/asyncio.html) can be used with Ray actors and tasks.\n",
    "\n",
    "> **Note:** The Async API support is experimental and work is ongoing to improve it. Please [report any issues](https://github.com/ray-project/ray/issues) you encounter.\n",
    "\n",
    "#### Actors\n",
    "Here is an actor example, adapted from the [Ray documentation](https://docs.ray.io/en/latest/async_api.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=52447)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52447)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52447)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52447)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52447)\u001b[0m finished\n",
      "\u001b[2m\u001b[36m(pid=52447)\u001b[0m finished\n",
      "\u001b[2m\u001b[36m(pid=52447)\u001b[0m finished\n",
      "\u001b[2m\u001b[36m(pid=52447)\u001b[0m finished\n",
      "\u001b[2m\u001b[36m(pid=52447)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52447)\u001b[0m finished\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "@ray.remote\n",
    "class AsyncActor:\n",
    "    # Multiple invocations of this method can be running in\n",
    "    # the event loop at the same time.\n",
    "    async def run_concurrent(self):\n",
    "        print(\"started\")\n",
    "        await asyncio.sleep(2)   # Concurrent workload here\n",
    "        print(\"finished\")\n",
    "\n",
    "actor = AsyncActor.remote()\n",
    "\n",
    "# regular ray.get\n",
    "ray.get([actor.run_concurrent.remote() for _ in range(4)])\n",
    "\n",
    "# async ray.get\n",
    "await actor.run_concurrent.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Tasks\n",
    "\n",
    "For Ray tasks, the object ids returned by them can be converted to `async.Future` instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@ray.remote\n",
    "def some_task():\n",
    "    return 1\n",
    "\n",
    "# The normal Ray way:\n",
    "ray.wait([some_task.remote()])\n",
    "ray.get(some_task.remote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({<Task finished coro=<_wrap_awaitable() done, defined at /Users/deanwampler/anaconda3/envs/anyscale-academy/lib/python3.7/asyncio/tasks.py:623> result=1>},\n",
       " set())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asyncio alternative way:\n",
    "await some_task.remote()\n",
    "await asyncio.wait([some_task.remote()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [asyncio docs](https://docs.python.org/3/library/asyncio-task.html) for more details on `asyncio` patterns, including timeouts and `asyncio.gather`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Async Actor\n",
    "\n",
    "Ray also supports concurrent multitasking by executing many actor tasks at once. To do so, you can define an actor with async methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class AsyncActor:\n",
    "    async def run_task(self):\n",
    "        print(\"started\")\n",
    "        await asyncio.sleep(1) # Network, I/O task here\n",
    "        print(\"ended\")\n",
    "\n",
    "actor = AsyncActor.remote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following invocation, all 10 tasks should start at once. After 1 second they should all finish about the same time. Note the _wall time_ that will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m started\n",
      "CPU times: user 29.3 ms, sys: 13.1 ms, total: 42.3 ms\n",
      "Wall time: 1.01 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52454)\u001b[0m ended\n"
     ]
    }
   ],
   "source": [
    "%time ray.get([actor.run_task.remote() for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, Ray runs all of the methods inside a single python event loop.\n",
    "\n",
    "> **Note:** Running blocking `ray.get` and `ray.wait` inside async actor methods is not allowed, because `ray.get` will block the execution of the event loop.\n",
    "\n",
    "You can limit the number of concurrent task running at once using the `max_concurrency` flag. By default, 1000 tasks can be running concurrently. \n",
    "\n",
    "In the following cell, we set the `max_concurrency` to `3`, so the subsequent cell will run tasks three at a time. Since there are ten total, it should take about four seconds to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = AsyncActor.options(max_concurrency=3).remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m started\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m ended\n",
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m started\n",
      "CPU times: user 109 ms, sys: 45.9 ms, total: 155 ms\n",
      "Wall time: 4.03 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=52440)\u001b[0m ended\n"
     ]
    }
   ],
   "source": [
    "%time ray.get([actor.run_task.remote() for _ in range(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "382.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
